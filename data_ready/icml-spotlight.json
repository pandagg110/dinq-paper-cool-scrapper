{
  "source_html": "html\\icml-spotlight.html",
  "paper_count": 225,
  "conference": "icml",
  "year": 2025,
  "status": "spotlight",
  "papers": [
    {
      "paper_id": "Hp53p5AU7X@OpenReview",
      "index": 1,
      "title": "Reducing Variance of Stochastic Optimization for Approximating Nash Equilibria in Normal-Form Games",
      "authors": [
        "Linjian Meng",
        "Wubing Chen",
        "Wenbin Li",
        "Tianpei Yang",
        "Youzhi Zhang",
        "Yang Gao"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "nal",
        "loss",
        "unbiased",
        "variance",
        "nash",
        "optimization",
        "approximating",
        "convex",
        "function",
        "nfgs"
      ],
      "summary": "Nash equilibrium (NE) plays an important role in game theory. How to efficiently compute an NE in NFGs is challenging due to its complexity and non-convex optimization property. Machine Learning (ML), the cornerstone of modern artificial intelligence, has demonstrated remarkable empirical performance across various applications including non-convex optimization. To leverage non-convex stochastic optimization techniques from ML for approximating an NE, various loss functions have been proposed. Among these, only one loss function is unbiased, allowing for unbiased estimation under the sampled play. Unfortunately, this loss function suffers from high variance, which degrades the convergence rate. To improve the convergence rate by mitigating the high variance associated with the existing unbiased loss function, we propose a novel surrogate loss function named Nash Advantage Loss (NAL). NAL is theoretically proved unbiased and exhibits significantly lower variance than the existing unbiased loss function. Experimental results demonstrate that the algorithm minimizing NAL achieves a significantly faster empirical convergence rates compared to other algorithms, while also reducing the variance of estimated loss value by several orders of magnitude.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Hp53p5AU7X"
        ],
        "venue": [
          "/venue/Hp53p5AU7X@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Hp53p5AU7X"
        ],
        "detail": [
          "https://openreview.net/forum?id=Hp53p5AU7X"
        ]
      },
      "scores": {
        "pdf": 31,
        "kimi": 27
      },
      "raw_excerpt": "Reducing Variance of Stochastic Optimization for Approximating Nash Equilibria in Normal-Form Games [PDF 31 ] [Copy] [Kimi 27 ] [REL] Authors : Linjian Meng , Wubing Chen , Wenbin Li , Tianpei Yang , Youzhi Zhang , Yang Gao Nash equilibrium (NE) plays an important role in game theory. How to efficiently compute an NE in NFGs is challenging due to its complexity and non-convex optimization property. Machine Learning (ML), the cornerstone of modern artificial intelligence, has demonstrated remarkable empirical performance across various applications including non-convex optimization. To leverage non-convex stochastic optimization techniques from ML for approximating an NE, various loss functions have been proposed. Among these, only one loss function is unbiased, allowing for unbiased estimation under the sampled play. Unfortunately, this loss function suffers from high variance, which degrades the convergence rate. To improve the convergence rate by mitigating the high variance associated with the existing unbiased loss function, we propose a novel surrogate loss function named Nash Advantage Loss (NAL). NAL is theoretically proved unbiased and exhibits significantly lower variance than the existing unbiased loss function. Experimental results demonstrate that the algorithm minimizing NAL achieves a significantly faster empirical convergence rates compared to other algorithms, while also reducing the variance of estimated loss value by several orders of magnitude. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "B9DOjtj9xK@OpenReview",
      "index": 2,
      "title": "Learning Soft Sparse Shapes for Efficient Time-Series Classification",
      "authors": [
        "Zhen Liu",
        "Yicheng Luo",
        "Boyuan Li",
        "Emadeldeen Eldele",
        "Min Wu",
        "Qianli Ma"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "shapes",
        "soft",
        "shape",
        "classification",
        "shapelets",
        "shapelet",
        "softshape",
        "sparsified",
        "subsequence",
        "sparsification"
      ],
      "summary": "Shapelets are discriminative subsequences (or shapes) with high interpretability in time series classification. Due to the time-intensive nature of shapelet discovery, existing shapelet-based methods mainly focus on selecting discriminative shapes while discarding others to achieve candidate subsequence sparsification. However, this approach may exclude beneficial shapes and overlook the varying contributions of shapelets to classification performance. To this end, we propose a Soft sparse Shapes (SoftShape) model for efficient time series classification. Our approach mainly introduces soft shape sparsification and soft shape learning blocks. The former transforms shapes into soft representations based on classification contribution scores, merging lower-scored ones into a single shape to retain and differentiate all subsequence information. The latter facilitates intra- and inter-shape temporal pattern learning, improving model efficiency by using sparsified soft shapes as inputs. Specifically, we employ a learnable router to activate a subset of class-specific expert networks for intra-shape pattern learning. Meanwhile, a shared expert network learns inter-shape patterns by converting sparsified shapes into sequences. Extensive experiments show that SoftShape outperforms state-of-the-art methods and produces interpretable results.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=B9DOjtj9xK"
        ],
        "venue": [
          "/venue/B9DOjtj9xK@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=B9DOjtj9xK"
        ],
        "detail": [
          "https://openreview.net/forum?id=B9DOjtj9xK"
        ]
      },
      "scores": {
        "pdf": 20,
        "kimi": 20
      },
      "raw_excerpt": "Learning Soft Sparse Shapes for Efficient Time-Series Classification [PDF 20 ] [Copy] [Kimi 20 ] [REL] Authors : Zhen Liu , Yicheng Luo , Boyuan Li , Emadeldeen Eldele , Min Wu , Qianli Ma Shapelets are discriminative subsequences (or shapes) with high interpretability in time series classification. Due to the time-intensive nature of shapelet discovery, existing shapelet-based methods mainly focus on selecting discriminative shapes while discarding others to achieve candidate subsequence sparsification. However, this approach may exclude beneficial shapes and overlook the varying contributions of shapelets to classification performance. To this end, we propose a Soft sparse Shapes (SoftShape) model for efficient time series classification. Our approach mainly introduces soft shape sparsification and soft shape learning blocks. The former transforms shapes into soft representations based on classification contribution scores, merging lower-scored ones into a single shape to retain and differentiate all subsequence information. The latter facilitates intra- and inter-shape temporal pattern learning, improving model efficiency by using sparsified soft shapes as inputs. Specifically, we employ a learnable router to activate a subset of class-specific expert networks for intra-shape pattern learning. Meanwhile, a shared expert network learns inter-shape patterns by converting sparsified shapes into sequences. Extensive experiments show that SoftShape outperforms state-of-the-art methods and produces interpretable results. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "XEyGcrhxB8@OpenReview",
      "index": 3,
      "title": "A Unified Theoretical Analysis of Private and Robust Offline Alignment: from RLHF to DPO",
      "authors": [
        "Xingyu Zhou",
        "Yulian Wu",
        "Francesco Orabona"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "corruption",
        "offline",
        "ltc",
        "privacy",
        "ctl",
        "alignment",
        "rlhf",
        "dpo",
        "labels",
        "corrupted"
      ],
      "summary": "In this paper, we theoretically investigate the effects of noisy labels in offline alignment, with a focus on the interplay between privacy and robustness against adversarial corruption. Specifically, under linear modeling assumptions, we present a unified analysis covering both reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO) under different privacy-corruption scenarios, such as Local differential privacy-then-Corruption (LTC), where human preference labels are privatized before being corrupted by an adversary, and Corruption-then-Local differential privacy (CTL), where labels are corrupted before privacy protection. Our analysis leverages a reduction framework that reduces the offline alignment problem under linear modeling assumptions to parameter estimation in logistic regression. This framework allows us to establish an interesting separation result between LTC and CTL, demonstrating that LTC presents a greater challenge than CTL in offline alignment, even under linear models. As important by-products, our findings also advance the state-of-the-art theoretical results in offline alignment under privacy-only or corruption-only scenarios.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=XEyGcrhxB8"
        ],
        "venue": [
          "/venue/XEyGcrhxB8@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=XEyGcrhxB8"
        ],
        "detail": [
          "https://openreview.net/forum?id=XEyGcrhxB8"
        ]
      },
      "scores": {
        "pdf": 21,
        "kimi": 18
      },
      "raw_excerpt": "A Unified Theoretical Analysis of Private and Robust Offline Alignment: from RLHF to DPO [PDF 21 ] [Copy] [Kimi 18 ] [REL] Authors : Xingyu Zhou , Yulian Wu , Francesco Orabona In this paper, we theoretically investigate the effects of noisy labels in offline alignment, with a focus on the interplay between privacy and robustness against adversarial corruption. Specifically, under linear modeling assumptions, we present a unified analysis covering both reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO) under different privacy-corruption scenarios, such as Local differential privacy-then-Corruption (LTC), where human preference labels are privatized before being corrupted by an adversary, and Corruption-then-Local differential privacy (CTL), where labels are corrupted before privacy protection. Our analysis leverages a reduction framework that reduces the offline alignment problem under linear modeling assumptions to parameter estimation in logistic regression. This framework allows us to establish an interesting separation result between LTC and CTL, demonstrating that LTC presents a greater challenge than CTL in offline alignment, even under linear models. As important by-products, our findings also advance the state-of-the-art theoretical results in offline alignment under privacy-only or corruption-only scenarios. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "il3KRr4H9u@OpenReview",
      "index": 4,
      "title": "BaxBench: Can LLMs Generate Correct and Secure Backends?",
      "authors": [
        "Mark Vero",
        "Niels Mündler",
        "Viktor Chibotaru",
        "Veselin Raychev",
        "Maximilian Baader",
        "Nikola Jovanović",
        "Jingxuan He",
        "Martin Vechev"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "baxbench",
        "llms",
        "secure",
        "backends",
        "security",
        "generate",
        "functionality",
        "correct",
        "backend",
        "code"
      ],
      "summary": "Automatic program generation has long been a fundamental challenge in computer science. Recent benchmarks have shown that large language models (LLMs) can effectively generate code at the function level, make code edits, and solve algorithmic coding tasks. However, to achieve full automation, LLMs should be able to generate production-quality, self-contained application modules. To evaluate the capabilities of LLMs in solving this challenge, we introduce BaxBench, a novel evaluation benchmark consisting of 392 tasks for the generation of backend applications. We focus on backends for three critical reasons: (i) they are practically relevant, building the core components of most modern web and cloud software, (ii) they are difficult to get right, requiring multiple functions and files to achieve the desired functionality, and (iii) they are security-critical, as they are exposed to untrusted third-parties, making secure solutions that prevent deployment-time attacks an imperative. BaxBench validates the functionality of the generated applications with comprehensive test cases, and assesses their security exposure by executing end-to-end exploits. Our experiments reveal key limitations of current LLMs in both functionality and security: (i) even the best model, OpenAI o1, achieves a mere 62% on code correctness; (ii) on average, we could successfully execute security exploits on around half of the correct programs generated by each LLM; and (iii) in less popular backend frameworks, models further struggle to generate correct and secure applications. Progress on BaxBench signifies important steps towards autonomous and secure software development with LLMs.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=il3KRr4H9u"
        ],
        "venue": [
          "/venue/il3KRr4H9u@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=il3KRr4H9u"
        ],
        "detail": [
          "https://openreview.net/forum?id=il3KRr4H9u"
        ]
      },
      "scores": {
        "pdf": 11,
        "kimi": 8
      },
      "raw_excerpt": "BaxBench: Can LLMs Generate Correct and Secure Backends? [PDF 11 ] [Copy] [Kimi 8 ] [REL] Authors : Mark Vero , Niels Mündler , Viktor Chibotaru , Veselin Raychev , Maximilian Baader , Nikola Jovanović , Jingxuan He , Martin Vechev Automatic program generation has long been a fundamental challenge in computer science. Recent benchmarks have shown that large language models (LLMs) can effectively generate code at the function level, make code edits, and solve algorithmic coding tasks. However, to achieve full automation, LLMs should be able to generate production-quality, self-contained application modules. To evaluate the capabilities of LLMs in solving this challenge, we introduce BaxBench, a novel evaluation benchmark consisting of 392 tasks for the generation of backend applications. We focus on backends for three critical reasons: (i) they are practically relevant, building the core components of most modern web and cloud software, (ii) they are difficult to get right, requiring multiple functions and files to achieve the desired functionality, and (iii) they are security-critical, as they are exposed to untrusted third-parties, making secure solutions that prevent deployment-time attacks an imperative. BaxBench validates the functionality of the generated applications with comprehensive test cases, and assesses their security exposure by executing end-to-end exploits. Our experiments reveal key limitations of current LLMs in both functionality and security: (i) even the best model, OpenAI o1, achieves a mere 62% on code correctness; (ii) on average, we could successfully execute security exploits on around half of the correct programs generated by each LLM; and (iii) in less popular backend frameworks, models further struggle to generate correct and secure applications. Progress on BaxBench signifies important steps towards autonomous and secure software development with LLMs. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Vhc0KrcqWu@OpenReview",
      "index": 5,
      "title": "Feynman-Kac Correctors in Diffusion: Annealing, Guidance, and Product of Experts",
      "authors": [
        "Marta Skreta",
        "Tara Akhound-Sadegh",
        "Viktor Ohanesian",
        "Roberto Bondesan",
        "Alan Aspuru-Guzik",
        "Arnaud Doucet",
        "Rob Brekelmans",
        "Alexander Tong",
        "Kirill Neklyudov"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "correctors",
        "feynman",
        "kac",
        "guidance",
        "pretrained",
        "annealing",
        "principled",
        "inference",
        "distributions",
        "sampling"
      ],
      "summary": "While score-based generative models are the model of choice across diverse domains, there are limited tools available for controlling inference-time behavior in a principled manner, e.g. for composing multiple pretrained models. Existing classifier-free guidance methods use a simple heuristic to mix conditional and unconditional scores to approximately sample from conditional distributions. However, such methods do not approximate the intermediate distributions, necessitating additional `corrector' steps. In this work, we provide an efficient and principled method for sampling from a sequence of annealed, geometric-averaged, or product distributions derived from pretrained score-based models. We derive a weighted simulation scheme which we call Feynman-Kac Correctors (FKCs) based on the celebrated Feynman-Kac formula by carefully accounting for terms in the appropriate partial differential equations (PDEs). To simulate these PDEs, we propose Sequential Monte Carlo (SMC) resampling algorithms that leverage inference-time scaling to improve sampling quality. We empirically demonstrate the utility of our methods by proposing amortized sampling via inference-time temperature annealing, improving multi-objective molecule generation using pretrained models, and improving classifier-free guidance for text-to-image generation.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Vhc0KrcqWu"
        ],
        "venue": [
          "/venue/Vhc0KrcqWu@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Vhc0KrcqWu"
        ],
        "detail": [
          "https://openreview.net/forum?id=Vhc0KrcqWu"
        ]
      },
      "scores": {
        "pdf": 13,
        "kimi": 16
      },
      "raw_excerpt": "Feynman-Kac Correctors in Diffusion: Annealing, Guidance, and Product of Experts [PDF 13 ] [Copy] [Kimi 16 ] [REL] Authors : Marta Skreta , Tara Akhound-Sadegh , Viktor Ohanesian , Roberto Bondesan , Alan Aspuru-Guzik , Arnaud Doucet , Rob Brekelmans , Alexander Tong , Kirill Neklyudov While score-based generative models are the model of choice across diverse domains, there are limited tools available for controlling inference-time behavior in a principled manner, e.g. for composing multiple pretrained models. Existing classifier-free guidance methods use a simple heuristic to mix conditional and unconditional scores to approximately sample from conditional distributions. However, such methods do not approximate the intermediate distributions, necessitating additional `corrector' steps. In this work, we provide an efficient and principled method for sampling from a sequence of annealed, geometric-averaged, or product distributions derived from pretrained score-based models. We derive a weighted simulation scheme which we call Feynman-Kac Correctors (FKCs) based on the celebrated Feynman-Kac formula by carefully accounting for terms in the appropriate partial differential equations (PDEs). To simulate these PDEs, we propose Sequential Monte Carlo (SMC) resampling algorithms that leverage inference-time scaling to improve sampling quality. We empirically demonstrate the utility of our methods by proposing amortized sampling via inference-time temperature annealing, improving multi-objective molecule generation using pretrained models, and improving classifier-free guidance for text-to-image generation. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "gKdjHLrHDS@OpenReview",
      "index": 6,
      "title": "Feature Learning beyond the Lazy-Rich Dichotomy: Insights from Representational Geometry",
      "authors": [
        "Chi-Ning Chou",
        "Hang Le",
        "Yichen Wang",
        "SueYeon Chung"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "lazy",
        "dichotomy",
        "rich",
        "feature",
        "representational",
        "learning",
        "task",
        "relevant",
        "geometry",
        "insights"
      ],
      "summary": "Integrating task-relevant information into neural representations is a fundamental ability of both biological and artificial intelligence systems. Recent theories have categorized learning into two regimes: the rich regime, where neural networks actively learn task-relevant features, and the lazy regime, where networks behave like random feature models. Yet this simple lazy–rich dichotomy overlooks a diverse underlying taxonomy of feature learning, shaped by differences in learning algorithms, network architectures, and data properties. To address this gap, we introduce an analysis framework to study feature learning via the geometry of neural representations. Rather than inspecting individual learned features, we characterize how task-relevant representational manifolds evolve throughout the learning process. We show, in both theoretical and empirical settings, that as networks learn features, task-relevant manifolds untangle, with changes in manifold geometry revealing distinct learning stages and strategies beyond the lazy–rich dichotomy. This framework provides novel insights into feature learning across neuroscience and machine learning, shedding light on structural inductive biases in neural circuits and the mechanisms underlying out-of-distribution generalization.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=gKdjHLrHDS"
        ],
        "venue": [
          "/venue/gKdjHLrHDS@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=gKdjHLrHDS"
        ],
        "detail": [
          "https://openreview.net/forum?id=gKdjHLrHDS"
        ]
      },
      "scores": {
        "pdf": 13,
        "kimi": 11
      },
      "raw_excerpt": "Feature Learning beyond the Lazy-Rich Dichotomy: Insights from Representational Geometry [PDF 13 ] [Copy] [Kimi 11 ] [REL] Authors : Chi-Ning Chou , Hang Le , Yichen Wang , SueYeon Chung Integrating task-relevant information into neural representations is a fundamental ability of both biological and artificial intelligence systems. Recent theories have categorized learning into two regimes: the rich regime, where neural networks actively learn task-relevant features, and the lazy regime, where networks behave like random feature models. Yet this simple lazy–rich dichotomy overlooks a diverse underlying taxonomy of feature learning, shaped by differences in learning algorithms, network architectures, and data properties. To address this gap, we introduce an analysis framework to study feature learning via the geometry of neural representations. Rather than inspecting individual learned features, we characterize how task-relevant representational manifolds evolve throughout the learning process. We show, in both theoretical and empirical settings, that as networks learn features, task-relevant manifolds untangle, with changes in manifold geometry revealing distinct learning stages and strategies beyond the lazy–rich dichotomy. This framework provides novel insights into feature learning across neuroscience and machine learning, shedding light on structural inductive biases in neural circuits and the mechanisms underlying out-of-distribution generalization. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "m3zrHhiCCj@OpenReview",
      "index": 7,
      "title": "Fishers for Free? Approximating the Fisher Information Matrix by Recycling the Squared Gradient Accumulator",
      "authors": [
        "YuXin Li",
        "Felix Dangel",
        "Derek Tam",
        "Colin Raffel"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "fisher",
        "accumulator",
        "squared",
        "gradient",
        "recycling",
        "squisher",
        "fishers",
        "squ",
        "isher",
        "ared"
      ],
      "summary": "The diagonal of a model's Fisher Information Matrix (the \"Fisher\") has frequently been used as a way to measure parameter sensitivity.Typically, the Fisher is estimated by computing the squared gradient of the model's outputs with respect to its parameters, averaged over a few hundred or thousand examples — a process which incurs nontrivial computational costs.At the same time, adaptive gradient methods like the ubiquitous Adam optimizer compute a moving average of the squared gradient over the course of training.This paper therefore explores whether an approximation of the Fisher can be obtained \"for free\" by recycling the squared gradient accumulator that has already been computed over the course of training.Through a comprehensive set of experiments covering five applications of the Fisher, we demonstrate that the \"Squisher\" (**Squ**ared gradient accumulator as an approximation of the F**isher**) consistently performs similarly to the Fisher while outperforming baseline methods.Additionally, we clarify the exact differences between the Squisher and the Fisher and provide empirical quantification of their respective impact.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=m3zrHhiCCj"
        ],
        "venue": [
          "/venue/m3zrHhiCCj@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=m3zrHhiCCj"
        ],
        "detail": [
          "https://openreview.net/forum?id=m3zrHhiCCj"
        ]
      },
      "scores": {
        "pdf": 16,
        "kimi": 13
      },
      "raw_excerpt": "Fishers for Free? Approximating the Fisher Information Matrix by Recycling the Squared Gradient Accumulator [PDF 16 ] [Copy] [Kimi 13 ] [REL] Authors : YuXin Li , Felix Dangel , Derek Tam , Colin Raffel The diagonal of a model's Fisher Information Matrix (the \"Fisher\") has frequently been used as a way to measure parameter sensitivity.Typically, the Fisher is estimated by computing the squared gradient of the model's outputs with respect to its parameters, averaged over a few hundred or thousand examples — a process which incurs nontrivial computational costs.At the same time, adaptive gradient methods like the ubiquitous Adam optimizer compute a moving average of the squared gradient over the course of training.This paper therefore explores whether an approximation of the Fisher can be obtained \"for free\" by recycling the squared gradient accumulator that has already been computed over the course of training.Through a comprehensive set of experiments covering five applications of the Fisher, we demonstrate that the \"Squisher\" (**Squ**ared gradient accumulator as an approximation of the F**isher**) consistently performs similarly to the Fisher while outperforming baseline methods.Additionally, we clarify the exact differences between the Squisher and the Fisher and provide empirical quantification of their respective impact. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "dzwUOiBlQW@OpenReview",
      "index": 8,
      "title": "Masked Autoencoders Are Effective Tokenizers for Diffusion Models",
      "authors": [
        "Hao Chen",
        "Yujin Han",
        "Fangyi Chen",
        "Xiang Li",
        "Yidong Wang",
        "Jindong Wang",
        "Ze Wang",
        "Zicheng Liu",
        "Difan Zou",
        "Bhiksha Raj"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "latent",
        "maetok",
        "diffusion",
        "autoencoders",
        "generation",
        "512",
        "tokenizers",
        "gfid",
        "space",
        "discriminative"
      ],
      "summary": "Recent advances in latent diffusion models have demonstrated their effectiveness for high-resolution image synthesis. However, the properties of the latent space from tokenizer for better learning and generation of diffusion models remain under-explored. Theoretically and empirically, we find that improved generation quality is closely tied to the latent distributions with better structure, such as the ones with fewer Gaussian Mixture modes and more discriminative features. Motivated by these insights, we propose MAETok, an autoencoder (AE) leveraging mask modeling to learn semantically rich latent space while maintaining reconstruction fidelity. Extensive experiments validate our analysis, demonstrating that the variational form of autoencoders is not necessary, and a discriminative latent space from AE alone enables state-of-the-art performance on ImageNet generation using only 128 tokens. MAETok achieves significant practical improvements, enabling a gFID of 1.69 with 76× faster training and 31× higher inference throughput for 512×512 generation. Our findings show that the structure of the latent space, rather than variational constraints, is crucial for effective diffusion models. Code and trained models will be released.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=dzwUOiBlQW"
        ],
        "venue": [
          "/venue/dzwUOiBlQW@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=dzwUOiBlQW"
        ],
        "detail": [
          "https://openreview.net/forum?id=dzwUOiBlQW"
        ]
      },
      "scores": {
        "pdf": 22,
        "kimi": 23
      },
      "raw_excerpt": "Masked Autoencoders Are Effective Tokenizers for Diffusion Models [PDF 22 ] [Copy] [Kimi 23 ] [REL] Authors : Hao Chen , Yujin Han , Fangyi Chen , Xiang Li , Yidong Wang , Jindong Wang , Ze Wang , Zicheng Liu , Difan Zou , Bhiksha Raj Recent advances in latent diffusion models have demonstrated their effectiveness for high-resolution image synthesis. However, the properties of the latent space from tokenizer for better learning and generation of diffusion models remain under-explored. Theoretically and empirically, we find that improved generation quality is closely tied to the latent distributions with better structure, such as the ones with fewer Gaussian Mixture modes and more discriminative features. Motivated by these insights, we propose MAETok, an autoencoder (AE) leveraging mask modeling to learn semantically rich latent space while maintaining reconstruction fidelity. Extensive experiments validate our analysis, demonstrating that the variational form of autoencoders is not necessary, and a discriminative latent space from AE alone enables state-of-the-art performance on ImageNet generation using only 128 tokens. MAETok achieves significant practical improvements, enabling a gFID of 1.69 with 76× faster training and 31× higher inference throughput for 512×512 generation. Our findings show that the structure of the latent space, rather than variational constraints, is crucial for effective diffusion models. Code and trained models will be released. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Ossg1IbHDT@OpenReview",
      "index": 9,
      "title": "Scalable Generation of Spatial Transcriptomics from Histology Images via Whole-Slide Flow Matching",
      "authors": [
        "Tinglin Huang",
        "Tianyu Liu",
        "Mehrtash Babadi",
        "Wengong Jin",
        "ZHITAO YING"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "slide",
        "histology",
        "transcriptomics",
        "whole",
        "gene",
        "cell",
        "stflow",
        "expression",
        "stimage",
        "1k4m"
      ],
      "summary": "Spatial transcriptomics (ST) has emerged as a powerful technology for bridging histology imaging with gene expression profiling. However, its application has been limited by low throughput and the need for specialized experimental facilities. Prior works sought to predict ST from whole-slide histology images to accelerate this process, but they suffer from two major limitations. First, they do not explicitly model cell-cell interaction as they factorize the joint distribution of whole-slide ST data and predict the gene expression of each spot independently. Second, their encoders struggle with memory constraints due to the large number of spots (often exceeding 10,000) in typical ST datasets. Herein, we propose STFlow, a flow matching generative model that considers cell-cell interaction by modeling the joint distribution of gene expression of an entire slide. It also employs an efficient slide-level encoder with local spatial attention, enabling whole-slide processing without excessive memory overhead. On the recently curated HEST-1k and STImage-1K4M benchmarks, STFlow substantially outperforms state-of-the-art baselines and achieves over 18% relative improvements over the pathology foundation models.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Ossg1IbHDT"
        ],
        "venue": [
          "/venue/Ossg1IbHDT@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Ossg1IbHDT"
        ],
        "detail": [
          "https://openreview.net/forum?id=Ossg1IbHDT"
        ]
      },
      "scores": {
        "pdf": 12,
        "kimi": 10
      },
      "raw_excerpt": "Scalable Generation of Spatial Transcriptomics from Histology Images via Whole-Slide Flow Matching [PDF 12 ] [Copy] [Kimi 10 ] [REL] Authors : Tinglin Huang , Tianyu Liu , Mehrtash Babadi , Wengong Jin , ZHITAO YING Spatial transcriptomics (ST) has emerged as a powerful technology for bridging histology imaging with gene expression profiling. However, its application has been limited by low throughput and the need for specialized experimental facilities. Prior works sought to predict ST from whole-slide histology images to accelerate this process, but they suffer from two major limitations. First, they do not explicitly model cell-cell interaction as they factorize the joint distribution of whole-slide ST data and predict the gene expression of each spot independently. Second, their encoders struggle with memory constraints due to the large number of spots (often exceeding 10,000) in typical ST datasets. Herein, we propose STFlow, a flow matching generative model that considers cell-cell interaction by modeling the joint distribution of gene expression of an entire slide. It also employs an efficient slide-level encoder with local spatial attention, enabling whole-slide processing without excessive memory overhead. On the recently curated HEST-1k and STImage-1K4M benchmarks, STFlow substantially outperforms state-of-the-art baselines and achieves over 18% relative improvements over the pathology foundation models. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Vf9f7eNX6T@OpenReview",
      "index": 10,
      "title": "A Closer Look at Multimodal Representation Collapse",
      "authors": [
        "Abhra Chaudhuri",
        "Anjan Dutta",
        "Tu Bui",
        "Serban Georgescu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "modality",
        "collapse",
        "multimodal",
        "fusion",
        "predictive",
        "abhrac",
        "modalities",
        "features",
        "head",
        "freeing"
      ],
      "summary": "We aim to develop a fundamental understanding of modality collapse, a recently observed empirical phenomenon wherein models trained for multimodal fusion tend to rely only on a subset of the modalities, ignoring the rest. We show that modality collapse happens when noisy features from one modality are entangled, via a shared set of neurons in the fusion head, with predictive features from another, effectively masking out positive contributions from the predictive features of the former modality and leading to its collapse. We further prove that cross-modal knowledge distillation implicitly disentangles such representations by freeing up rank bottlenecks in the student encoder, denoising the fusion-head outputs without negatively impacting the predictive features from either modality. Based on the above findings, we propose an algorithm that prevents modality collapse through explicit basis reallocation, with applications in dealing with missing modalities. Extensive experiments on multiple multimodal benchmarks validate our theoretical claims. Project page: https://abhrac.github.io/mmcollapse/.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Vf9f7eNX6T"
        ],
        "venue": [
          "/venue/Vf9f7eNX6T@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Vf9f7eNX6T"
        ],
        "detail": [
          "https://openreview.net/forum?id=Vf9f7eNX6T"
        ]
      },
      "scores": {
        "pdf": 23,
        "kimi": 19
      },
      "raw_excerpt": "A Closer Look at Multimodal Representation Collapse [PDF 23 ] [Copy] [Kimi 19 ] [REL] Authors : Abhra Chaudhuri , Anjan Dutta , Tu Bui , Serban Georgescu We aim to develop a fundamental understanding of modality collapse, a recently observed empirical phenomenon wherein models trained for multimodal fusion tend to rely only on a subset of the modalities, ignoring the rest. We show that modality collapse happens when noisy features from one modality are entangled, via a shared set of neurons in the fusion head, with predictive features from another, effectively masking out positive contributions from the predictive features of the former modality and leading to its collapse. We further prove that cross-modal knowledge distillation implicitly disentangles such representations by freeing up rank bottlenecks in the student encoder, denoising the fusion-head outputs without negatively impacting the predictive features from either modality. Based on the above findings, we propose an algorithm that prevents modality collapse through explicit basis reallocation, with applications in dealing with missing modalities. Extensive experiments on multiple multimodal benchmarks validate our theoretical claims. Project page: https://abhrac.github.io/mmcollapse/. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "TyArXyYnvz@OpenReview",
      "index": 11,
      "title": "GL-LowPopArt: A Nearly Instance-Wise Minimax-Optimal Estimator for Generalized Low-Rank Trace Regression",
      "authors": [
        "Junghyun Lee",
        "Kyoungseok Jang",
        "Kwang-Sung Jun",
        "Milan Vojnovic",
        "Se-Young Yun"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "lowpopart",
        "catoni",
        "2024",
        "minimax",
        "generalized",
        "instance",
        "wise",
        "estimator",
        "rank",
        "trace"
      ],
      "summary": "We present `GL-LowPopArt`, a novel Catoni-style estimator for generalized low-rank trace regression. Building on `LowPopArt` (Jang et al., 2024), it employs a two-stage approach: nuclear norm regularization followed by matrix Catoni estimation. We establish state-of-the-art estimation error bounds, surpassing existing guarantees (Fan et al., 2019; Kang et al., 2022), and reveal a novel experimental design objective, G L ( π ) G L ( π ) . The key technical challenge is controlling bias from the nonlinear inverse link function, which we address by our two-stage approach. We prove a *local* minimax lower bound, showing that our `GL-LowPopArt` enjoys instance-wise optimality up to the condition number of the ground-truth Hessian. Applications include generalized linear matrix completion, where `GL-LowPopArt` achieves a state-of-the-art Frobenius error guarantee, and **bilinear dueling bandits**, a novel setting inspired by general preference learning (Zhang et al., 2024). Our analysis of a `GL-LowPopArt`-based explore-then-commit algorithm reveals a new, potentially interesting problem-dependent quantity, along with improved Borda regret bound than vectorization (Wu et al., 2024).",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=TyArXyYnvz"
        ],
        "venue": [
          "/venue/TyArXyYnvz@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=TyArXyYnvz"
        ],
        "detail": [
          "https://openreview.net/forum?id=TyArXyYnvz"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 4
      },
      "raw_excerpt": "GL-LowPopArt: A Nearly Instance-Wise Minimax-Optimal Estimator for Generalized Low-Rank Trace Regression [PDF 5 ] [Copy] [Kimi 4 ] [REL] Authors : Junghyun Lee , Kyoungseok Jang , Kwang-Sung Jun , Milan Vojnovic , Se-Young Yun We present `GL-LowPopArt`, a novel Catoni-style estimator for generalized low-rank trace regression. Building on `LowPopArt` (Jang et al., 2024), it employs a two-stage approach: nuclear norm regularization followed by matrix Catoni estimation. We establish state-of-the-art estimation error bounds, surpassing existing guarantees (Fan et al., 2019; Kang et al., 2022), and reveal a novel experimental design objective, G L ( π ) G L ( π ) . The key technical challenge is controlling bias from the nonlinear inverse link function, which we address by our two-stage approach. We prove a *local* minimax lower bound, showing that our `GL-LowPopArt` enjoys instance-wise optimality up to the condition number of the ground-truth Hessian. Applications include generalized linear matrix completion, where `GL-LowPopArt` achieves a state-of-the-art Frobenius error guarantee, and **bilinear dueling bandits**, a novel setting inspired by general preference learning (Zhang et al., 2024). Our analysis of a `GL-LowPopArt`-based explore-then-commit algorithm reveals a new, potentially interesting problem-dependent quantity, along with improved Borda regret bound than vectorization (Wu et al., 2024). Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "zk5k2NQcEA@OpenReview",
      "index": 12,
      "title": "Score-of-Mixture Training: One-Step Generative Model Training Made Simple via Score Estimation of Mixture Distributions",
      "authors": [
        "Tejas Jayashankar",
        "Jongha (Jon) Ryu",
        "Gregory Wornell"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "smt",
        "score",
        "mixture",
        "training",
        "smd",
        "generative",
        "distillation",
        "step",
        "distributions",
        "jensen"
      ],
      "summary": "We propose *Score-of-Mixture Training* (SMT), a novel framework for training one-step generative models by minimizing a class of divergences called the α α -skew Jensen–Shannon divergence. At its core, SMT estimates the score of mixture distributions between real and fake samples across multiple noise levels.Similar to consistency models, our approach supports both training from scratch (SMT) and distillation using a pretrained diffusion model, which we call *Score-of-Mixture Distillation* (SMD).It is simple to implement, requires minimal hyperparameter tuning, and ensures stable training. Experiments on CIFAR-10 and ImageNet 64×64 show that SMT/SMD are competitive with and can even outperform existing methods.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=zk5k2NQcEA"
        ],
        "venue": [
          "/venue/zk5k2NQcEA@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=zk5k2NQcEA"
        ],
        "detail": [
          "https://openreview.net/forum?id=zk5k2NQcEA"
        ]
      },
      "scores": {
        "pdf": 9,
        "kimi": 11
      },
      "raw_excerpt": "Score-of-Mixture Training: One-Step Generative Model Training Made Simple via Score Estimation of Mixture Distributions [PDF 9 ] [Copy] [Kimi 11 ] [REL] Authors : Tejas Jayashankar , Jongha (Jon) Ryu , Gregory Wornell We propose *Score-of-Mixture Training* (SMT), a novel framework for training one-step generative models by minimizing a class of divergences called the α α -skew Jensen–Shannon divergence. At its core, SMT estimates the score of mixture distributions between real and fake samples across multiple noise levels.Similar to consistency models, our approach supports both training from scratch (SMT) and distillation using a pretrained diffusion model, which we call *Score-of-Mixture Distillation* (SMD).It is simple to implement, requires minimal hyperparameter tuning, and ensures stable training. Experiments on CIFAR-10 and ImageNet 64×64 show that SMT/SMD are competitive with and can even outperform existing methods. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "VpBBw1bL47@OpenReview",
      "index": 13,
      "title": "InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective",
      "authors": [
        "Yuanhong Zhang",
        "Muyao Yuan",
        "Weizhan Zhang",
        "Tieliang Gong",
        "Wen Wen",
        "Jiangyong Ying",
        "Weijie Shi"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "sam",
        "infosam",
        "peft",
        "anything",
        "fine",
        "tuning",
        "information",
        "pre",
        "trained",
        "segment"
      ],
      "summary": "The Segment Anything Model (SAM), a vision foundation model, exhibits impressive zero-shot capabilities in general tasks but struggles in specialized domains. Parameter-efficient fine-tuning (PEFT) is a promising approach to unleash the potential of SAM in novel scenarios. However, existing PEFT methods for SAM neglect the domain-invariant relations encoded in the pre-trained model. To bridge this gap, we propose InfoSAM, an information-theoretic approach that enhances SAM fine-tuning by distilling and preserving its pre-trained segmentation knowledge. Specifically, we formulate the knowledge transfer process as two novel mutual information-based objectives: (i) to compress the domain-invariant relation extracted from pre-trained SAM, excluding pseudo-invariant information as possible, and (ii) to maximize mutual information between the relational knowledge learned by the teacher (pre-trained SAM) and the student (fine-tuned model). The proposed InfoSAM establishes a robust distillation framework for PEFT of SAM. Extensive experiments across diverse benchmarks validate InfoSAM's effectiveness in improving SAM family's performance on real-world tasks, demonstrating its adaptability and superiority in handling specialized scenarios. The code and models are available at https://muyaoyuan.github.io/InfoSAM_Page.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=VpBBw1bL47"
        ],
        "venue": [
          "/venue/VpBBw1bL47@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=VpBBw1bL47"
        ],
        "detail": [
          "https://openreview.net/forum?id=VpBBw1bL47"
        ]
      },
      "scores": {
        "pdf": 14,
        "kimi": 6
      },
      "raw_excerpt": "InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective [PDF 14 ] [Copy] [Kimi 6 ] [REL] Authors : Yuanhong Zhang , Muyao Yuan , Weizhan Zhang , Tieliang Gong , Wen Wen , Jiangyong Ying , Weijie Shi The Segment Anything Model (SAM), a vision foundation model, exhibits impressive zero-shot capabilities in general tasks but struggles in specialized domains. Parameter-efficient fine-tuning (PEFT) is a promising approach to unleash the potential of SAM in novel scenarios. However, existing PEFT methods for SAM neglect the domain-invariant relations encoded in the pre-trained model. To bridge this gap, we propose InfoSAM, an information-theoretic approach that enhances SAM fine-tuning by distilling and preserving its pre-trained segmentation knowledge. Specifically, we formulate the knowledge transfer process as two novel mutual information-based objectives: (i) to compress the domain-invariant relation extracted from pre-trained SAM, excluding pseudo-invariant information as possible, and (ii) to maximize mutual information between the relational knowledge learned by the teacher (pre-trained SAM) and the student (fine-tuned model). The proposed InfoSAM establishes a robust distillation framework for PEFT of SAM. Extensive experiments across diverse benchmarks validate InfoSAM's effectiveness in improving SAM family's performance on real-world tasks, demonstrating its adaptability and superiority in handling specialized scenarios. The code and models are available at https://muyaoyuan.github.io/InfoSAM_Page. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "79O2XccGXZ@OpenReview",
      "index": 14,
      "title": "Geometric Representation Condition Improves Equivariant Molecule Generation",
      "authors": [
        "Zian Li",
        "Cai Zhou",
        "Xiyuan Wang",
        "Xingang Peng",
        "Muhan Zhang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "generation",
        "molecule",
        "representation",
        "geometric",
        "molecular",
        "quality",
        "georcg",
        "stage",
        "semlaflow",
        "drug"
      ],
      "summary": "Recent advances in molecular generative models have demonstrated great promise for accelerating scientific discovery, particularly in drug design. However, these models often struggle to generate high-quality molecules, especially in conditional scenarios where specific molecular properties must be satisfied. In this work, we introduce GeoRCG, a general framework to improve molecular generative models by integrating geometric representation conditions with provable theoretical guarantees. We decompose the generation process into two stages: first, generating an informative geometric representation; second, generating a molecule conditioned on the representation. Compared with single-stage generation, the easy-to-generate representation in the first stage guides the second stage generation toward a high-quality molecule in a goal-oriented way. Leveraging EDM and SemlaFlow as base generators, we observe significant quality improvements in unconditional molecule generation on the widely used QM9 and GEOM-DRUG datasets. More notably, in the challenging conditional molecular generation task, our framework achieves an average 50\\% performance improvement over state-of-the-art approaches, highlighting the superiority of conditioning on semantically rich geometric representations. Furthermore, with such representation guidance, the number of diffusion steps can be reduced to as small as 100 while largely preserving the generation quality achieved with 1,000 steps, thereby significantly reducing the generation iterations needed.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=79O2XccGXZ"
        ],
        "venue": [
          "/venue/79O2XccGXZ@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=79O2XccGXZ"
        ],
        "detail": [
          "https://openreview.net/forum?id=79O2XccGXZ"
        ]
      },
      "scores": {
        "pdf": 10,
        "kimi": 7
      },
      "raw_excerpt": "Geometric Representation Condition Improves Equivariant Molecule Generation [PDF 10 ] [Copy] [Kimi 7 ] [REL] Authors : Zian Li , Cai Zhou , Xiyuan Wang , Xingang Peng , Muhan Zhang Recent advances in molecular generative models have demonstrated great promise for accelerating scientific discovery, particularly in drug design. However, these models often struggle to generate high-quality molecules, especially in conditional scenarios where specific molecular properties must be satisfied. In this work, we introduce GeoRCG, a general framework to improve molecular generative models by integrating geometric representation conditions with provable theoretical guarantees. We decompose the generation process into two stages: first, generating an informative geometric representation; second, generating a molecule conditioned on the representation. Compared with single-stage generation, the easy-to-generate representation in the first stage guides the second stage generation toward a high-quality molecule in a goal-oriented way. Leveraging EDM and SemlaFlow as base generators, we observe significant quality improvements in unconditional molecule generation on the widely used QM9 and GEOM-DRUG datasets. More notably, in the challenging conditional molecular generation task, our framework achieves an average 50\\% performance improvement over state-of-the-art approaches, highlighting the superiority of conditioning on semantically rich geometric representations. Furthermore, with such representation guidance, the number of diffusion steps can be reduced to as small as 100 while largely preserving the generation quality achieved with 1,000 steps, thereby significantly reducing the generation iterations needed. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "jNCTdUsQaC@OpenReview",
      "index": 15,
      "title": "On Learning Parallel Pancakes with Mostly Uniform Weights",
      "authors": [
        "Ilias Diakonikolas",
        "Daniel Kane",
        "Sushrut Karmalkar",
        "Jasper Lee",
        "Thanasis Pittas"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "weights",
        "gmms",
        "uniform",
        "pancakes",
        "bound",
        "complexity",
        "task",
        "min",
        "posits",
        "gaussians"
      ],
      "summary": "We study the complexity of learning k k -mixtures of Gaussians ( k k -GMMs) on R d R d . This task is known to have complexity d Ω ( k ) d Ω ( k ) in full generality. To circumvent this exponential lower bound on the number of components, research has focused on learning families of GMMs satisfying additional structural properties. A natural assumption posits that the component weights are not exponentially small and that the components have the same unknown covariance. Recent work gave a d O ( log ( 1 / w min ) ) d O ( log ⁡ ( 1 / w min ) ) -time algorithm for this class of GMMs, where w min w min is the minimum weight. Our first main result is a Statistical Query (SQ) lower bound showing that this quasi-polynomial upper bound is essentially best possible, even for the special case of uniform weights. Specifically, we show that it is SQ-hard to distinguish between such a mixture and the standard Gaussian. We further explore how the distribution of weights affects the complexity of this task. Our second main result is a quasi-polynomial upper bound for the aforementioned testing task when most of the weights are uniform while a small fraction of the weights are potentially arbitrary.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=jNCTdUsQaC"
        ],
        "venue": [
          "/venue/jNCTdUsQaC@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=jNCTdUsQaC"
        ],
        "detail": [
          "https://openreview.net/forum?id=jNCTdUsQaC"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "On Learning Parallel Pancakes with Mostly Uniform Weights [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Ilias Diakonikolas , Daniel Kane , Sushrut Karmalkar , Jasper Lee , Thanasis Pittas We study the complexity of learning k k -mixtures of Gaussians ( k k -GMMs) on R d R d . This task is known to have complexity d Ω ( k ) d Ω ( k ) in full generality. To circumvent this exponential lower bound on the number of components, research has focused on learning families of GMMs satisfying additional structural properties. A natural assumption posits that the component weights are not exponentially small and that the components have the same unknown covariance. Recent work gave a d O ( log ( 1 / w min ) ) d O ( log ⁡ ( 1 / w min ) ) -time algorithm for this class of GMMs, where w min w min is the minimum weight. Our first main result is a Statistical Query (SQ) lower bound showing that this quasi-polynomial upper bound is essentially best possible, even for the special case of uniform weights. Specifically, we show that it is SQ-hard to distinguish between such a mixture and the standard Gaussian. We further explore how the distribution of weights affects the complexity of this task. Our second main result is a quasi-polynomial upper bound for the aforementioned testing task when most of the weights are uniform while a small fraction of the weights are potentially arbitrary. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "GFsMJKt9Kp@OpenReview",
      "index": 16,
      "title": "Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety",
      "authors": [
        "Zihan Guan",
        "Mengxuan Hu",
        "Ronghang Zhu",
        "Sheng Li",
        "Anil Vullikanti"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "benign",
        "samples",
        "tuning",
        "fine",
        "outlier",
        "llms",
        "severely",
        "safety",
        "inf",
        "attack"
      ],
      "summary": "Recent studies have uncovered a troubling vulnerability in the fine-tuning stage of large language models (LLMs): even fine-tuning on entirely benign datasets can lead to a significant increase in the harmfulness of LLM outputs. Building on this finding, our red teaming study takes this threat one step further by developing a more effective attack. Specifically, we analyze and identify samples within benign datasets that contribute most to safety degradation, then fine-tune LLMs exclusively on these samples. We approach this problem from an outlier detection perspective and propose Self-Inf-N, to detect and extract outliers for fine-tuning. Our findings reveal that fine-tuning LLMs on 100 outlier samples selected by Self-Inf-N in the benign datasets severely compromises LLM safety alignment. Extensive experiments across seven mainstream LLMs demonstrate that our attack exhibits high transferability across different architectures and remains effective in practical scenarios. Alarmingly, our results indicate that most existing mitigation strategies fail to defend against this attack, underscoring the urgent need for more robust alignment safeguards. Codes are available at https://github.com/GuanZihan/Benign-Samples-Matter.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=GFsMJKt9Kp"
        ],
        "venue": [
          "/venue/GFsMJKt9Kp@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=GFsMJKt9Kp"
        ],
        "detail": [
          "https://openreview.net/forum?id=GFsMJKt9Kp"
        ]
      },
      "scores": {
        "pdf": 11,
        "kimi": 6
      },
      "raw_excerpt": "Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety [PDF 11 ] [Copy] [Kimi 6 ] [REL] Authors : Zihan Guan , Mengxuan Hu , Ronghang Zhu , Sheng Li , Anil Vullikanti Recent studies have uncovered a troubling vulnerability in the fine-tuning stage of large language models (LLMs): even fine-tuning on entirely benign datasets can lead to a significant increase in the harmfulness of LLM outputs. Building on this finding, our red teaming study takes this threat one step further by developing a more effective attack. Specifically, we analyze and identify samples within benign datasets that contribute most to safety degradation, then fine-tune LLMs exclusively on these samples. We approach this problem from an outlier detection perspective and propose Self-Inf-N, to detect and extract outliers for fine-tuning. Our findings reveal that fine-tuning LLMs on 100 outlier samples selected by Self-Inf-N in the benign datasets severely compromises LLM safety alignment. Extensive experiments across seven mainstream LLMs demonstrate that our attack exhibits high transferability across different architectures and remains effective in practical scenarios. Alarmingly, our results indicate that most existing mitigation strategies fail to defend against this attack, underscoring the urgent need for more robust alignment safeguards. Codes are available at https://github.com/GuanZihan/Benign-Samples-Matter. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "J5MmGPWKfb@OpenReview",
      "index": 17,
      "title": "Position: Language model developers should report train-test overlap",
      "authors": [
        "Andy Zhang",
        "Kevin Klyman",
        "Yifan Mai",
        "Yoav Levine",
        "Yian Zhang",
        "Rishi Bommasani",
        "Percy Liang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "overlap",
        "train",
        "test",
        "language",
        "developers",
        "publish",
        "public",
        "statistics",
        "report",
        "models"
      ],
      "summary": "Language models are extensively evaluated, but correctly interpreting evaluation results requires knowledge of train-test overlap, which refers to the extent to which the language model is trained on the very data it is being tested on. The public currently lacks adequate information about train-test overlap: most models have no public train-test overlap statistics, and third parties cannot directly measure train-test overlap since they do not have access to the training data. To make this clear, we document the practices of 30 models, finding that just 9 models report train-test overlap: 4 models release training data under open-source licenses, enabling the community to directly measure train-test overlap, and 5 models publish their train-test overlap methodology and statistics. By engaging with language model developers, we provide novel information about train-test overlap for three additional models. Overall, this position paper argues that language model developers should publish train-test overlap statistics and/or training data whenever they report evaluation results on public test sets. We hope our work increases transparency into train-test overlap to increase the community-wide trust in model evaluations.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=J5MmGPWKfb"
        ],
        "venue": [
          "/venue/J5MmGPWKfb@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=J5MmGPWKfb"
        ],
        "detail": [
          "https://openreview.net/forum?id=J5MmGPWKfb"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 10
      },
      "raw_excerpt": "Position: Language model developers should report train-test overlap [PDF 5 ] [Copy] [Kimi 10 ] [REL] Authors : Andy Zhang , Kevin Klyman , Yifan Mai , Yoav Levine , Yian Zhang , Rishi Bommasani , Percy Liang Language models are extensively evaluated, but correctly interpreting evaluation results requires knowledge of train-test overlap, which refers to the extent to which the language model is trained on the very data it is being tested on. The public currently lacks adequate information about train-test overlap: most models have no public train-test overlap statistics, and third parties cannot directly measure train-test overlap since they do not have access to the training data. To make this clear, we document the practices of 30 models, finding that just 9 models report train-test overlap: 4 models release training data under open-source licenses, enabling the community to directly measure train-test overlap, and 5 models publish their train-test overlap methodology and statistics. By engaging with language model developers, we provide novel information about train-test overlap for three additional models. Overall, this position paper argues that language model developers should publish train-test overlap statistics and/or training data whenever they report evaluation results on public test sets. We hope our work increases transparency into train-test overlap to increase the community-wide trust in model evaluations. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "0ysC6VS0y3@OpenReview",
      "index": 18,
      "title": "Emergence and Effectiveness of Task Vectors in In-Context Learning: An Encoder Decoder Perspective",
      "authors": [
        "Seungwook Han",
        "Jinyeop Song",
        "Jeff Gore",
        "Pulkit Agrawal"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "icl",
        "task",
        "encoding",
        "transformers",
        "decoding",
        "vectors",
        "representations",
        "pretraining",
        "finetuning",
        "olmo"
      ],
      "summary": "Autoregressive transformers exhibit adaptive learning through in-context learning (ICL), which begs the question of how. Prior works have shown that transformers represent the ICL tasks as vectors in their representations. In this paper, we leverage the encoding-decoding framework to study how transformers form task vectors during pretraining and how their task encoding quality predicts ICL task performance. On synthetic ICL tasks, we analyze the training dynamics of a small transformer and report the coupled emergence of task encoding and decoding. As the model learns to encode different latent tasks (e.g., \"Finding the first noun in a sentence.\") into distinct, separable representations, it concurrently builds conditional decoding algorithms and improves its ICL performance. We validate this phenomenon across pretrained models of varying scales (Gemma-2 2B/9B/27B, Llama-3.1 8B/70B) and over the course of pretraining in OLMo-7B. Further, we demonstrate that the quality of task encoding inferred from representations predicts ICL performance, and that, surprisingly, finetuning the earlier layers can improve the task encoding and performance more than finetuning the latter layers. Our empirical insights shed light into better understanding the success and failure modes of large language models via their representations.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=0ysC6VS0y3"
        ],
        "venue": [
          "/venue/0ysC6VS0y3@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=0ysC6VS0y3"
        ],
        "detail": [
          "https://openreview.net/forum?id=0ysC6VS0y3"
        ]
      },
      "scores": {
        "pdf": 9,
        "kimi": 10
      },
      "raw_excerpt": "Emergence and Effectiveness of Task Vectors in In-Context Learning: An Encoder Decoder Perspective [PDF 9 ] [Copy] [Kimi 10 ] [REL] Authors : Seungwook Han , Jinyeop Song , Jeff Gore , Pulkit Agrawal Autoregressive transformers exhibit adaptive learning through in-context learning (ICL), which begs the question of how. Prior works have shown that transformers represent the ICL tasks as vectors in their representations. In this paper, we leverage the encoding-decoding framework to study how transformers form task vectors during pretraining and how their task encoding quality predicts ICL task performance. On synthetic ICL tasks, we analyze the training dynamics of a small transformer and report the coupled emergence of task encoding and decoding. As the model learns to encode different latent tasks (e.g., \"Finding the first noun in a sentence.\") into distinct, separable representations, it concurrently builds conditional decoding algorithms and improves its ICL performance. We validate this phenomenon across pretrained models of varying scales (Gemma-2 2B/9B/27B, Llama-3.1 8B/70B) and over the course of pretraining in OLMo-7B. Further, we demonstrate that the quality of task encoding inferred from representations predicts ICL performance, and that, surprisingly, finetuning the earlier layers can improve the task encoding and performance more than finetuning the latter layers. Our empirical insights shed light into better understanding the success and failure modes of large language models via their representations. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "10l1pGeOcK@OpenReview",
      "index": 19,
      "title": "SAFE: Finding Sparse and Flat Minima to Improve Pruning",
      "authors": [
        "Dongyeop Lee",
        "Kwanhee Lee",
        "Jinseok Chung",
        "Namhoon Lee"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "safe",
        "pruning",
        "sparse",
        "finding",
        "flat",
        "minima",
        "sparsifying",
        "performance",
        "subnetworks",
        "optimization"
      ],
      "summary": "Sparsifying neural networks often suffers from seemingly inevitable performance degradation, and it remains challenging to restore the original performance despite much recent progress.Motivated by recent studies in robust optimization, we aim to tackle this problem by finding subnetworks that are both sparse and flat at the same time.Specifically, we formulate pruning as a sparsity-constrained optimization problem where flatness is encouraged as an objective.We solve it explicitly via an augmented Lagrange dual approach and extend it further by proposing a generalized projection operation, resulting in novel pruning methods called SAFE and its extension, SAFE + + .Extensive evaluations on standard image classification and language modeling tasks reveal that SAFE consistently yields sparse networks with improved generalization performance, which compares competitively to well-established baselines.In addition, SAFE demonstrates resilience to noisy data, making it well-suited for real-world conditions.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=10l1pGeOcK"
        ],
        "venue": [
          "/venue/10l1pGeOcK@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=10l1pGeOcK"
        ],
        "detail": [
          "https://openreview.net/forum?id=10l1pGeOcK"
        ]
      },
      "scores": {
        "pdf": 10,
        "kimi": 5
      },
      "raw_excerpt": "SAFE: Finding Sparse and Flat Minima to Improve Pruning [PDF 10 ] [Copy] [Kimi 5 ] [REL] Authors : Dongyeop Lee , Kwanhee Lee , Jinseok Chung , Namhoon Lee Sparsifying neural networks often suffers from seemingly inevitable performance degradation, and it remains challenging to restore the original performance despite much recent progress.Motivated by recent studies in robust optimization, we aim to tackle this problem by finding subnetworks that are both sparse and flat at the same time.Specifically, we formulate pruning as a sparsity-constrained optimization problem where flatness is encouraged as an objective.We solve it explicitly via an augmented Lagrange dual approach and extend it further by proposing a generalized projection operation, resulting in novel pruning methods called SAFE and its extension, SAFE + + .Extensive evaluations on standard image classification and language modeling tasks reveal that SAFE consistently yields sparse networks with improved generalization performance, which compares competitively to well-established baselines.In addition, SAFE demonstrates resilience to noisy data, making it well-suited for real-world conditions. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "1w0Zp99dnX@OpenReview",
      "index": 20,
      "title": "Generalized Random Forests Using Fixed-Point Trees",
      "authors": [
        "David Fleischer",
        "David A Stephens",
        "Archer Yang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "grfs",
        "forests",
        "generalized",
        "random",
        "fixed",
        "computationally",
        "alternative",
        "grf",
        "dimensions",
        "gradient"
      ],
      "summary": "We propose a computationally efficient alternative to generalized random forests (GRFs) for estimating heterogeneous effects in large dimensions. While GRFs rely on a gradient-based splitting criterion, which in large dimensions is computationally expensive and unstable, our method introduces a fixed-point approximation that eliminates the need for Jacobian estimation. This gradient-free approach preserves GRF’s theoretical guarantees of consistency and asymptotic normality while significantly improving computational efficiency. We demonstrate that our method achieves a speedup of multiple times over standard GRFs without compromising statistical accuracy. Experiments on both simulated and real-world data validate our approach. Our findings suggest that the proposed method is a scalable alternative for localized effect estimation in machine learning and causal inference applications.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=1w0Zp99dnX"
        ],
        "venue": [
          "/venue/1w0Zp99dnX@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=1w0Zp99dnX"
        ],
        "detail": [
          "https://openreview.net/forum?id=1w0Zp99dnX"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 3
      },
      "raw_excerpt": "Generalized Random Forests Using Fixed-Point Trees [PDF 3 ] [Copy] [Kimi 3 ] [REL] Authors : David Fleischer , David A Stephens , Archer Yang We propose a computationally efficient alternative to generalized random forests (GRFs) for estimating heterogeneous effects in large dimensions. While GRFs rely on a gradient-based splitting criterion, which in large dimensions is computationally expensive and unstable, our method introduces a fixed-point approximation that eliminates the need for Jacobian estimation. This gradient-free approach preserves GRF’s theoretical guarantees of consistency and asymptotic normality while significantly improving computational efficiency. We demonstrate that our method achieves a speedup of multiple times over standard GRFs without compromising statistical accuracy. Experiments on both simulated and real-world data validate our approach. Our findings suggest that the proposed method is a scalable alternative for localized effect estimation in machine learning and causal inference applications. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "2Oqm2IzTy9@OpenReview",
      "index": 21,
      "title": "Training Deep Learning Models with Norm-Constrained LMOs",
      "authors": [
        "Thomas Pethick",
        "Wanyun Xie",
        "Kimon Antonakopoulos",
        "Zhenyu Zhu",
        "Antonio Silveti-Falls",
        "Volkan Cevher"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "lmo",
        "lmos",
        "norm",
        "nanogpt",
        "optimization",
        "speedups",
        "adam",
        "training",
        "deep",
        "constrained"
      ],
      "summary": "In this work, we study optimization methods that leverage the linear minimization oracle (LMO) over a norm-ball. We propose a new stochastic family of algorithms that uses the LMO to adapt to the geometry of the problem and, perhaps surprisingly, show that they can be applied to unconstrained problems. The resulting update rule unifies several existing optimization methods under a single framework. Furthermore, we propose an explicit choice of norm for deep architectures, which, as a side benefit, leads to the transferability of hyperparameters across model sizes. Experimentally, we demonstrate significant speedups on nanoGPT training without any reliance on Adam. The proposed method is memory-efficient, requiring only one set of model weights and one set of gradients, which can be stored in half-precision.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=2Oqm2IzTy9"
        ],
        "venue": [
          "/venue/2Oqm2IzTy9@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=2Oqm2IzTy9"
        ],
        "detail": [
          "https://openreview.net/forum?id=2Oqm2IzTy9"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 5
      },
      "raw_excerpt": "Training Deep Learning Models with Norm-Constrained LMOs [PDF 5 ] [Copy] [Kimi 5 ] [REL] Authors : Thomas Pethick , Wanyun Xie , Kimon Antonakopoulos , Zhenyu Zhu , Antonio Silveti-Falls , Volkan Cevher In this work, we study optimization methods that leverage the linear minimization oracle (LMO) over a norm-ball. We propose a new stochastic family of algorithms that uses the LMO to adapt to the geometry of the problem and, perhaps surprisingly, show that they can be applied to unconstrained problems. The resulting update rule unifies several existing optimization methods under a single framework. Furthermore, we propose an explicit choice of norm for deep architectures, which, as a side benefit, leads to the transferability of hyperparameters across model sizes. Experimentally, we demonstrate significant speedups on nanoGPT training without any reliance on Adam. The proposed method is memory-efficient, requiring only one set of model weights and one set of gradients, which can be stored in half-precision. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "2PWn1LtCwP@OpenReview",
      "index": 22,
      "title": "Doubly Robust Conformalized Survival Analysis with Right-Censored Data",
      "authors": [
        "Matteo Sesia",
        "vladimir svetnik"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "survival",
        "censored",
        "conformalized",
        "censoring",
        "right",
        "imputes",
        "robust",
        "conformal",
        "doubly",
        "data"
      ],
      "summary": "We present a conformal inference method for constructing lower prediction bounds for survival times from right-censored data, extending recent approaches designed for more restrictive type-I censoring scenarios. The proposed method imputes unobserved censoring times using a machine learning model, and then analyzes the imputed data using a survival model calibrated via weighted conformal inference. This approach is theoretically supported by an asymptotic double robustness property. Empirical studies on simulated and real data demonstrate that our method leads to relatively informative predictive inferences and is especially robust in challenging settings where the survival model may be inaccurate.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=2PWn1LtCwP"
        ],
        "venue": [
          "/venue/2PWn1LtCwP@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=2PWn1LtCwP"
        ],
        "detail": [
          "https://openreview.net/forum?id=2PWn1LtCwP"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 5
      },
      "raw_excerpt": "Doubly Robust Conformalized Survival Analysis with Right-Censored Data [PDF 4 ] [Copy] [Kimi 5 ] [REL] Authors : Matteo Sesia , vladimir svetnik We present a conformal inference method for constructing lower prediction bounds for survival times from right-censored data, extending recent approaches designed for more restrictive type-I censoring scenarios. The proposed method imputes unobserved censoring times using a machine learning model, and then analyzes the imputed data using a survival model calibrated via weighted conformal inference. This approach is theoretically supported by an asymptotic double robustness property. Empirical studies on simulated and real data demonstrate that our method leads to relatively informative predictive inferences and is especially robust in challenging settings where the survival model may be inaccurate. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "2dz6psiiA0@OpenReview",
      "index": 23,
      "title": "Overcoming Multi-step Complexity in Multimodal Theory-of-Mind Reasoning: A Scalable Bayesian Planner",
      "authors": [
        "Chunhui Zhang",
        "Zhongyu Ouyang",
        "Kwonjoon Lee",
        "Nakul Agarwal",
        "Sean Houlihan",
        "Soroush Vosoughi",
        "Shao-Yuan Lo"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "tom",
        "bayesian",
        "multimodal",
        "mental",
        "mind",
        "planner",
        "complexity",
        "lms",
        "reasoning",
        "scalable"
      ],
      "summary": "Theory-of-mind (ToM) enables humans to infer mental states—such as beliefs, desires, and intentions—forming the foundation of social cognition. Existing computational ToM methods rely on structured workflows with ToM-specific priors or deep model fine-tuning but struggle with scalability in multimodal environments. They remain trapped within the gravitational pull of multi-step planning complexity, failing to generalize as task demands increase. To overcome these limitations, we propose a scalable Bayesian ToM planner. It breaks down ToM complexity into stepwise Bayesian updates. Meanwhile, weak-to-strong control specializes smaller LMs to refine ToM-specific likelihood estimation, transferring their ToM reasoning behavior to larger LMs (7B to 405B) for social and world knowledge integration. This synergistic approach enables scalability, aligning large-model inference with human mental states with Bayesian principles. Extensive experiments demonstrate a 4.6% improvement in accuracy over state-of-the-art methods on multimodal ToM benchmarks, including unseen scenarios, establishing a new standard for modeling human mental states in complex environments.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=2dz6psiiA0"
        ],
        "venue": [
          "/venue/2dz6psiiA0@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=2dz6psiiA0"
        ],
        "detail": [
          "https://openreview.net/forum?id=2dz6psiiA0"
        ]
      },
      "scores": {
        "pdf": 9,
        "kimi": 8
      },
      "raw_excerpt": "Overcoming Multi-step Complexity in Multimodal Theory-of-Mind Reasoning: A Scalable Bayesian Planner [PDF 9 ] [Copy] [Kimi 8 ] [REL] Authors : Chunhui Zhang , Zhongyu Ouyang , Kwonjoon Lee , Nakul Agarwal , Sean Houlihan , Soroush Vosoughi , Shao-Yuan Lo Theory-of-mind (ToM) enables humans to infer mental states—such as beliefs, desires, and intentions—forming the foundation of social cognition. Existing computational ToM methods rely on structured workflows with ToM-specific priors or deep model fine-tuning but struggle with scalability in multimodal environments. They remain trapped within the gravitational pull of multi-step planning complexity, failing to generalize as task demands increase. To overcome these limitations, we propose a scalable Bayesian ToM planner. It breaks down ToM complexity into stepwise Bayesian updates. Meanwhile, weak-to-strong control specializes smaller LMs to refine ToM-specific likelihood estimation, transferring their ToM reasoning behavior to larger LMs (7B to 405B) for social and world knowledge integration. This synergistic approach enables scalability, aligning large-model inference with human mental states with Bayesian principles. Extensive experiments demonstrate a 4.6% improvement in accuracy over state-of-the-art methods on multimodal ToM benchmarks, including unseen scenarios, establishing a new standard for modeling human mental states in complex environments. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "3Z827FtMNe@OpenReview",
      "index": 24,
      "title": "Great Models Think Alike and this Undermines AI Oversight",
      "authors": [
        "Shashwat Goel",
        "Joschka Strüber",
        "Ilze Amanda Auzina",
        "Karuna Chandra",
        "Ponnurangam Kumaraguru",
        "Douwe Kiela",
        "Ameya Pandurang Prabhu",
        "Matthias Bethge",
        "Jonas Geiping"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "oversight",
        "capa",
        "mistakes",
        "judge",
        "capabilities",
        "similarity",
        "model",
        "harder",
        "undermines",
        "alike"
      ],
      "summary": "As Language Model (LM) capabilities advance, evaluating and supervising them at scale is getting harder for humans. There is hope that other language models can automate both these tasks, which we refer to as *AI Oversight*. We study how model similarity affects both aspects of AI oversight by proposing *Chance Adjusted Probabilistic Agreement (CAPA)*--a metric for LM similarity based on overlap in model mistakes. Using CAPA, we first show that *LLM-as-a-judge* scores favor models similar to the judge, generalizing recent self-preference results. Then, we study training on LM annotations, and find complementary knowledge between the weak supervisor and strong student model plays a crucial role in gains from *weak-to-strong generalization*. As model capabilities increase, it becomes harder to find their mistakes, and we might defer more to AI oversight. However, we observe a concerning trend--model mistakes are becoming more similar with increasing capabilities, pointing to risks from correlated failures. Our work underscores the importance of reporting and correcting for model similarity, especially in the emerging paradigm of AI oversight.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=3Z827FtMNe"
        ],
        "venue": [
          "/venue/3Z827FtMNe@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=3Z827FtMNe"
        ],
        "detail": [
          "https://openreview.net/forum?id=3Z827FtMNe"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 7
      },
      "raw_excerpt": "Great Models Think Alike and this Undermines AI Oversight [PDF 5 ] [Copy] [Kimi 7 ] [REL] Authors : Shashwat Goel , Joschka Strüber , Ilze Amanda Auzina , Karuna Chandra , Ponnurangam Kumaraguru , Douwe Kiela , Ameya Pandurang Prabhu , Matthias Bethge , Jonas Geiping As Language Model (LM) capabilities advance, evaluating and supervising them at scale is getting harder for humans. There is hope that other language models can automate both these tasks, which we refer to as *AI Oversight*. We study how model similarity affects both aspects of AI oversight by proposing *Chance Adjusted Probabilistic Agreement (CAPA)*--a metric for LM similarity based on overlap in model mistakes. Using CAPA, we first show that *LLM-as-a-judge* scores favor models similar to the judge, generalizing recent self-preference results. Then, we study training on LM annotations, and find complementary knowledge between the weak supervisor and strong student model plays a crucial role in gains from *weak-to-strong generalization*. As model capabilities increase, it becomes harder to find their mistakes, and we might defer more to AI oversight. However, we observe a concerning trend--model mistakes are becoming more similar with increasing capabilities, pointing to risks from correlated failures. Our work underscores the importance of reporting and correcting for model similarity, especially in the emerging paradigm of AI oversight. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "3rB0bVU6z6@OpenReview",
      "index": 25,
      "title": "RE-Bench: Evaluating Frontier AI R&D Capabilities of Language Model Agents against Human Experts",
      "authors": [
        "Hjalmar Wijk",
        "Tao Lin",
        "Joel Becker",
        "Sami Jawhar",
        "Neev Parikh",
        "Thomas Broadley",
        "Lawrence Chan",
        "Michael Chen",
        "Joshua Clymer",
        "Jai Dhyani",
        "Elena Ericheva",
        "Katharyn Garcia",
        "Brian Goodrich",
        "Nikola Jurkovic",
        "Megan Kinniment",
        "Aron Lajko",
        "Seraphina Nix",
        "Lucas Jun Koba Sato",
        "William Saunders",
        "Maksym Taran",
        "Ben West",
        "Elizabeth Barnes"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "experts",
        "frontier",
        "bench",
        "human",
        "attempts",
        "hours",
        "agents",
        "budgets",
        "score",
        "agent"
      ],
      "summary": "Frontier AI safety policies highlight automation of AI research and development (R&D) by AI agents as an important capability to anticipate. However, there exist few evaluations for AI R&D capabilities, and none that are highly realistic and have a direct comparison to human performance. We introduce RE-Bench (Research Engineering Benchmark, V1), which consists of 7 challenging, open-ended ML research engineering environments and data from 71 8-hour attempts by 61 distinct human experts. We confirm that our experts make progress in the environments given 8 hours, with 82% of expert attempts achieving a non-zero score and 24% matching or exceeding our strong reference solutions. We compare humans to several public frontier models through best-of- k k with varying time budgets and agent designs, and find that the best AI agents achieve a score 4× higher than human experts when both are given a total time budget of 2 hours per environment. However, humans currently display better returns to increasing time budgets, narrowly exceeding the top AI agent scores given an 8-hour budget, and achieving 2× the score of the top AI agent when both are given 32 total hours (across different attempts).",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=3rB0bVU6z6"
        ],
        "venue": [
          "/venue/3rB0bVU6z6@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=3rB0bVU6z6"
        ],
        "detail": [
          "https://openreview.net/forum?id=3rB0bVU6z6"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "RE-Bench: Evaluating Frontier AI R&D Capabilities of Language Model Agents against Human Experts [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Hjalmar Wijk , Tao Lin , Joel Becker , Sami Jawhar , Neev Parikh , Thomas Broadley , Lawrence Chan , Michael Chen , Joshua Clymer , Jai Dhyani , Elena Ericheva , Katharyn Garcia , Brian Goodrich , Nikola Jurkovic , Megan Kinniment , Aron Lajko , Seraphina Nix , Lucas Jun Koba Sato , William Saunders , Maksym Taran , Ben West , Elizabeth Barnes Frontier AI safety policies highlight automation of AI research and development (R&D) by AI agents as an important capability to anticipate. However, there exist few evaluations for AI R&D capabilities, and none that are highly realistic and have a direct comparison to human performance. We introduce RE-Bench (Research Engineering Benchmark, V1), which consists of 7 challenging, open-ended ML research engineering environments and data from 71 8-hour attempts by 61 distinct human experts. We confirm that our experts make progress in the environments given 8 hours, with 82% of expert attempts achieving a non-zero score and 24% matching or exceeding our strong reference solutions. We compare humans to several public frontier models through best-of- k k with varying time budgets and agent designs, and find that the best AI agents achieve a score 4× higher than human experts when both are given a total time budget of 2 hours per environment. However, humans currently display better returns to increasing time budgets, narrowly exceeding the top AI agent scores given an 8-hour budget, and achieving 2× the score of the top AI agent when both are given 32 total hours (across different attempts). Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "4gWE7CMOlH@OpenReview",
      "index": 26,
      "title": "Soft Reasoning: Navigating Solution Spaces in Large Language Models through Controlled Embedding Exploration",
      "authors": [
        "Qinglin Zhu",
        "Runcong Zhao",
        "Hanqi Yan",
        "Yulan He",
        "Yudong Chen",
        "Lin Gui"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "reasoning",
        "embedding",
        "exploration",
        "soft",
        "controlled",
        "navigating",
        "search",
        "language",
        "optimises",
        "verifier"
      ],
      "summary": "Large Language Models (LLMs) struggle with complex reasoning due to limited diversity and inefficient search. We propose Soft Reasoning, an embedding-based search framework that optimises the embedding of the first token to guide generation. It combines (1) embedding perturbation for controlled exploration and (2) Bayesian optimisation to refine embeddings via a verifier-guided objective, balancing exploration and exploitation. This approach improves reasoning accuracy and coherence while avoiding reliance on heuristic search. Experiments demonstrate superior correctness with minimal computation, making it a scalable, model-agnostic solution.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=4gWE7CMOlH"
        ],
        "venue": [
          "/venue/4gWE7CMOlH@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=4gWE7CMOlH"
        ],
        "detail": [
          "https://openreview.net/forum?id=4gWE7CMOlH"
        ]
      },
      "scores": {
        "pdf": 20,
        "kimi": 16
      },
      "raw_excerpt": "Soft Reasoning: Navigating Solution Spaces in Large Language Models through Controlled Embedding Exploration [PDF 20 ] [Copy] [Kimi 16 ] [REL] Authors : Qinglin Zhu , Runcong Zhao , Hanqi Yan , Yulan He , Yudong Chen , Lin Gui Large Language Models (LLMs) struggle with complex reasoning due to limited diversity and inefficient search. We propose Soft Reasoning, an embedding-based search framework that optimises the embedding of the first token to guide generation. It combines (1) embedding perturbation for controlled exploration and (2) Bayesian optimisation to refine embeddings via a verifier-guided objective, balancing exploration and exploitation. This approach improves reasoning accuracy and coherence while avoiding reliance on heuristic search. Experiments demonstrate superior correctness with minimal computation, making it a scalable, model-agnostic solution. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "4qIP1sXcR1@OpenReview",
      "index": 27,
      "title": "ResQ: Mixed-Precision Quantization of Large Language Models with Low-Rank Residuals",
      "authors": [
        "Utkarsh Saxena",
        "Sayeh Sharify",
        "Kaushik Roy",
        "Xin Wang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "resq",
        "ptq",
        "quantization",
        "bit",
        "precision",
        "subspace",
        "mixed",
        "anonymous",
        "outliers",
        "spinquant"
      ],
      "summary": "Post-training quantization (PTQ) of large language models (LLMs) holds the promise in reducing the prohibitive computational cost at inference time. Quantization of all weight, activation and key-value (KV) cache tensors to 4-bit without significantly degrading generalizability is challenging, due to the high quantization error caused by extreme outliers in activations. To tackle this problem, we propose ResQ, a PTQ method that pushes further the state-of-the-art. By means of principal component analysis (PCA), it identifies a low-rank subspace (in practice 1/8 of the hidden dimension) in which activation variances are highest, and keep the coefficients within this subspace in high precision, e.g.~8-bit, while quantizing the rest to 4-bit. Within each subspace, invariant random rotation is applied to further suppress outliers. We show that this is a provably optimal mixed precision quantization scheme that minimizes error. With the Llama and Qwen2.5 families of models, we demonstrate that ResQ outperforms recent uniform and mixed precision PTQ methods on a variety of benchmarks, achieving up to 33\\% lower perplexity on Wikitext than the next best method SpinQuant, and upto 3X speedup over 16-bit baseline. Anonymous code repository available at https://anonymous.4open.science/r/project-resq-2142.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=4qIP1sXcR1"
        ],
        "venue": [
          "/venue/4qIP1sXcR1@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=4qIP1sXcR1"
        ],
        "detail": [
          "https://openreview.net/forum?id=4qIP1sXcR1"
        ]
      },
      "scores": {
        "pdf": 16,
        "kimi": 5
      },
      "raw_excerpt": "ResQ: Mixed-Precision Quantization of Large Language Models with Low-Rank Residuals [PDF 16 ] [Copy] [Kimi 5 ] [REL] Authors : Utkarsh Saxena , Sayeh Sharify , Kaushik Roy , Xin Wang Post-training quantization (PTQ) of large language models (LLMs) holds the promise in reducing the prohibitive computational cost at inference time. Quantization of all weight, activation and key-value (KV) cache tensors to 4-bit without significantly degrading generalizability is challenging, due to the high quantization error caused by extreme outliers in activations. To tackle this problem, we propose ResQ, a PTQ method that pushes further the state-of-the-art. By means of principal component analysis (PCA), it identifies a low-rank subspace (in practice 1/8 of the hidden dimension) in which activation variances are highest, and keep the coefficients within this subspace in high precision, e.g.~8-bit, while quantizing the rest to 4-bit. Within each subspace, invariant random rotation is applied to further suppress outliers. We show that this is a provably optimal mixed precision quantization scheme that minimizes error. With the Llama and Qwen2.5 families of models, we demonstrate that ResQ outperforms recent uniform and mixed precision PTQ methods on a variety of benchmarks, achieving up to 33\\% lower perplexity on Wikitext than the next best method SpinQuant, and upto 3X speedup over 16-bit baseline. Anonymous code repository available at https://anonymous.4open.science/r/project-resq-2142. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "4vAa0A98xI@OpenReview",
      "index": 28,
      "title": "CoPINN: Cognitive Physics-Informed Neural Networks",
      "authors": [
        "Siyuan Duan",
        "Wenyuan Wu",
        "Peng Hu",
        "Zhenwen Ren",
        "Dezhong Peng",
        "Yuan Sun"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "copinn",
        "cognitive",
        "informed",
        "pinn",
        "physical",
        "easy",
        "hard",
        "physics",
        "upp",
        "regions"
      ],
      "summary": "Physics-informed neural networks (PINNs) aim to constrain the outputs and gradients of deep learning models to satisfy specified governing physics equations, which have demonstrated significant potential for solving partial differential equations (PDEs). Although existing PINN methods have achieved pleasing performance, they always treat both easy and hard sample points indiscriminately, especially ones in the physical boundaries. This easily causes the PINN model to fall into undesirable local minima and unstable learning, thereby resulting in an Unbalanced Prediction Problem (UPP). To deal with this daunting problem, we propose a novel framework named Cognitive Physical Informed Neural Network (CoPINN) that imitates the human cognitive learning manner from easy to hard. Specifically, we first employ separable subnetworks to encode independent one-dimensional coordinates and apply an aggregation scheme to generate multi-dimensional predicted physical variables. Then, during the training phase, we dynamically evaluate the difficulty of each sample according to the gradient of the PDE residuals. Finally, we propose a cognitive training scheduler to progressively optimize the entire sampling regions from easy to hard, thereby embracing robustness and generalization against predicting physical boundary regions. Extensive experiments demonstrate that our CoPINN achieves state-of-the-art performance, particularly significantly reducing prediction errors in stubborn regions.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=4vAa0A98xI"
        ],
        "venue": [
          "/venue/4vAa0A98xI@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=4vAa0A98xI"
        ],
        "detail": [
          "https://openreview.net/forum?id=4vAa0A98xI"
        ]
      },
      "scores": {
        "pdf": 17,
        "kimi": 4
      },
      "raw_excerpt": "CoPINN: Cognitive Physics-Informed Neural Networks [PDF 17 ] [Copy] [Kimi 4 ] [REL] Authors : Siyuan Duan , Wenyuan Wu , Peng Hu , Zhenwen Ren , Dezhong Peng , Yuan Sun Physics-informed neural networks (PINNs) aim to constrain the outputs and gradients of deep learning models to satisfy specified governing physics equations, which have demonstrated significant potential for solving partial differential equations (PDEs). Although existing PINN methods have achieved pleasing performance, they always treat both easy and hard sample points indiscriminately, especially ones in the physical boundaries. This easily causes the PINN model to fall into undesirable local minima and unstable learning, thereby resulting in an Unbalanced Prediction Problem (UPP). To deal with this daunting problem, we propose a novel framework named Cognitive Physical Informed Neural Network (CoPINN) that imitates the human cognitive learning manner from easy to hard. Specifically, we first employ separable subnetworks to encode independent one-dimensional coordinates and apply an aggregation scheme to generate multi-dimensional predicted physical variables. Then, during the training phase, we dynamically evaluate the difficulty of each sample according to the gradient of the PDE residuals. Finally, we propose a cognitive training scheduler to progressively optimize the entire sampling regions from easy to hard, thereby embracing robustness and generalization against predicting physical boundary regions. Extensive experiments demonstrate that our CoPINN achieves state-of-the-art performance, particularly significantly reducing prediction errors in stubborn regions. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "4yHWV3B6g4@OpenReview",
      "index": 29,
      "title": "Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models",
      "authors": [
        "Ulzee An",
        "Moonseong Jeong",
        "Simon Lee",
        "Aditya Gorla",
        "Yuzhe Yang",
        "Sriram Sankararaman"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "raptor",
        "volumes",
        "medical",
        "pretrained",
        "foundation",
        "volumetric",
        "voco",
        "train",
        "embeddings",
        "tokens"
      ],
      "summary": "Current challenges in developing foundational models for volumetric imaging data, such as magnetic resonance imaging (MRI), stem from the computational complexity of state-of-the-art architectures in high dimensions and curating sufficiently large datasets of volumes.To address these challenges, we introduce Raptor (Random Planar Tensor Reduction), a train-free method for generating semantically rich embeddings for volumetric data. Raptor leverages a frozen 2D foundation model, pretrained on natural images, to extract visual tokens from individual cross-sections of medical volumes. These tokens are then spatially compressed using random projections, significantly reducing computational complexity while retaining rich semantic information. Extensive experiments on 10 diverse medical volume tasks verify the superior performance of Raptor over state-of-the-art methods, including those pretrained exclusively on medical volumes (+3 SuPreM, +6 MISFM, +10 Merlin, +13 VoCo, and +14 SLIViT), while entirely bypassing the need for costly training. Our results highlight Raptor's effectiveness and versatility as a foundation for advancing deep learning-based methods for medical volumes (code: github.com/sriramlab/raptor).",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=4yHWV3B6g4"
        ],
        "venue": [
          "/venue/4yHWV3B6g4@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=4yHWV3B6g4"
        ],
        "detail": [
          "https://openreview.net/forum?id=4yHWV3B6g4"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 3
      },
      "raw_excerpt": "Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models [PDF 5 ] [Copy] [Kimi 3 ] [REL] Authors : Ulzee An , Moonseong Jeong , Simon Lee , Aditya Gorla , Yuzhe Yang , Sriram Sankararaman Current challenges in developing foundational models for volumetric imaging data, such as magnetic resonance imaging (MRI), stem from the computational complexity of state-of-the-art architectures in high dimensions and curating sufficiently large datasets of volumes.To address these challenges, we introduce Raptor (Random Planar Tensor Reduction), a train-free method for generating semantically rich embeddings for volumetric data. Raptor leverages a frozen 2D foundation model, pretrained on natural images, to extract visual tokens from individual cross-sections of medical volumes. These tokens are then spatially compressed using random projections, significantly reducing computational complexity while retaining rich semantic information. Extensive experiments on 10 diverse medical volume tasks verify the superior performance of Raptor over state-of-the-art methods, including those pretrained exclusively on medical volumes (+3 SuPreM, +6 MISFM, +10 Merlin, +13 VoCo, and +14 SLIViT), while entirely bypassing the need for costly training. Our results highlight Raptor's effectiveness and versatility as a foundation for advancing deep learning-based methods for medical volumes (code: github.com/sriramlab/raptor). Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "5IpVe9PH14@OpenReview",
      "index": 30,
      "title": "Catoni Contextual Bandits are Robust to Heavy-tailed Rewards",
      "authors": [
        "Chenlu Ye",
        "Yujia Jin",
        "Alekh Agarwal",
        "Tong Zhang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "variance",
        "rewards",
        "catoni",
        "reward",
        "contextual",
        "regret",
        "bandits",
        "tailed",
        "bound",
        "range"
      ],
      "summary": "Typical contextual bandit algorithms assume that the rewards at each round lie in some fixed range [ 0 , R ] [ 0 , R ] , and their regret scales polynomially with this reward range R R . However, many practical scenarios naturally involve heavy-tailed rewards or rewards where the worst-case range can be substantially larger than the variance. In this paper, we develop an algorithmic approach building on Catoni's estimator from robust statistics, and apply it to contextual bandits with general function approximation. When the variance of the reward at each round is known, we use a variance-weighted regression approach and establish a regret bound that depends only on the cumulative reward variance and logarithmically on the reward range R R as well as the number of rounds T T . For the unknown-variance case, we further propose a careful peeling-based algorithm and remove the need for cumbersome variance estimation. With additional dependence on the fourth moment, our algorithm also enjoys a variance-based bound with logarithmic reward-range dependence. Moreover, we demonstrate the optimality of the leading-order term in our regret bound through a matching lower bound.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=5IpVe9PH14"
        ],
        "venue": [
          "/venue/5IpVe9PH14@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=5IpVe9PH14"
        ],
        "detail": [
          "https://openreview.net/forum?id=5IpVe9PH14"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 5
      },
      "raw_excerpt": "Catoni Contextual Bandits are Robust to Heavy-tailed Rewards [PDF 5 ] [Copy] [Kimi 5 ] [REL] Authors : Chenlu Ye , Yujia Jin , Alekh Agarwal , Tong Zhang Typical contextual bandit algorithms assume that the rewards at each round lie in some fixed range [ 0 , R ] [ 0 , R ] , and their regret scales polynomially with this reward range R R . However, many practical scenarios naturally involve heavy-tailed rewards or rewards where the worst-case range can be substantially larger than the variance. In this paper, we develop an algorithmic approach building on Catoni's estimator from robust statistics, and apply it to contextual bandits with general function approximation. When the variance of the reward at each round is known, we use a variance-weighted regression approach and establish a regret bound that depends only on the cumulative reward variance and logarithmically on the reward range R R as well as the number of rounds T T . For the unknown-variance case, we further propose a careful peeling-based algorithm and remove the need for cumbersome variance estimation. With additional dependence on the fourth moment, our algorithm also enjoys a variance-based bound with logarithmic reward-range dependence. Moreover, we demonstrate the optimality of the leading-order term in our regret bound through a matching lower bound. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "5hZCK4Wbex@OpenReview",
      "index": 31,
      "title": "Everything Everywhere All at Once: LLMs can In-Context Learn Multiple Tasks in Superposition",
      "authors": [
        "Zheyang Xiong",
        "Jack Cai",
        "John Cooper",
        "Albert Ge",
        "Vasilis Papageorgiou",
        "Zack Sifakis",
        "Angeliki Giannou",
        "Ziqian Lin",
        "Liu Yang",
        "Saurabh Agarwal",
        "Grigorios Chrysos",
        "Samet Oymak",
        "Kangwook Lee",
        "Dimitris Papailiopoulos"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "llms",
        "icl",
        "superposition",
        "task",
        "phenomenon",
        "context",
        "tasks",
        "everything",
        "everywhere",
        "learn"
      ],
      "summary": "Large Language Models (LLMs) have demonstrated remarkable in-context learning (ICL) capabilities. In this study, we explore a surprising phenomenon related to ICL: LLMs can perform multiple, computationally distinct ICL tasks simultaneously, during a single inference call, a capability we term task superposition\". We provide empirical evidence of this phenomenon across various LLM families and scales and show that this phenomenon emerges even if we train the model to in-context learn one task at a time. We offer theoretical explanations that this capability is well within the expressive power of transformers. We also explore how LLMs internally compose task vectors during superposition. Furthermore, we show that larger models can solve more ICL tasks in parallel, and better calibrate their output distribution. Our findings offer insights into the latent capabilities of LLMs, further substantiate the perspective of \"LLMs as superposition of simulators\", and raise questions about the mechanisms enabling simultaneous task execution.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=5hZCK4Wbex"
        ],
        "venue": [
          "/venue/5hZCK4Wbex@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=5hZCK4Wbex"
        ],
        "detail": [
          "https://openreview.net/forum?id=5hZCK4Wbex"
        ]
      },
      "scores": {
        "pdf": 9,
        "kimi": 11
      },
      "raw_excerpt": "Everything Everywhere All at Once: LLMs can In-Context Learn Multiple Tasks in Superposition [PDF 9 ] [Copy] [Kimi 11 ] [REL] Authors : Zheyang Xiong , Jack Cai , John Cooper , Albert Ge , Vasilis Papageorgiou , Zack Sifakis , Angeliki Giannou , Ziqian Lin , Liu Yang , Saurabh Agarwal , Grigorios Chrysos , Samet Oymak , Kangwook Lee , Dimitris Papailiopoulos Large Language Models (LLMs) have demonstrated remarkable in-context learning (ICL) capabilities. In this study, we explore a surprising phenomenon related to ICL: LLMs can perform multiple, computationally distinct ICL tasks simultaneously, during a single inference call, a capability we term task superposition\". We provide empirical evidence of this phenomenon across various LLM families and scales and show that this phenomenon emerges even if we train the model to in-context learn one task at a time. We offer theoretical explanations that this capability is well within the expressive power of transformers. We also explore how LLMs internally compose task vectors during superposition. Furthermore, we show that larger models can solve more ICL tasks in parallel, and better calibrate their output distribution. Our findings offer insights into the latent capabilities of LLMs, further substantiate the perspective of \"LLMs as superposition of simulators\", and raise questions about the mechanisms enabling simultaneous task execution. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "5hyfZ2jYfI@OpenReview",
      "index": 32,
      "title": "The Synergy of LLMs & RL Unlocks Offline Learning of Generalizable Language-Conditioned Policies with Low-fidelity Data",
      "authors": [
        "Thomas Pouplin",
        "Katarzyna Kobalczyk",
        "Hao Sun",
        "M van der Schaar"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "teduo",
        "language",
        "offline",
        "conditioned",
        "textit",
        "llms",
        "generalizable",
        "policies",
        "unlocks",
        "synergy"
      ],
      "summary": "Developing autonomous agents capable of performing complex, multi-step decision-making tasks specified in natural language remains a significant challenge, particularly in realistic settings where labeled data is scarce and real-time experimentation is impractical. Existing reinforcement learning (RL) approaches often struggle to generalize to unseen goals and states, limiting their applicability. In this paper, we introduce TEDUO TEDUO , a novel training pipeline for offline language-conditioned policy learning in symbolic environments. Unlike conventional methods, TEDUO TEDUO operates on readily available, unlabeled datasets and addresses the challenge of generalization to previously unseen goals and states. Our approach harnesses large language models (LLMs) in a dual capacity: first, as automatization tools augmenting offline datasets with richer annotations, and second, as generalizable instruction-following agents. Empirical results demonstrate that TEDUO TEDUO achieves data-efficient learning of robust language-conditioned policies, accomplishing tasks beyond the reach of conventional RL frameworks or out-of-the-box LLMs alone.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=5hyfZ2jYfI"
        ],
        "venue": [
          "/venue/5hyfZ2jYfI@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=5hyfZ2jYfI"
        ],
        "detail": [
          "https://openreview.net/forum?id=5hyfZ2jYfI"
        ]
      },
      "scores": {
        "pdf": 10,
        "kimi": 4
      },
      "raw_excerpt": "The Synergy of LLMs & RL Unlocks Offline Learning of Generalizable Language-Conditioned Policies with Low-fidelity Data [PDF 10 ] [Copy] [Kimi 4 ] [REL] Authors : Thomas Pouplin , Katarzyna Kobalczyk , Hao Sun , M van der Schaar Developing autonomous agents capable of performing complex, multi-step decision-making tasks specified in natural language remains a significant challenge, particularly in realistic settings where labeled data is scarce and real-time experimentation is impractical. Existing reinforcement learning (RL) approaches often struggle to generalize to unseen goals and states, limiting their applicability. In this paper, we introduce TEDUO TEDUO , a novel training pipeline for offline language-conditioned policy learning in symbolic environments. Unlike conventional methods, TEDUO TEDUO operates on readily available, unlabeled datasets and addresses the challenge of generalization to previously unseen goals and states. Our approach harnesses large language models (LLMs) in a dual capacity: first, as automatization tools augmenting offline datasets with richer annotations, and second, as generalizable instruction-following agents. Empirical results demonstrate that TEDUO TEDUO achieves data-efficient learning of robust language-conditioned policies, accomplishing tasks beyond the reach of conventional RL frameworks or out-of-the-box LLMs alone. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "6gX4rP6QJW@OpenReview",
      "index": 33,
      "title": "Self-supervised Masked Graph Autoencoder via Structure-aware Curriculum",
      "authors": [
        "Haoyang Li",
        "Xin Wang",
        "Zeyang Zhang",
        "Zongyuan Wu",
        "Linxin Xiao",
        "Wenwu Zhu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "masked",
        "graph",
        "edges",
        "curriculum",
        "difficulty",
        "self",
        "autoencoder",
        "node",
        "supervised",
        "pretext"
      ],
      "summary": "Self-supervised learning (SSL) on graph-structured data has attracted considerable attention recently. Masked graph autoencoder, as one promising generative graph SSL approach that aims to recover masked parts of the input graph data, has shown great success in various downstream graph tasks. However, existing masked graph autoencoders fail to consider the degree of difficulty of recovering the masked edges that often have different impacts on the model performance, resulting in suboptimal node representations. To tackle this challenge, in this paper, we propose a novel curriculum based self-supervised masked graph autoencoder that is able to capture and leverage the underlying degree of difficulty of data dependencies hidden in edges, and design better mask-reconstruction pretext tasks for learning informative node representations. Specifically, we first design a difficulty measurer to identify the underlying structural degree of difficulty of edges during the masking step. Then, we adopt a self-paced scheduler to determine the order of masking edges, which encourages the graph encoder to learn from easy to difficult parts. Finally, the masked edges are gradually incorporated into the reconstruction pretext task, leading to high-quality node representations. Experiments on several real-world node classification and link prediction datasets demonstrate the superiority of our proposed method over state-of-the-art graph self-supervised learning baselines. This work is the first study of curriculum strategy for masked graph autoencoders, to the best of our knowledge.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=6gX4rP6QJW"
        ],
        "venue": [
          "/venue/6gX4rP6QJW@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=6gX4rP6QJW"
        ],
        "detail": [
          "https://openreview.net/forum?id=6gX4rP6QJW"
        ]
      },
      "scores": {
        "pdf": 10,
        "kimi": 4
      },
      "raw_excerpt": "Self-supervised Masked Graph Autoencoder via Structure-aware Curriculum [PDF 10 ] [Copy] [Kimi 4 ] [REL] Authors : Haoyang Li , Xin Wang , Zeyang Zhang , Zongyuan Wu , Linxin Xiao , Wenwu Zhu Self-supervised learning (SSL) on graph-structured data has attracted considerable attention recently. Masked graph autoencoder, as one promising generative graph SSL approach that aims to recover masked parts of the input graph data, has shown great success in various downstream graph tasks. However, existing masked graph autoencoders fail to consider the degree of difficulty of recovering the masked edges that often have different impacts on the model performance, resulting in suboptimal node representations. To tackle this challenge, in this paper, we propose a novel curriculum based self-supervised masked graph autoencoder that is able to capture and leverage the underlying degree of difficulty of data dependencies hidden in edges, and design better mask-reconstruction pretext tasks for learning informative node representations. Specifically, we first design a difficulty measurer to identify the underlying structural degree of difficulty of edges during the masking step. Then, we adopt a self-paced scheduler to determine the order of masking edges, which encourages the graph encoder to learn from easy to difficult parts. Finally, the masked edges are gradually incorporated into the reconstruction pretext task, leading to high-quality node representations. Experiments on several real-world node classification and link prediction datasets demonstrate the superiority of our proposed method over state-of-the-art graph self-supervised learning baselines. This work is the first study of curriculum strategy for masked graph autoencoders, to the best of our knowledge. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "71Mm8GDGYd@OpenReview",
      "index": 34,
      "title": "K 2 K 2 VAE: A Koopman-Kalman Enhanced Variational AutoEncoder for Probabilistic Time Series Forecasting",
      "authors": [
        "Xingjian Wu",
        "Xiangfei Qiu",
        "Hongfan Gao",
        "Jilin Hu",
        "Bin Yang",
        "Chenjuan Guo"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "forecasting",
        "vae",
        "ptsf",
        "series",
        "probabilistic",
        "term",
        "excell",
        "kalmannet",
        "koopman",
        "kalman"
      ],
      "summary": "Probabilistic Time Series Forecasting (PTSF) plays a crucial role in decision-making across various fields, including economics, energy, and transportation. Most existing methods excell at short-term forecasting, while overlooking the hurdles of Long-term Probabilistic Time Series Forecasting (LPTSF). As the forecast horizon extends, the inherent nonlinear dynamics have a significant adverse effect on prediction accuracy, and make generative models inefficient by increasing the cost of each iteration. To overcome these limitations, we introduce K 2 K 2 VAE, an efficient VAE-based generative model that leverages a KoopmanNet to transform nonlinear time series into a linear dynamical system, and devises a KalmanNet to refine predictions and model uncertainty in such linear system, which reduces error accumulation in long-term forecasting. Extensive experiments demonstrate that K 2 K 2 VAE outperforms state-of-the-art methods in both short- and long-term PTSF, providing a more efficient and accurate solution.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=71Mm8GDGYd"
        ],
        "venue": [
          "/venue/71Mm8GDGYd@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=71Mm8GDGYd"
        ],
        "detail": [
          "https://openreview.net/forum?id=71Mm8GDGYd"
        ]
      },
      "scores": {
        "pdf": 12,
        "kimi": 4
      },
      "raw_excerpt": "K 2 K 2 VAE: A Koopman-Kalman Enhanced Variational AutoEncoder for Probabilistic Time Series Forecasting [PDF 12 ] [Copy] [Kimi 4 ] [REL] Authors : Xingjian Wu , Xiangfei Qiu , Hongfan Gao , Jilin Hu , Bin Yang , Chenjuan Guo Probabilistic Time Series Forecasting (PTSF) plays a crucial role in decision-making across various fields, including economics, energy, and transportation. Most existing methods excell at short-term forecasting, while overlooking the hurdles of Long-term Probabilistic Time Series Forecasting (LPTSF). As the forecast horizon extends, the inherent nonlinear dynamics have a significant adverse effect on prediction accuracy, and make generative models inefficient by increasing the cost of each iteration. To overcome these limitations, we introduce K 2 K 2 VAE, an efficient VAE-based generative model that leverages a KoopmanNet to transform nonlinear time series into a linear dynamical system, and devises a KalmanNet to refine predictions and model uncertainty in such linear system, which reduces error accumulation in long-term forecasting. Extensive experiments demonstrate that K 2 K 2 VAE outperforms state-of-the-art methods in both short- and long-term PTSF, providing a more efficient and accurate solution. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "73mDARqOtQ@OpenReview",
      "index": 35,
      "title": "RAPID: Long-Context Inference with Retrieval-Augmented Speculative Decoding",
      "authors": [
        "Guanzheng Chen",
        "Qilong Feng",
        "Jinjie Ni",
        "Xin Li",
        "Michael Shieh"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "rag",
        "context",
        "speculative",
        "drafters",
        "rapid",
        "retrieval",
        "inference",
        "long",
        "decoding",
        "llms"
      ],
      "summary": "The emergence of long-context large language models (LLMs) offers a promising alternative to traditional retrieval-augmented generation (RAG) for processing extensive documents. However, the computational overhead of long-context inference presents significant efficiency challenges. While Speculative Decoding (SD) traditionally accelerates inference using smaller draft models, its effectiveness diminishes substantially in long-context scenarios due to memory-bound KV cache operations. We introduce Retrieval-Augmented Speculative Decoding (RAPID), which leverages RAG for both accelerating and enhancing generation quality in long-context inference. RAPID introduces the RAG drafter—a draft LLM operating on shortened retrieval contexts—to speculate on the generation of long-context target LLMs. Our approach enables a new paradigm where same-scale or even larger LLMs can serve as RAG drafters while maintaining computational efficiency. To fully leverage the potentially superior capabilities from stronger RAG drafters, we develop an inference-time knowledge transfer that enriches the target distribution by RAG. Extensive experiments on the LLaMA-3.1 and Qwen2.5 backbones demonstrate that RAPID effectively integrates the strengths of both RAG and long-context LLMs, achieving significant performance improvements (e.g., from 39.33 to 42.83 on InfiniteBench for LLaMA-3.1-8B) with more than 2 × × speedups for long-context inference. Our analyses also reveal the robustness of RAPID across various context lengths and retrieval quality.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=73mDARqOtQ"
        ],
        "venue": [
          "/venue/73mDARqOtQ@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=73mDARqOtQ"
        ],
        "detail": [
          "https://openreview.net/forum?id=73mDARqOtQ"
        ]
      },
      "scores": {
        "pdf": 16,
        "kimi": 20
      },
      "raw_excerpt": "RAPID: Long-Context Inference with Retrieval-Augmented Speculative Decoding [PDF 16 ] [Copy] [Kimi 20 ] [REL] Authors : Guanzheng Chen , Qilong Feng , Jinjie Ni , Xin Li , Michael Shieh The emergence of long-context large language models (LLMs) offers a promising alternative to traditional retrieval-augmented generation (RAG) for processing extensive documents. However, the computational overhead of long-context inference presents significant efficiency challenges. While Speculative Decoding (SD) traditionally accelerates inference using smaller draft models, its effectiveness diminishes substantially in long-context scenarios due to memory-bound KV cache operations. We introduce Retrieval-Augmented Speculative Decoding (RAPID), which leverages RAG for both accelerating and enhancing generation quality in long-context inference. RAPID introduces the RAG drafter—a draft LLM operating on shortened retrieval contexts—to speculate on the generation of long-context target LLMs. Our approach enables a new paradigm where same-scale or even larger LLMs can serve as RAG drafters while maintaining computational efficiency. To fully leverage the potentially superior capabilities from stronger RAG drafters, we develop an inference-time knowledge transfer that enriches the target distribution by RAG. Extensive experiments on the LLaMA-3.1 and Qwen2.5 backbones demonstrate that RAPID effectively integrates the strengths of both RAG and long-context LLMs, achieving significant performance improvements (e.g., from 39.33 to 42.83 on InfiniteBench for LLaMA-3.1-8B) with more than 2 × × speedups for long-context inference. Our analyses also reveal the robustness of RAPID across various context lengths and retrieval quality. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "8JGwoZceQs@OpenReview",
      "index": 36,
      "title": "Robust Noise Attenuation via Adaptive Pooling of Transformer Outputs",
      "authors": [
        "Greyson Brothers"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "pooling",
        "outputs",
        "snr",
        "transformer",
        "signal",
        "avgpool",
        "noise",
        "adaptive",
        "maxpool",
        "attenuation"
      ],
      "summary": "We investigate the design of pooling methods used to summarize the outputs of transformer embedding models, primarily motivated by reinforcement learning and vision applications. This work considers problems where a subset of the input vectors contains requisite information for a downstream task (signal) while the rest are distractors (noise). By framing pooling as vector quantization with the goal of minimizing signal loss, we demonstrate that the standard methods used to aggregate transformer outputs, AvgPool, MaxPool, and ClsToken, are vulnerable to performance collapse as the signal-to-noise ratio (SNR) of inputs fluctuates. We then show that an attention-based *adaptive pooling* method can approximate the signal-optimal vector quantizer within derived error bounds for any SNR. Our theoretical results are first validated by supervised experiments on a synthetic dataset designed to isolate the SNR problem, then generalized to standard relational reasoning, multi-agent reinforcement learning, and vision benchmarks with noisy observations, where transformers with adaptive pooling display superior robustness across tasks.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=8JGwoZceQs"
        ],
        "venue": [
          "/venue/8JGwoZceQs@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=8JGwoZceQs"
        ],
        "detail": [
          "https://openreview.net/forum?id=8JGwoZceQs"
        ]
      },
      "scores": {
        "pdf": 15,
        "kimi": 7
      },
      "raw_excerpt": "Robust Noise Attenuation via Adaptive Pooling of Transformer Outputs [PDF 15 ] [Copy] [Kimi 7 ] [REL] Author : Greyson Brothers We investigate the design of pooling methods used to summarize the outputs of transformer embedding models, primarily motivated by reinforcement learning and vision applications. This work considers problems where a subset of the input vectors contains requisite information for a downstream task (signal) while the rest are distractors (noise). By framing pooling as vector quantization with the goal of minimizing signal loss, we demonstrate that the standard methods used to aggregate transformer outputs, AvgPool, MaxPool, and ClsToken, are vulnerable to performance collapse as the signal-to-noise ratio (SNR) of inputs fluctuates. We then show that an attention-based *adaptive pooling* method can approximate the signal-optimal vector quantizer within derived error bounds for any SNR. Our theoretical results are first validated by supervised experiments on a synthetic dataset designed to isolate the SNR problem, then generalized to standard relational reasoning, multi-agent reinforcement learning, and vision benchmarks with noisy observations, where transformers with adaptive pooling display superior robustness across tasks. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "9hFQvmCl7P@OpenReview",
      "index": 37,
      "title": "FedSSI: Rehearsal-Free Continual Federated Learning with Synergistic Synaptic Intelligence",
      "authors": [
        "Yichen Li",
        "Yuying Wang",
        "Haozhao Wang",
        "Yining Qi",
        "Tianzhe Xiao",
        "Ruixuan Li"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "cfl",
        "rehearsal",
        "fedssi",
        "synaptic",
        "regularization",
        "continual",
        "intelligence",
        "federated",
        "data",
        "synergistic"
      ],
      "summary": "Continual Federated Learning (CFL) allows distributed devices to collaboratively learn novel concepts from continuously shifting training data while avoiding \\textit{knowledge forgetting} of previously seen tasks. To tackle this challenge, most current CFL approaches rely on extensive rehearsal of previous data. Despite effectiveness, rehearsal comes at a cost to memory, and it may also violate data privacy. Considering these, we seek to apply regularization techniques to CFL by considering their cost-efficient properties that do not require sample caching or rehearsal. Specifically, we first apply traditional regularization techniques to CFL and observe that existing regularization techniques, especially synaptic intelligence, can achieve promising results under homogeneous data distribution but fail when the data is heterogeneous. Based on this observation, we propose a simple yet effective regularization algorithm for CFL named \\textbf{FedSSI}, which tailors the synaptic intelligence for the CFL with heterogeneous data settings. FedSSI can not only reduce computational overhead without rehearsal but also address the data heterogeneity issue. Extensive experiments show that FedSSI achieves superior performance compared to state-of-the-art methods.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=9hFQvmCl7P"
        ],
        "venue": [
          "/venue/9hFQvmCl7P@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=9hFQvmCl7P"
        ],
        "detail": [
          "https://openreview.net/forum?id=9hFQvmCl7P"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 4
      },
      "raw_excerpt": "FedSSI: Rehearsal-Free Continual Federated Learning with Synergistic Synaptic Intelligence [PDF 4 ] [Copy] [Kimi 4 ] [REL] Authors : Yichen Li , Yuying Wang , Haozhao Wang , Yining Qi , Tianzhe Xiao , Ruixuan Li Continual Federated Learning (CFL) allows distributed devices to collaboratively learn novel concepts from continuously shifting training data while avoiding \\textit{knowledge forgetting} of previously seen tasks. To tackle this challenge, most current CFL approaches rely on extensive rehearsal of previous data. Despite effectiveness, rehearsal comes at a cost to memory, and it may also violate data privacy. Considering these, we seek to apply regularization techniques to CFL by considering their cost-efficient properties that do not require sample caching or rehearsal. Specifically, we first apply traditional regularization techniques to CFL and observe that existing regularization techniques, especially synaptic intelligence, can achieve promising results under homogeneous data distribution but fail when the data is heterogeneous. Based on this observation, we propose a simple yet effective regularization algorithm for CFL named \\textbf{FedSSI}, which tailors the synaptic intelligence for the CFL with heterogeneous data settings. FedSSI can not only reduce computational overhead without rehearsal but also address the data heterogeneity issue. Extensive experiments show that FedSSI achieves superior performance compared to state-of-the-art methods. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "9hd5WA6QCn@OpenReview",
      "index": 38,
      "title": "MODA: MOdular Duplex Attention for Multimodal Perception, Cognition, and Emotion Understanding",
      "authors": [
        "Zhicheng Zhang",
        "Wuyou Xia",
        "Chenxi Zhao",
        "Zhou Yan",
        "Xiaoqiang Liu",
        "Yongjie Zhu",
        "Wenyu Qin",
        "Pengfei Wan",
        "Di ZHANG",
        "Jufeng Yang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "moda",
        "attention",
        "duplex",
        "multimodal",
        "cognition",
        "emotion",
        "modality",
        "perception",
        "modal",
        "modular"
      ],
      "summary": "Multimodal large language models (MLLMs) recently showed strong capacity in integrating data among multiple modalities, empowered by generalizable attention architecture. Advanced methods predominantly focus on language-centric tuning while less exploring multimodal tokens mixed through attention, posing challenges in high-level tasks that require fine-grained cognition and emotion understanding. In this work, we identify the attention deficit disorder problem in multimodal learning, caused by inconsistent cross-modal attention and layer-by-layer decayed attention activation. To address this, we propose a novel attention mechanism, termed MOdular Duplex Attention (MODA), simultaneously conducting the inner-modal refinement and inter-modal interaction. MODA employs a correct-after-align strategy to effectively decouple modality alignment from cross-layer token mixing. In the alignment phase, tokens are mapped to duplex modality spaces based on the basis vectors, enabling the interaction between visual and language modality. Further, the correctness of attention scores is ensured through adaptive masked attention, which enhances the model's flexibility by allowing customizable masking patterns for different modalities. Extensive experiments on 21 benchmark datasets verify the effectiveness of MODA in perception, cognition, and emotion tasks.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=9hd5WA6QCn"
        ],
        "venue": [
          "/venue/9hd5WA6QCn@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=9hd5WA6QCn"
        ],
        "detail": [
          "https://openreview.net/forum?id=9hd5WA6QCn"
        ]
      },
      "scores": {
        "pdf": 11,
        "kimi": 9
      },
      "raw_excerpt": "MODA: MOdular Duplex Attention for Multimodal Perception, Cognition, and Emotion Understanding [PDF 11 ] [Copy] [Kimi 9 ] [REL] Authors : Zhicheng Zhang , Wuyou Xia , Chenxi Zhao , Zhou Yan , Xiaoqiang Liu , Yongjie Zhu , Wenyu Qin , Pengfei Wan , Di ZHANG , Jufeng Yang Multimodal large language models (MLLMs) recently showed strong capacity in integrating data among multiple modalities, empowered by generalizable attention architecture. Advanced methods predominantly focus on language-centric tuning while less exploring multimodal tokens mixed through attention, posing challenges in high-level tasks that require fine-grained cognition and emotion understanding. In this work, we identify the attention deficit disorder problem in multimodal learning, caused by inconsistent cross-modal attention and layer-by-layer decayed attention activation. To address this, we propose a novel attention mechanism, termed MOdular Duplex Attention (MODA), simultaneously conducting the inner-modal refinement and inter-modal interaction. MODA employs a correct-after-align strategy to effectively decouple modality alignment from cross-layer token mixing. In the alignment phase, tokens are mapped to duplex modality spaces based on the basis vectors, enabling the interaction between visual and language modality. Further, the correctness of attention scores is ensured through adaptive masked attention, which enhances the model's flexibility by allowing customizable masking patterns for different modalities. Extensive experiments on 21 benchmark datasets verify the effectiveness of MODA in perception, cognition, and emotion tasks. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "9vYGZX4OVN@OpenReview",
      "index": 39,
      "title": "Adjusting Model Size in Continual Gaussian Processes: How Big is Big Enough?",
      "authors": [
        "Guiomar Pescador-Barrios",
        "Sarah Filippi",
        "Mark van der Wilk"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "big",
        "size",
        "continual",
        "adjust",
        "enough",
        "dataset",
        "adjusting",
        "gaussian",
        "processes",
        "performance"
      ],
      "summary": "Many machine learning models require setting a parameter that controls their size before training, e.g. number of neurons in DNNs, or inducing points in GPs. Increasing capacity typically improves performance until all the information from the dataset is captured. After this point, computational cost keeps increasing, without improved performance. This leads to the question \"How big is big enough?\" We investigate this problem for Gaussian processes (single-layer neural networks) in continual learning. Here, data becomes available incrementally, and the final dataset size will therefore not be known before training, preventing the use of heuristics for setting a fixed model size. We develop a method to automatically adjust model size while maintaining near-optimal performance. Our experimental procedure follows the constraint that any hyperparameters must be set without seeing dataset properties, and we show that our method performs well across diverse datasets without the need to adjust its hyperparameter, showing it requires less tuning than others.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=9vYGZX4OVN"
        ],
        "venue": [
          "/venue/9vYGZX4OVN@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=9vYGZX4OVN"
        ],
        "detail": [
          "https://openreview.net/forum?id=9vYGZX4OVN"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Adjusting Model Size in Continual Gaussian Processes: How Big is Big Enough? [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Guiomar Pescador-Barrios , Sarah Filippi , Mark van der Wilk Many machine learning models require setting a parameter that controls their size before training, e.g. number of neurons in DNNs, or inducing points in GPs. Increasing capacity typically improves performance until all the information from the dataset is captured. After this point, computational cost keeps increasing, without improved performance. This leads to the question \"How big is big enough?\" We investigate this problem for Gaussian processes (single-layer neural networks) in continual learning. Here, data becomes available incrementally, and the final dataset size will therefore not be known before training, preventing the use of heuristics for setting a fixed model size. We develop a method to automatically adjust model size while maintaining near-optimal performance. Our experimental procedure follows the constraint that any hyperparameters must be set without seeing dataset properties, and we show that our method performs well across diverse datasets without the need to adjust its hyperparameter, showing it requires less tuning than others. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "AiaVCVDuxF@OpenReview",
      "index": 40,
      "title": "Robust ML Auditing using Prior Knowledge",
      "authors": [
        "Jade Garcia Bourrée",
        "Augustin Godinot",
        "Sayan Biswas",
        "Anne-Marie Kermarrec",
        "Erwan Le Merrer",
        "Gilles Tredan",
        "Martijn de Vos",
        "Milos Vujasinovic"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "auditor",
        "auditing",
        "audit",
        "manipulation",
        "prior",
        "platform",
        "knowledge",
        "answers",
        "robust",
        "public"
      ],
      "summary": "Among the many technical challenges to enforcing AI regulations, one crucial yet underexplored problem is the risk of audit manipulation.This manipulation occurs when a platform deliberately alters its answers to a regulator to pass an audit without modifying its answers to other users.In this paper, we introduce a novel approach to manipulation-proof auditing by taking into account the auditor's prior knowledge of the task solved by the platform. We first demonstrate that regulators must not rely on public priors (e.g. a public dataset), as platforms could easily fool the auditor in such cases. We then formally establish the conditions under which an auditor can prevent audit manipulations using prior knowledge about the ground truth. Finally, our experiments with two standard datasets illustrate the maximum level of unfairness a platform can hide before being detected as malicious.Our formalization and generalization of manipulation-proof auditing with a prior opens up new research directions for more robust fairness audits.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=AiaVCVDuxF"
        ],
        "venue": [
          "/venue/AiaVCVDuxF@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=AiaVCVDuxF"
        ],
        "detail": [
          "https://openreview.net/forum?id=AiaVCVDuxF"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Robust ML Auditing using Prior Knowledge [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Jade Garcia Bourrée , Augustin Godinot , Sayan Biswas , Anne-Marie Kermarrec , Erwan Le Merrer , Gilles Tredan , Martijn de Vos , Milos Vujasinovic Among the many technical challenges to enforcing AI regulations, one crucial yet underexplored problem is the risk of audit manipulation.This manipulation occurs when a platform deliberately alters its answers to a regulator to pass an audit without modifying its answers to other users.In this paper, we introduce a novel approach to manipulation-proof auditing by taking into account the auditor's prior knowledge of the task solved by the platform. We first demonstrate that regulators must not rely on public priors (e.g. a public dataset), as platforms could easily fool the auditor in such cases. We then formally establish the conditions under which an auditor can prevent audit manipulations using prior knowledge about the ground truth. Finally, our experiments with two standard datasets illustrate the maximum level of unfairness a platform can hide before being detected as malicious.Our formalization and generalization of manipulation-proof auditing with a prior opens up new research directions for more robust fairness audits. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "AnoIgkc6WS@OpenReview",
      "index": 41,
      "title": "Exogenous Isomorphism for Counterfactual Identifiability",
      "authors": [
        "Yikang Chen",
        "Dehui du"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "identifiability",
        "scms",
        "counterfactual",
        "sim",
        "exogenous",
        "isomorphism",
        "mathcal",
        "causal",
        "pch",
        "assumptions"
      ],
      "summary": "This paper investigates ∼ L _ 3 ∼ L _ 3 -identifiability, a form of complete counterfactual identifiability within the Pearl Causal Hierarchy (PCH) framework, ensuring that all Structural Causal Models (SCMs) satisfying the given assumptions provide consistent answers to all causal questions. To simplify this problem, we introduce exogenous isomorphism and propose ∼ E I ∼ E I -identifiability, reflecting the strength of model identifiability required for ∼ L _ 3 ∼ L _ 3 -identifiability. We explore sufficient assumptions for achieving ∼ E I ∼ E I -identifiability in two special classes of SCMs: Bijective SCMs (BSCMs), based on counterfactual transport, and Triangular Monotonic SCMs (TM-SCMs), which extend ∼ L _ 2 ∼ L _ 2 -identifiability. Our results unify and generalize existing theories, providing theoretical guarantees for practical applications. Finally, we leverage neural TM-SCMs to address the consistency problem in counterfactual reasoning, with experiments validating both the effectiveness of our method and the correctness of the theory.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=AnoIgkc6WS"
        ],
        "venue": [
          "/venue/AnoIgkc6WS@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=AnoIgkc6WS"
        ],
        "detail": [
          "https://openreview.net/forum?id=AnoIgkc6WS"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 1
      },
      "raw_excerpt": "Exogenous Isomorphism for Counterfactual Identifiability [PDF 5 ] [Copy] [Kimi 1 ] [REL] Authors : Yikang Chen , Dehui du This paper investigates ∼ L _ 3 ∼ L _ 3 -identifiability, a form of complete counterfactual identifiability within the Pearl Causal Hierarchy (PCH) framework, ensuring that all Structural Causal Models (SCMs) satisfying the given assumptions provide consistent answers to all causal questions. To simplify this problem, we introduce exogenous isomorphism and propose ∼ E I ∼ E I -identifiability, reflecting the strength of model identifiability required for ∼ L _ 3 ∼ L _ 3 -identifiability. We explore sufficient assumptions for achieving ∼ E I ∼ E I -identifiability in two special classes of SCMs: Bijective SCMs (BSCMs), based on counterfactual transport, and Triangular Monotonic SCMs (TM-SCMs), which extend ∼ L _ 2 ∼ L _ 2 -identifiability. Our results unify and generalize existing theories, providing theoretical guarantees for practical applications. Finally, we leverage neural TM-SCMs to address the consistency problem in counterfactual reasoning, with experiments validating both the effectiveness of our method and the correctness of the theory. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "AsODat0dkE@OpenReview",
      "index": 42,
      "title": "Optimizing Adaptive Attacks against Watermarks for Language Models",
      "authors": [
        "Abdulrahman Diaa",
        "Toluwani Aremu",
        "Nils Lukas"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "watermarking",
        "attacks",
        "watermarks",
        "content",
        "robustness",
        "adaptive",
        "evading",
        "watermark",
        "nilslukas",
        "paraphrasers"
      ],
      "summary": "Large Language Models (LLMs) can be misused to spread unwanted content at scale. Content watermarking deters misuse by hiding messages in content, enabling its detection using a secret *watermarking key*. Robustness is a core security property, stating that evading detection requires (significant) degradation of the content's quality. Many LLM watermarking methods have been proposed, but robustness is tested only against *non-adaptive* attackers who lack knowledge of the watermarking method and can find only suboptimal attacks. We formulate watermark robustness as an objective function and use preference-based optimization to tune *adaptive* attacks against the specific watermarking method. Our evaluation shows that (i) adaptive attacks evade detection against all surveyed watermarks, (ii) training against *any* watermark succeeds in evading unseen watermarks, and (iii) optimization-based attacks are cost-effective. Our findings underscore the need to test robustness against adaptively tuned attacks. We release our adaptively tuned paraphrasers at <https://github.com/nilslukas/ada-wm-evasion>.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=AsODat0dkE"
        ],
        "venue": [
          "/venue/AsODat0dkE@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=AsODat0dkE"
        ],
        "detail": [
          "https://openreview.net/forum?id=AsODat0dkE"
        ]
      },
      "scores": {
        "pdf": 6,
        "kimi": 4
      },
      "raw_excerpt": "Optimizing Adaptive Attacks against Watermarks for Language Models [PDF 6 ] [Copy] [Kimi 4 ] [REL] Authors : Abdulrahman Diaa , Toluwani Aremu , Nils Lukas Large Language Models (LLMs) can be misused to spread unwanted content at scale. Content watermarking deters misuse by hiding messages in content, enabling its detection using a secret *watermarking key*. Robustness is a core security property, stating that evading detection requires (significant) degradation of the content's quality. Many LLM watermarking methods have been proposed, but robustness is tested only against *non-adaptive* attackers who lack knowledge of the watermarking method and can find only suboptimal attacks. We formulate watermark robustness as an objective function and use preference-based optimization to tune *adaptive* attacks against the specific watermarking method. Our evaluation shows that (i) adaptive attacks evade detection against all surveyed watermarks, (ii) training against *any* watermark succeeds in evading unseen watermarks, and (iii) optimization-based attacks are cost-effective. Our findings underscore the need to test robustness against adaptively tuned attacks. We release our adaptively tuned paraphrasers at <https://github.com/nilslukas/ada-wm-evasion>. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "W2Fe1hT7Ks@OpenReview",
      "index": 43,
      "title": "The Role of Randomness in Stability",
      "authors": [
        "Max Hopkins",
        "Shay Moran"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "randomness",
        "mathcal",
        "stability",
        "textit",
        "yehudayoff",
        "2024",
        "replicability",
        "chase",
        "moran",
        "complexity"
      ],
      "summary": "Stability is a central property in learning and statistics promising the output of an algorithm A A does not change substantially when applied to similar datasets S S and S ′ S ′ . It is an elementary fact that any sufficiently stable algorithm (e.g.\\ one returning the same result with high probability, satisfying privacy guarantees, etc.) must be randomized. This raises a natural question: can we quantify \\textit{how much} randomness is needed for algorithmic stability? We study the randomness complexity of two influential notions of stability in learning: \\textit{replicability} (which promises A A usually outputs the same result when run over samples from the same distribution), and \\textit{differential privacy} (which promises the output distribution of A A remains similar under neighboring datasets). In particular, building on the ideas of (Dixon, Pavan, Vander Woude, and Vinodchandran ICML 2024) and (Cannone, Su, and Vadhan ITCS 2024), we prove a \"weak-to-strong\" boosting theorem for stability in these settings: the randomness complexity of a task M M is tightly controlled by the best replication probability of any \\textit{deterministic} algorithm solving M M , a parameter known as M M 's \"global stability\" (Chase, Moran, Yehudayoff FOCS 2023). Finally, we use this connection to characterize the randomness complexity of PAC Learning: a class has bounded randomness complexity iff it has finite Littlestone dimension, and moreover scales at worst logarithmically in the excess error of the learner. As a corollary, we resolve a question of (Chase, Chornomaz, Moran, and Yehudayoff STOC 2024) about the error-dependent list-replicability of agnostic learning.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=W2Fe1hT7Ks"
        ],
        "venue": [
          "/venue/W2Fe1hT7Ks@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=W2Fe1hT7Ks"
        ],
        "detail": [
          "https://openreview.net/forum?id=W2Fe1hT7Ks"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "The Role of Randomness in Stability [PDF 3 ] [Copy] [Kimi 1 ] [REL] Authors : Max Hopkins , Shay Moran Stability is a central property in learning and statistics promising the output of an algorithm A A does not change substantially when applied to similar datasets S S and S ′ S ′ . It is an elementary fact that any sufficiently stable algorithm (e.g.\\ one returning the same result with high probability, satisfying privacy guarantees, etc.) must be randomized. This raises a natural question: can we quantify \\textit{how much} randomness is needed for algorithmic stability? We study the randomness complexity of two influential notions of stability in learning: \\textit{replicability} (which promises A A usually outputs the same result when run over samples from the same distribution), and \\textit{differential privacy} (which promises the output distribution of A A remains similar under neighboring datasets). In particular, building on the ideas of (Dixon, Pavan, Vander Woude, and Vinodchandran ICML 2024) and (Cannone, Su, and Vadhan ITCS 2024), we prove a \"weak-to-strong\" boosting theorem for stability in these settings: the randomness complexity of a task M M is tightly controlled by the best replication probability of any \\textit{deterministic} algorithm solving M M , a parameter known as M M 's \"global stability\" (Chase, Moran, Yehudayoff FOCS 2023). Finally, we use this connection to characterize the randomness complexity of PAC Learning: a class has bounded randomness complexity iff it has finite Littlestone dimension, and moreover scales at worst logarithmically in the excess error of the learner. As a corollary, we resolve a question of (Chase, Chornomaz, Moran, and Yehudayoff STOC 2024) about the error-dependent list-replicability of agnostic learning. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "BkdAnSKNoX@OpenReview",
      "index": 44,
      "title": "TLLC: Transfer Learning-based Label Completion for Crowdsourcing",
      "authors": [
        "Wenjun Zhang",
        "Liangxiao Jiang",
        "Chaoqun Li"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "worker",
        "tllc",
        "label",
        "completion",
        "instances",
        "crowdsourced",
        "modeling",
        "transfer",
        "domain",
        "annotated"
      ],
      "summary": "Label completion serves as a preprocessing approach to handling the sparse crowdsourced label matrix problem, significantly boosting the effectiveness of the downstream label aggregation. In recent advances, worker modeling has been proved to be a powerful strategy to further improve the performance of label completion. However, in real-world scenarios, workers typically annotate only a few instances, leading to insufficient worker modeling and thus limiting the improvement of label completion. To address this issue, we propose a novel transfer learning-based label completion (TLLC) method. Specifically, we first identify all high-confidence instances from the whole crowdsourced data as a source domain and use it to pretrain a Siamese network. The abundant annotated instances in the source domain provide essential knowledge for worker modeling. Then, we transfer the pretrained network to the target domain with the instances annotated by each worker separately, ensuring worker modeling captures unique characteristics of each worker. Finally, we leverage the new embeddings learned by the transferred network to complete each worker’s missing labels. Extensive experiments on several widely used real-world datasets demonstrate the effectiveness of TLLC. Our codes and datasets are available at https://github.com/jiangliangxiao/TLLC.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=BkdAnSKNoX"
        ],
        "venue": [
          "/venue/BkdAnSKNoX@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=BkdAnSKNoX"
        ],
        "detail": [
          "https://openreview.net/forum?id=BkdAnSKNoX"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "TLLC: Transfer Learning-based Label Completion for Crowdsourcing [PDF 3 ] [Copy] [Kimi 1 ] [REL] Authors : Wenjun Zhang , Liangxiao Jiang , Chaoqun Li Label completion serves as a preprocessing approach to handling the sparse crowdsourced label matrix problem, significantly boosting the effectiveness of the downstream label aggregation. In recent advances, worker modeling has been proved to be a powerful strategy to further improve the performance of label completion. However, in real-world scenarios, workers typically annotate only a few instances, leading to insufficient worker modeling and thus limiting the improvement of label completion. To address this issue, we propose a novel transfer learning-based label completion (TLLC) method. Specifically, we first identify all high-confidence instances from the whole crowdsourced data as a source domain and use it to pretrain a Siamese network. The abundant annotated instances in the source domain provide essential knowledge for worker modeling. Then, we transfer the pretrained network to the target domain with the instances annotated by each worker separately, ensuring worker modeling captures unique characteristics of each worker. Finally, we leverage the new embeddings learned by the transferred network to complete each worker’s missing labels. Extensive experiments on several widely used real-world datasets demonstrate the effectiveness of TLLC. Our codes and datasets are available at https://github.com/jiangliangxiao/TLLC. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "BkrIQPREkn@OpenReview",
      "index": 45,
      "title": "Not All Wrong is Bad: Using Adversarial Examples for Unlearning",
      "authors": [
        "Ali Ebrahimpour-Boroojeny",
        "Hari Sundaram",
        "Varun Chandrasekaran"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "unlearning",
        "forget",
        "amun",
        "adversarial",
        "examples",
        "samples",
        "model",
        "sota",
        "wrong",
        "bad"
      ],
      "summary": "Machine unlearning, where users can request the deletion of a forget dataset, is becoming increasingly important because of numerous privacy regulations. Initial works on \"exact'' unlearning (e.g., retraining) incur large computational overheads. However, while computationally inexpensive, \"approximate'' methods have fallen short of reaching the effectiveness of exact unlearning: models produced fail to obtain comparable accuracy and prediction confidence on both the forget and test (i.e., unseen) dataset. Exploiting this observation, we propose a new unlearning method, Adversarial Machine UNlearning (AMUN), that outperforms prior state-of-the-art (SOTA) methods for image classification. AMUN lowers the confidence of the model on the forget samples by fine-tuning the model on their corresponding adversarial examples. Adversarial examples naturally belong to the distribution imposed by the model on the input space; fine-tuning the model on the adversarial examples closest to the corresponding forget samples (a) localizes the changes to the decision boundary of the model around each forget sample and (b) avoids drastic changes to the global behavior of the model, thereby preserving the model's accuracy on test samples. Using AMUN for unlearning a random 10% of CIFAR-10 samples, we observe that even SOTA membership inference attacks cannot do better than random guessing.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=BkrIQPREkn"
        ],
        "venue": [
          "/venue/BkrIQPREkn@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=BkrIQPREkn"
        ],
        "detail": [
          "https://openreview.net/forum?id=BkrIQPREkn"
        ]
      },
      "scores": {
        "pdf": 6,
        "kimi": 5
      },
      "raw_excerpt": "Not All Wrong is Bad: Using Adversarial Examples for Unlearning [PDF 6 ] [Copy] [Kimi 5 ] [REL] Authors : Ali Ebrahimpour-Boroojeny , Hari Sundaram , Varun Chandrasekaran Machine unlearning, where users can request the deletion of a forget dataset, is becoming increasingly important because of numerous privacy regulations. Initial works on \"exact'' unlearning (e.g., retraining) incur large computational overheads. However, while computationally inexpensive, \"approximate'' methods have fallen short of reaching the effectiveness of exact unlearning: models produced fail to obtain comparable accuracy and prediction confidence on both the forget and test (i.e., unseen) dataset. Exploiting this observation, we propose a new unlearning method, Adversarial Machine UNlearning (AMUN), that outperforms prior state-of-the-art (SOTA) methods for image classification. AMUN lowers the confidence of the model on the forget samples by fine-tuning the model on their corresponding adversarial examples. Adversarial examples naturally belong to the distribution imposed by the model on the input space; fine-tuning the model on the adversarial examples closest to the corresponding forget samples (a) localizes the changes to the decision boundary of the model around each forget sample and (b) avoids drastic changes to the global behavior of the model, thereby preserving the model's accuracy on test samples. Using AMUN for unlearning a random 10% of CIFAR-10 samples, we observe that even SOTA membership inference attacks cannot do better than random guessing. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Bm706VlAtU@OpenReview",
      "index": 46,
      "title": "Diffusion-based Adversarial Purification from the Perspective of the Frequency Domain",
      "authors": [
        "Gaozheng Pei",
        "Ke Ma",
        "Yingfei Sun",
        "Qianqian Xu",
        "Qingming Huang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "adversarial",
        "purification",
        "damage",
        "frequency",
        "spectrum",
        "image",
        "perturbations",
        "amplitude",
        "domain",
        "perspective"
      ],
      "summary": "The diffusion-based adversarial purification methods attempt to drown adversarial perturbations into a part of isotropic noise through the forward process, and then recover the clean images through the reverse process. Due to the lack of distribution information about adversarial perturbations in the pixel domain, it is often unavoidable to damage normal semantics. We turn to the frequency domain perspective, decomposing the image into amplitude spectrum and phase spectrum. We find that for both spectra, the damage caused by adversarial perturbations tends to increase monotonically with frequency. This means that we can extract the content and structural information of the original clean sample from the frequency components that are less damaged. Meanwhile, theoretical analysis indicates that existing purification methods indiscriminately damage all frequency components, leading to excessive damage to the image. Therefore, we propose a purification method that can eliminate adversarial perturbations while maximizing the preservation of the content and structure of the original image. Specifically, at each time step during the reverse process, for the amplitude spectrum, we replace the low-frequency components of the estimated image's amplitude spectrum with the corresponding parts of the adversarial image.For the phase spectrum, we project the phase of the estimated image into a designated range of the adversarial image's phase spectrum, focusing on the low frequencies. Empirical evidence from extensive experiments demonstrates that our method significantly outperforms most current defense methods.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Bm706VlAtU"
        ],
        "venue": [
          "/venue/Bm706VlAtU@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Bm706VlAtU"
        ],
        "detail": [
          "https://openreview.net/forum?id=Bm706VlAtU"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 3
      },
      "raw_excerpt": "Diffusion-based Adversarial Purification from the Perspective of the Frequency Domain [PDF 4 ] [Copy] [Kimi 3 ] [REL] Authors : Gaozheng Pei , Ke Ma , Yingfei Sun , Qianqian Xu , Qingming Huang The diffusion-based adversarial purification methods attempt to drown adversarial perturbations into a part of isotropic noise through the forward process, and then recover the clean images through the reverse process. Due to the lack of distribution information about adversarial perturbations in the pixel domain, it is often unavoidable to damage normal semantics. We turn to the frequency domain perspective, decomposing the image into amplitude spectrum and phase spectrum. We find that for both spectra, the damage caused by adversarial perturbations tends to increase monotonically with frequency. This means that we can extract the content and structural information of the original clean sample from the frequency components that are less damaged. Meanwhile, theoretical analysis indicates that existing purification methods indiscriminately damage all frequency components, leading to excessive damage to the image. Therefore, we propose a purification method that can eliminate adversarial perturbations while maximizing the preservation of the content and structure of the original image. Specifically, at each time step during the reverse process, for the amplitude spectrum, we replace the low-frequency components of the estimated image's amplitude spectrum with the corresponding parts of the adversarial image.For the phase spectrum, we project the phase of the estimated image into a designated range of the adversarial image's phase spectrum, focusing on the low frequencies. Empirical evidence from extensive experiments demonstrates that our method significantly outperforms most current defense methods. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "DDIGCk25BO@OpenReview",
      "index": 47,
      "title": "Robust Automatic Modulation Classification with Fuzzy Regularization",
      "authors": [
        "Xinyan Liang",
        "Ruijie Sang",
        "Yuhua Qian",
        "Qian Guo",
        "Feijiang Li",
        "Liang Du"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "amc",
        "modulation",
        "classification",
        "confusable",
        "fuzzy",
        "ambiguity",
        "automatic",
        "regularization",
        "pillar",
        "dynamic"
      ],
      "summary": "Automatic Modulation Classification (AMC) serves as a foundational pillar for cognitive radio systems, enabling critical functionalities including dynamic spectrum allocation, non-cooperative signal surveillance, and adaptive waveform optimization. However, practical deployment of AMC faces a fundamental challenge: prediction ambiguity arising from intrinsic similarity among modulation schemes and exacerbated under low signal-to-noise ratio (SNR) conditions. This phenomenon manifests as near-identical probability distributions across confusable modulation types, significantly degrading classification reliability. To address this, we propose Fuzzy Regularization-enhanced AMC (FR-AMC), a novel framework that integrates uncertainty quantification into the classification pipeline. The proposed FR has three features: (1) Explicitly model prediction ambiguity during backpropagation, (2) dynamic sample reweighting through adaptive loss scaling, (3) encourage margin maximization between confusable modulation clusters. Experimental results on benchmark datasets demonstrate that the FR achieves superior classification accuracy and robustness compared to compared methods, making it a promising solution for real-world spectrum management and communication applications.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=DDIGCk25BO"
        ],
        "venue": [
          "/venue/DDIGCk25BO@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=DDIGCk25BO"
        ],
        "detail": [
          "https://openreview.net/forum?id=DDIGCk25BO"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Robust Automatic Modulation Classification with Fuzzy Regularization [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Xinyan Liang , Ruijie Sang , Yuhua Qian , Qian Guo , Feijiang Li , Liang Du Automatic Modulation Classification (AMC) serves as a foundational pillar for cognitive radio systems, enabling critical functionalities including dynamic spectrum allocation, non-cooperative signal surveillance, and adaptive waveform optimization. However, practical deployment of AMC faces a fundamental challenge: prediction ambiguity arising from intrinsic similarity among modulation schemes and exacerbated under low signal-to-noise ratio (SNR) conditions. This phenomenon manifests as near-identical probability distributions across confusable modulation types, significantly degrading classification reliability. To address this, we propose Fuzzy Regularization-enhanced AMC (FR-AMC), a novel framework that integrates uncertainty quantification into the classification pipeline. The proposed FR has three features: (1) Explicitly model prediction ambiguity during backpropagation, (2) dynamic sample reweighting through adaptive loss scaling, (3) encourage margin maximization between confusable modulation clusters. Experimental results on benchmark datasets demonstrate that the FR achieves superior classification accuracy and robustness compared to compared methods, making it a promising solution for real-world spectrum management and communication applications. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "DJcEoC9JpQ@OpenReview",
      "index": 48,
      "title": "Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger",
      "authors": [
        "Qi Yang",
        "Chenghao Zhang",
        "Lubin Fan",
        "Kun Ding",
        "Jieping Ye",
        "Shiming Xiang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "lvlms",
        "reasoning",
        "rag",
        "ranking",
        "knowledge",
        "tree",
        "vqa",
        "base",
        "context",
        "search"
      ],
      "summary": "Recent advancements in Large Vision Language Models (LVLMs) have significantly improved performance in Visual Question Answering (VQA) tasks through multimodal Retrieval-Augmented Generation (RAG). However, existing methods still face challenges, such as the scarcity of knowledge with reasoning examples and erratic responses from retrieved knowledge. To address these issues, in this study, we propose a multimodal RAG framework, termed RCTS, which enhances LVLMs by constructing a Reasoning Context-enriched knowledge base and a Tree Search re-ranking method. Specifically, we introduce a self-consistent evaluation mechanism to enrich the knowledge base with intrinsic reasoning patterns. We further propose a Monte Carlo Tree Search with Heuristic Rewards (MCTS-HR) to prioritize the most relevant examples. This ensures that LVLMs can leverage high-quality contextual reasoning for better and more consistent responses. Extensive experiments demonstrate that our framework achieves state-of-the-art performance on multiple VQA datasets, significantly outperforming In-Context Learning (ICL) and Vanilla-RAG methods. It highlights the effectiveness of our knowledge base and re-ranking method in improving LVLMs.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=DJcEoC9JpQ"
        ],
        "venue": [
          "/venue/DJcEoC9JpQ@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=DJcEoC9JpQ"
        ],
        "detail": [
          "https://openreview.net/forum?id=DJcEoC9JpQ"
        ]
      },
      "scores": {
        "pdf": 12,
        "kimi": 10
      },
      "raw_excerpt": "Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger [PDF 12 ] [Copy] [Kimi 10 ] [REL] Authors : Qi Yang , Chenghao Zhang , Lubin Fan , Kun Ding , Jieping Ye , Shiming Xiang Recent advancements in Large Vision Language Models (LVLMs) have significantly improved performance in Visual Question Answering (VQA) tasks through multimodal Retrieval-Augmented Generation (RAG). However, existing methods still face challenges, such as the scarcity of knowledge with reasoning examples and erratic responses from retrieved knowledge. To address these issues, in this study, we propose a multimodal RAG framework, termed RCTS, which enhances LVLMs by constructing a Reasoning Context-enriched knowledge base and a Tree Search re-ranking method. Specifically, we introduce a self-consistent evaluation mechanism to enrich the knowledge base with intrinsic reasoning patterns. We further propose a Monte Carlo Tree Search with Heuristic Rewards (MCTS-HR) to prioritize the most relevant examples. This ensures that LVLMs can leverage high-quality contextual reasoning for better and more consistent responses. Extensive experiments demonstrate that our framework achieves state-of-the-art performance on multiple VQA datasets, significantly outperforming In-Context Learning (ICL) and Vanilla-RAG methods. It highlights the effectiveness of our knowledge base and re-ranking method in improving LVLMs. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "DUGFTH9W8B@OpenReview",
      "index": 49,
      "title": "Monte-Carlo Tree Search with Uncertainty Propagation via Optimal Transport",
      "authors": [
        "Tuan Dam",
        "Pascal Stenger",
        "Lukas Schneider",
        "Joni Pajarinen",
        "Carlo D&#x27;Eramo",
        "Odalric-Ambrym Maillard"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "backup",
        "wasserstein",
        "mcts",
        "barycenter",
        "tree",
        "value",
        "operator",
        "nodes",
        "monte",
        "carlo"
      ],
      "summary": "This paper introduces a novel backup strategy for Monte-Carlo Tree Search (MCTS) tailored for highly stochastic and partially observable Markov decision processes. We adopt a probabilistic approach, modeling both value and action-value nodes as Gaussian distributions, to introduce a novel backup operator that computes value nodes as the Wasserstein barycenter of their action-value children nodes; thus, propagating the uncertainty of the estimate across the tree to the root node. We study our novel backup operator when using a novel combination of L 1 L 1 -Wasserstein barycenter with α α -divergence, by drawing a crucial connection to the generalized mean backup operator. We complement our probabilistic backup operator with two sampling strategies, based on optimistic selection and Thompson sampling, obtaining our Wasserstein MCTS algorithm. We provide theoretical guarantees of asymptotic convergence of O ( n − 1 / 2 ) O ( n − 1 / 2 ) , with n n as the number of visited trajectories, to the optimal policy and an empirical evaluation on several stochastic and partially observable environments, where our approach outperforms well-known related baselines.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=DUGFTH9W8B"
        ],
        "venue": [
          "/venue/DUGFTH9W8B@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=DUGFTH9W8B"
        ],
        "detail": [
          "https://openreview.net/forum?id=DUGFTH9W8B"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 5
      },
      "raw_excerpt": "Monte-Carlo Tree Search with Uncertainty Propagation via Optimal Transport [PDF 4 ] [Copy] [Kimi 5 ] [REL] Authors : Tuan Dam , Pascal Stenger , Lukas Schneider , Joni Pajarinen , Carlo D&#x27;Eramo , Odalric-Ambrym Maillard This paper introduces a novel backup strategy for Monte-Carlo Tree Search (MCTS) tailored for highly stochastic and partially observable Markov decision processes. We adopt a probabilistic approach, modeling both value and action-value nodes as Gaussian distributions, to introduce a novel backup operator that computes value nodes as the Wasserstein barycenter of their action-value children nodes; thus, propagating the uncertainty of the estimate across the tree to the root node. We study our novel backup operator when using a novel combination of L 1 L 1 -Wasserstein barycenter with α α -divergence, by drawing a crucial connection to the generalized mean backup operator. We complement our probabilistic backup operator with two sampling strategies, based on optimistic selection and Thompson sampling, obtaining our Wasserstein MCTS algorithm. We provide theoretical guarantees of asymptotic convergence of O ( n − 1 / 2 ) O ( n − 1 / 2 ) , with n n as the number of visited trajectories, to the optimal policy and an empirical evaluation on several stochastic and partially observable environments, where our approach outperforms well-known related baselines. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "DoDXFkF10S@OpenReview",
      "index": 50,
      "title": "Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation",
      "authors": [
        "Alessandro Palma",
        "Sergei Rybakov",
        "Leon Hetzel",
        "Stephan Günnemann",
        "Fabian Theis"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "latent",
        "interpolations",
        "euclidean",
        "cell",
        "manifold",
        "geometry",
        "flatvi",
        "single",
        "interpolation",
        "rna"
      ],
      "summary": "Latent space interpolations are a powerful tool for navigating deep generative models in applied settings. An example is single-cell RNA sequencing, where existing methods model cellular state transitions as latent space interpolations with variational autoencoders, often assuming linear shifts and Euclidean geometry. However, unless explicitly enforced, linear interpolations in the latent space may not correspond to geodesic paths on the data manifold, limiting methods that assume Euclidean geometry in the data representations. We introduce FlatVI, a novel training framework that regularises the latent manifold of discrete-likelihood variational autoencoders towards Euclidean geometry, specifically tailored for modelling single-cell count data. By encouraging straight lines in the latent space to approximate geodesic interpolations on the decoded single-cell manifold, FlatVI enhances compatibility with downstream approaches that assume Euclidean latent geometry. Experiments on synthetic data support the theoretical soundness of our approach, while applications to time-resolved single-cell RNA sequencing data demonstrate improved trajectory reconstruction and manifold interpolation.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=DoDXFkF10S"
        ],
        "venue": [
          "/venue/DoDXFkF10S@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=DoDXFkF10S"
        ],
        "detail": [
          "https://openreview.net/forum?id=DoDXFkF10S"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 3
      },
      "raw_excerpt": "Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation [PDF 3 ] [Copy] [Kimi 3 ] [REL] Authors : Alessandro Palma , Sergei Rybakov , Leon Hetzel , Stephan Günnemann , Fabian Theis Latent space interpolations are a powerful tool for navigating deep generative models in applied settings. An example is single-cell RNA sequencing, where existing methods model cellular state transitions as latent space interpolations with variational autoencoders, often assuming linear shifts and Euclidean geometry. However, unless explicitly enforced, linear interpolations in the latent space may not correspond to geodesic paths on the data manifold, limiting methods that assume Euclidean geometry in the data representations. We introduce FlatVI, a novel training framework that regularises the latent manifold of discrete-likelihood variational autoencoders towards Euclidean geometry, specifically tailored for modelling single-cell count data. By encouraging straight lines in the latent space to approximate geodesic interpolations on the decoded single-cell manifold, FlatVI enhances compatibility with downstream approaches that assume Euclidean latent geometry. Experiments on synthetic data support the theoretical soundness of our approach, while applications to time-resolved single-cell RNA sequencing data demonstrate improved trajectory reconstruction and manifold interpolation. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "DzLP43CbiX@OpenReview",
      "index": 51,
      "title": "Flopping for FLOPs: Leveraging Equivariance for Computational Efficiency",
      "authors": [
        "Georg Bökman",
        "David Nordström",
        "Fredrik Kahl"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "flops",
        "flopping",
        "networksthat",
        "equivariance",
        "equivariant",
        "mirror",
        "irreps",
        "computational",
        "efficiency",
        "invariance"
      ],
      "summary": "Incorporating geometric invariance into neural networks enhances parameter efficiency but typically increases computational costs.This paper introduces new equivariant neural networksthat preserve symmetry while maintaining a comparable number of floating-point operations (FLOPs) per parameter to standard non-equivariant networks. We focus on horizontal mirroring (flopping) invariance, common in many computer vision tasks.The main idea is to parametrize the feature spaces in terms of mirror-symmetric and mirror-antisymmetric features, i.e., irreps of the flopping group.This decomposes the linear layers to be block-diagonal, requiring half the number of FLOPs.Our approach reduces both FLOPs and wall-clock time,providing a practical solution for efficient, scalable symmetry-aware architectures.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=DzLP43CbiX"
        ],
        "venue": [
          "/venue/DzLP43CbiX@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=DzLP43CbiX"
        ],
        "detail": [
          "https://openreview.net/forum?id=DzLP43CbiX"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Flopping for FLOPs: Leveraging Equivariance for Computational Efficiency [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Georg Bökman , David Nordström , Fredrik Kahl Incorporating geometric invariance into neural networks enhances parameter efficiency but typically increases computational costs.This paper introduces new equivariant neural networksthat preserve symmetry while maintaining a comparable number of floating-point operations (FLOPs) per parameter to standard non-equivariant networks. We focus on horizontal mirroring (flopping) invariance, common in many computer vision tasks.The main idea is to parametrize the feature spaces in terms of mirror-symmetric and mirror-antisymmetric features, i.e., irreps of the flopping group.This decomposes the linear layers to be block-diagonal, requiring half the number of FLOPs.Our approach reduces both FLOPs and wall-clock time,providing a practical solution for efficient, scalable symmetry-aware architectures. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "EW2JR5aVLm@OpenReview",
      "index": 52,
      "title": "Understanding and Mitigating Memorization in Generative Models via Sharpness of Probability Landscapes",
      "authors": [
        "Dongjae Jeon",
        "Dueun Kim",
        "Albert No"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "memorization",
        "sharpness",
        "metric",
        "landscapes",
        "probability",
        "mitigating",
        "diffusion",
        "initial",
        "generation",
        "generative"
      ],
      "summary": "In this paper, we introduce a geometric framework to analyze memorization in diffusion models through the sharpness of the log probability density. We mathematically justify a previously proposed score-difference-based memorization metric by demonstrating its effectiveness in quantifying sharpness. Additionally, we propose a novel memorization metric that captures sharpness at the initial stage of image generation in latent diffusion models, offering early insights into potential memorization. Leveraging this metric, we develop a mitigation strategy that optimizes the initial noise of the generation process using a sharpness-aware regularization term.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=EW2JR5aVLm"
        ],
        "venue": [
          "/venue/EW2JR5aVLm@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=EW2JR5aVLm"
        ],
        "detail": [
          "https://openreview.net/forum?id=EW2JR5aVLm"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Understanding and Mitigating Memorization in Generative Models via Sharpness of Probability Landscapes [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Dongjae Jeon , Dueun Kim , Albert No In this paper, we introduce a geometric framework to analyze memorization in diffusion models through the sharpness of the log probability density. We mathematically justify a previously proposed score-difference-based memorization metric by demonstrating its effectiveness in quantifying sharpness. Additionally, we propose a novel memorization metric that captures sharpness at the initial stage of image generation in latent diffusion models, offering early insights into potential memorization. Leveraging this metric, we develop a mitigation strategy that optimizes the initial noise of the generation process using a sharpness-aware regularization term. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "F1ff8zcjPp@OpenReview",
      "index": 53,
      "title": "Layer-wise Alignment: Examining Safety Alignment Across Image Encoder Layers in Vision Language Models",
      "authors": [
        "Saketh Bachu",
        "Erfan Shayegani",
        "Rohit Lal",
        "Trishna Chakraborty",
        "Arindam Dutta",
        "Chengyu Song",
        "Yue Dong",
        "Nael Abu-Ghazaleh",
        "Amit Roy-Chowdhury"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "ppo",
        "vlms",
        "encoder",
        "harmful",
        "alignment",
        "early",
        "across",
        "llava",
        "exits",
        "wise"
      ],
      "summary": "Vision-language models (VLMs) have improved significantly in their capabilities, but their complex architecture makes their safety alignment challenging. In this paper, we reveal an uneven distribution of harmful information across the intermediate layers of the image encoder and show that skipping a certain set of layers and exiting early can increase the chance of the VLM generating harmful responses. We call it as “Image enCoder Early-exiT” based vulnerability (ICET). Our experiments across three VLMs: LLaVA-1.5, LLaVA-NeXT, and Llama 3.2 show that performing early exits from the image encoder significantly increases the likelihood of generating harmful outputs. To tackle this, we propose a simple yet effective modification of the Clipped-Proximal Policy Optimization (Clip-PPO) algorithm for performing layer-wise multi-modal RLHF for VLMs. We term this as Layer-Wise PPO (L-PPO). We evaluate our L-PPO algorithm across three multi-modal datasets and show that it consistently reduces the harmfulness caused by early exits.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=F1ff8zcjPp"
        ],
        "venue": [
          "/venue/F1ff8zcjPp@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=F1ff8zcjPp"
        ],
        "detail": [
          "https://openreview.net/forum?id=F1ff8zcjPp"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 6
      },
      "raw_excerpt": "Layer-wise Alignment: Examining Safety Alignment Across Image Encoder Layers in Vision Language Models [PDF 5 ] [Copy] [Kimi 6 ] [REL] Authors : Saketh Bachu , Erfan Shayegani , Rohit Lal , Trishna Chakraborty , Arindam Dutta , Chengyu Song , Yue Dong , Nael Abu-Ghazaleh , Amit Roy-Chowdhury Vision-language models (VLMs) have improved significantly in their capabilities, but their complex architecture makes their safety alignment challenging. In this paper, we reveal an uneven distribution of harmful information across the intermediate layers of the image encoder and show that skipping a certain set of layers and exiting early can increase the chance of the VLM generating harmful responses. We call it as “Image enCoder Early-exiT” based vulnerability (ICET). Our experiments across three VLMs: LLaVA-1.5, LLaVA-NeXT, and Llama 3.2 show that performing early exits from the image encoder significantly increases the likelihood of generating harmful outputs. To tackle this, we propose a simple yet effective modification of the Clipped-Proximal Policy Optimization (Clip-PPO) algorithm for performing layer-wise multi-modal RLHF for VLMs. We term this as Layer-Wise PPO (L-PPO). We evaluate our L-PPO algorithm across three multi-modal datasets and show that it consistently reduces the harmfulness caused by early exits. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "F8NTPAz5HH@OpenReview",
      "index": 54,
      "title": "Is Complex Query Answering Really Complex?",
      "authors": [
        "Cosimo Gregucci",
        "Bo Xiong",
        "Daniel Hernández",
        "Lorenzo Loconte",
        "Pasquale Minervini",
        "Steffen Staab",
        "Antonio Vergari"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "cqa",
        "benchmarks",
        "queries",
        "query",
        "kgs",
        "complex",
        "answering",
        "decreses",
        "really",
        "link"
      ],
      "summary": "Complex query answering (CQA) on knowledge graphs (KGs) is gaining momentum as a challenging reasoning task.In this paper, we show that the current benchmarks for CQA might not be as *complex* as we think, as the way they are built distorts our perception of progress in this field.For example, we find that in these benchmarks most queries (up to 98% for some query types) can be reduced to simpler problems, e.g., link prediction, where only one link needs to be predicted.The performance of state-of-the-art CQA models decreses significantly when such models are evaluated on queries that cannot be reduced to easier types.Thus, we propose a set of more challenging benchmarks composed of queries that *require* models to reason over multiple hops and better reflect the construction of real-world KGs.In a systematic empirical investigation, the new benchmarks show that current methods leave much to be desired from current CQA methods.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=F8NTPAz5HH"
        ],
        "venue": [
          "/venue/F8NTPAz5HH@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=F8NTPAz5HH"
        ],
        "detail": [
          "https://openreview.net/forum?id=F8NTPAz5HH"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 3
      },
      "raw_excerpt": "Is Complex Query Answering Really Complex? [PDF 4 ] [Copy] [Kimi 3 ] [REL] Authors : Cosimo Gregucci , Bo Xiong , Daniel Hernández , Lorenzo Loconte , Pasquale Minervini , Steffen Staab , Antonio Vergari Complex query answering (CQA) on knowledge graphs (KGs) is gaining momentum as a challenging reasoning task.In this paper, we show that the current benchmarks for CQA might not be as *complex* as we think, as the way they are built distorts our perception of progress in this field.For example, we find that in these benchmarks most queries (up to 98% for some query types) can be reduced to simpler problems, e.g., link prediction, where only one link needs to be predicted.The performance of state-of-the-art CQA models decreses significantly when such models are evaluated on queries that cannot be reduced to easier types.Thus, we propose a set of more challenging benchmarks composed of queries that *require* models to reason over multiple hops and better reflect the construction of real-world KGs.In a systematic empirical investigation, the new benchmarks show that current methods leave much to be desired from current CQA methods. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "FKi6yjXwCN@OpenReview",
      "index": 55,
      "title": "LOCATE 3D: Real-World Object Localization via Self-Supervised Learning in 3D",
      "authors": [
        "Paul McVay",
        "Sergio Arnaud",
        "Ada Martin",
        "Arjun Majumdar",
        "Krishna Murthy Jatavallabhula",
        "Phillip Thomas",
        "Ruslan Partsey",
        "Daniel Dugas",
        "Abha Gejji",
        "Alexander Sax",
        "Vincent-Pierre Berges",
        "Mikael Henaff",
        "Ayush Jain",
        "Ang Cao",
        "Ishita Prasad",
        "Mrinal Kalakrishnan",
        "Michael Rabbat",
        "Nicolas Ballas",
        "Mahmoud Assran",
        "Oleksandr Maksymets",
        "Aravind Rajeswaran",
        "Franziska Meier"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "locate",
        "jepa",
        "pointcloud",
        "referential",
        "locate3d",
        "self",
        "supervised",
        "grounding",
        "featurized",
        "dataset"
      ],
      "summary": "We present LOCATE 3D, a model for localizing objects in 3D scenes from referring expressions like \"the small coffee table between the sofa and the lamp.\" LOCATE 3D sets a new state-of-the-art on standard referential grounding benchmarks and showcases robust generalization capabilities. Notably, LOCATE 3D operates directly on sensor observation streams (posed RGB-D frames), enabling real-world deployment on robots and AR devices. Key to our approach is 3D-JEPA, a novel self-supervised learning (SSL) algorithm applicable to sensor point clouds. It takes as input a 3D pointcloud featurized using 2D foundation models (CLIP, DINO). Subsequently, masked prediction in latent space is employed as a pretext task to aid the self-supervised learning of contextualized pointcloud features. Once trained, the 3D-JEPA encoder is finetuned alongside a language-conditioned decoder to jointly predict 3D masks and bounding boxes. Additionally, we introduce LOCATE 3D DATASET, a new dataset for 3D referential grounding, spanning multiple capture setups with over 130K annotations. This enables a systematic study of generalization capabilities as well as a stronger model. Code, models and dataset can be found at the project website: locate3d.atmeta.com",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=FKi6yjXwCN"
        ],
        "venue": [
          "/venue/FKi6yjXwCN@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=FKi6yjXwCN"
        ],
        "detail": [
          "https://openreview.net/forum?id=FKi6yjXwCN"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "LOCATE 3D: Real-World Object Localization via Self-Supervised Learning in 3D [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Paul McVay , Sergio Arnaud , Ada Martin , Arjun Majumdar , Krishna Murthy Jatavallabhula , Phillip Thomas , Ruslan Partsey , Daniel Dugas , Abha Gejji , Alexander Sax , Vincent-Pierre Berges , Mikael Henaff , Ayush Jain , Ang Cao , Ishita Prasad , Mrinal Kalakrishnan , Michael Rabbat , Nicolas Ballas , Mahmoud Assran , Oleksandr Maksymets , Aravind Rajeswaran , Franziska Meier We present LOCATE 3D, a model for localizing objects in 3D scenes from referring expressions like \"the small coffee table between the sofa and the lamp.\" LOCATE 3D sets a new state-of-the-art on standard referential grounding benchmarks and showcases robust generalization capabilities. Notably, LOCATE 3D operates directly on sensor observation streams (posed RGB-D frames), enabling real-world deployment on robots and AR devices. Key to our approach is 3D-JEPA, a novel self-supervised learning (SSL) algorithm applicable to sensor point clouds. It takes as input a 3D pointcloud featurized using 2D foundation models (CLIP, DINO). Subsequently, masked prediction in latent space is employed as a pretext task to aid the self-supervised learning of contextualized pointcloud features. Once trained, the 3D-JEPA encoder is finetuned alongside a language-conditioned decoder to jointly predict 3D masks and bounding boxes. Additionally, we introduce LOCATE 3D DATASET, a new dataset for 3D referential grounding, spanning multiple capture setups with over 130K annotations. This enables a systematic study of generalization capabilities as well as a stronger model. Code, models and dataset can be found at the project website: locate3d.atmeta.com Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "FSVdEzR4To@OpenReview",
      "index": 56,
      "title": "Penalizing Infeasible Actions and Reward Scaling in Reinforcement Learning with Offline Data",
      "authors": [
        "Jeonghye Kim",
        "Yongjae Shin",
        "Whiyoung Jung",
        "Sunghoon Hong",
        "Deunsol Yoon",
        "Youngchul Sung",
        "Kanghoon Lee",
        "Woohyung Lim"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "pars",
        "offline",
        "infeasible",
        "reward",
        "extrapolation",
        "penalizing",
        "actions",
        "reinforcement",
        "antmaze",
        "scaling"
      ],
      "summary": "Reinforcement learning with offline data suffers from Q-value extrapolation errors. To address this issue, we first demonstrate that linear extrapolation of the Q-function beyond the data range is particularly problematic. To mitigate this, we propose guiding the gradual decrease of Q-values outside the data range, which is achieved through reward scaling with layer normalization (RS-LN) and a penalization mechanism for infeasible actions (PA). By combining RS-LN and PA, we develop a new algorithm called PARS. We evaluate PARS across a range of tasks, demonstrating superior performance compared to state-of-the-art algorithms in both offline training and online fine-tuning on the D4RL benchmark, with notable success in the challenging AntMaze Ultra task.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=FSVdEzR4To"
        ],
        "venue": [
          "/venue/FSVdEzR4To@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=FSVdEzR4To"
        ],
        "detail": [
          "https://openreview.net/forum?id=FSVdEzR4To"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 6
      },
      "raw_excerpt": "Penalizing Infeasible Actions and Reward Scaling in Reinforcement Learning with Offline Data [PDF 4 ] [Copy] [Kimi 6 ] [REL] Authors : Jeonghye Kim , Yongjae Shin , Whiyoung Jung , Sunghoon Hong , Deunsol Yoon , Youngchul Sung , Kanghoon Lee , Woohyung Lim Reinforcement learning with offline data suffers from Q-value extrapolation errors. To address this issue, we first demonstrate that linear extrapolation of the Q-function beyond the data range is particularly problematic. To mitigate this, we propose guiding the gradual decrease of Q-values outside the data range, which is achieved through reward scaling with layer normalization (RS-LN) and a penalization mechanism for infeasible actions (PA). By combining RS-LN and PA, we develop a new algorithm called PARS. We evaluate PARS across a range of tasks, demonstrating superior performance compared to state-of-the-art algorithms in both offline training and online fine-tuning on the D4RL benchmark, with notable success in the challenging AntMaze Ultra task. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Ffpc7vx6qq@OpenReview",
      "index": 57,
      "title": "Learning Safety Constraints for Large Language Models",
      "authors": [
        "Xin Chen",
        "Yarden As",
        "Andreas Krause"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "safety",
        "polytope",
        "sap",
        "unsafe",
        "facets",
        "llms",
        "constraints",
        "outputs",
        "geometric",
        "representation"
      ],
      "summary": "Large language models (LLMs) have emerged as powerful tools but pose significant safety risks through harmful outputs and vulnerability to adversarial attacks. We propose SaP–short for Safety Polytope–a geometric approach to LLM safety, that learns and enforces multiple safety constraints directly in the model's representation space. We develop a framework that identifies safe and unsafe regions via the polytope's facets, enabling both detection and correction of unsafe outputs through geometric steering. Unlike existing approaches that modify model weights, SaP operates post-hoc in the representation space, preserving model capabilities while enforcing safety constraints. Experiments across multiple LLMs demonstrate that our method can effectively detect unethical inputs, reduce adversarial attack success rates while maintaining performance on standard tasks, thus highlighting the importance of having an explicit geometric model for safety. Analysis of the learned polytope facets reveals emergence of specialization in detecting different semantic notions of safety, providing interpretable insights into how safety is captured in LLMs' representation space.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Ffpc7vx6qq"
        ],
        "venue": [
          "/venue/Ffpc7vx6qq@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Ffpc7vx6qq"
        ],
        "detail": [
          "https://openreview.net/forum?id=Ffpc7vx6qq"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 7
      },
      "raw_excerpt": "Learning Safety Constraints for Large Language Models [PDF 4 ] [Copy] [Kimi 7 ] [REL] Authors : Xin Chen , Yarden As , Andreas Krause Large language models (LLMs) have emerged as powerful tools but pose significant safety risks through harmful outputs and vulnerability to adversarial attacks. We propose SaP–short for Safety Polytope–a geometric approach to LLM safety, that learns and enforces multiple safety constraints directly in the model's representation space. We develop a framework that identifies safe and unsafe regions via the polytope's facets, enabling both detection and correction of unsafe outputs through geometric steering. Unlike existing approaches that modify model weights, SaP operates post-hoc in the representation space, preserving model capabilities while enforcing safety constraints. Experiments across multiple LLMs demonstrate that our method can effectively detect unethical inputs, reduce adversarial attack success rates while maintaining performance on standard tasks, thus highlighting the importance of having an explicit geometric model for safety. Analysis of the learned polytope facets reveals emergence of specialization in detecting different semantic notions of safety, providing interpretable insights into how safety is captured in LLMs' representation space. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "FuGps5Zyia@OpenReview",
      "index": 58,
      "title": "Ad-Hoc Human-AI Coordination Challenge",
      "authors": [
        "Tin Dizdarevic",
        "Ravi Hammond",
        "Tobias Gessler",
        "Anisoara Calinescu",
        "Jonathan Cook",
        "Matteo Gallici",
        "Andrei Lupu",
        "Jakob Foerster"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "human",
        "ah2ac2",
        "flairox",
        "coordination",
        "hanabi",
        "evaluation",
        "hoc",
        "agents",
        "challenge",
        "proxy"
      ],
      "summary": "Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is a cooperative card game featuring imperfect information, constrained communication, theory of mind requirements, and coordinated action -- making it an ideal testbed for human-AI coordination. However, its use for human-AI interaction has been limited by the challenges of human evaluation. In this work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to overcome the constraints of costly and difficult-to-reproduce human evaluations. We develop \\textit{human proxy agents} on a large-scale human dataset that serve as robust, cheap, and reproducible human-like evaluation partners in AH2AC2. To encourage the development of data-efficient methods, we open-source a dataset of 3,079 games, deliberately limiting the amount of available human gameplay data. We present baseline results for both two- and three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy agents through a controlled evaluation system rather than releasing them publicly. The code is available at \\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=FuGps5Zyia"
        ],
        "venue": [
          "/venue/FuGps5Zyia@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=FuGps5Zyia"
        ],
        "detail": [
          "https://openreview.net/forum?id=FuGps5Zyia"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Ad-Hoc Human-AI Coordination Challenge [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Tin Dizdarevic , Ravi Hammond , Tobias Gessler , Anisoara Calinescu , Jonathan Cook , Matteo Gallici , Andrei Lupu , Jakob Foerster Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is a cooperative card game featuring imperfect information, constrained communication, theory of mind requirements, and coordinated action -- making it an ideal testbed for human-AI coordination. However, its use for human-AI interaction has been limited by the challenges of human evaluation. In this work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to overcome the constraints of costly and difficult-to-reproduce human evaluations. We develop \\textit{human proxy agents} on a large-scale human dataset that serve as robust, cheap, and reproducible human-like evaluation partners in AH2AC2. To encourage the development of data-efficient methods, we open-source a dataset of 3,079 games, deliberately limiting the amount of available human gameplay data. We present baseline results for both two- and three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy agents through a controlled evaluation system rather than releasing them publicly. The code is available at \\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "GazlTYxZss@OpenReview",
      "index": 59,
      "title": "Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems",
      "authors": [
        "Shaokun Zhang",
        "Ming Yin",
        "Jieyu Zhang",
        "Jiale Liu",
        "Zhiguang Han",
        "Jingyang Zhang",
        "Beibin Li",
        "Chi Wang",
        "Huazheng Wang",
        "Yiran Chen",
        "Qingyun Wu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "failure",
        "attribution",
        "agent",
        "llm",
        "failures",
        "automated",
        "systems",
        "agents",
        "task",
        "multi"
      ],
      "summary": "Failure attribution in LLM multi-agent systems—identifying the agent and step responsible for task failures—provides crucial clues for systems debugging but remains underexplored and labor-intensive. In this paper, we propose and formulate a new research area: automated failure attribution for LLM multi-agent systems.To support this initiative, we introduce the Who\\&When dataset, comprising extensive failure logs from 127 LLM multi-agent systems with fine-grained annotations linking failures to specific agents and decisive error steps.Using the Who\\&When, we develop and evaluate three automated failure attribution methods, summarizing their corresponding pros and cons. The best method achieves 53.5\\% accuracy in identifying failure-responsible agents but only 14.2\\% in pinpointing failure steps, with some methods performing below random. Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to achieve practical usability. These results highlight the task's complexity and the need for further research in this area. Code and dataset are available in https://github.com/mingyin1/Agents_Failure_Attribution.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=GazlTYxZss"
        ],
        "venue": [
          "/venue/GazlTYxZss@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=GazlTYxZss"
        ],
        "detail": [
          "https://openreview.net/forum?id=GazlTYxZss"
        ]
      },
      "scores": {
        "pdf": 9,
        "kimi": 2
      },
      "raw_excerpt": "Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems [PDF 9 ] [Copy] [Kimi 2 ] [REL] Authors : Shaokun Zhang , Ming Yin , Jieyu Zhang , Jiale Liu , Zhiguang Han , Jingyang Zhang , Beibin Li , Chi Wang , Huazheng Wang , Yiran Chen , Qingyun Wu Failure attribution in LLM multi-agent systems—identifying the agent and step responsible for task failures—provides crucial clues for systems debugging but remains underexplored and labor-intensive. In this paper, we propose and formulate a new research area: automated failure attribution for LLM multi-agent systems.To support this initiative, we introduce the Who\\&When dataset, comprising extensive failure logs from 127 LLM multi-agent systems with fine-grained annotations linking failures to specific agents and decisive error steps.Using the Who\\&When, we develop and evaluate three automated failure attribution methods, summarizing their corresponding pros and cons. The best method achieves 53.5\\% accuracy in identifying failure-responsible agents but only 14.2\\% in pinpointing failure steps, with some methods performing below random. Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to achieve practical usability. These results highlight the task's complexity and the need for further research in this area. Code and dataset are available in https://github.com/mingyin1/Agents_Failure_Attribution. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "GhTdNOMfOD@OpenReview",
      "index": 60,
      "title": "TimeBase: The Power of Minimalism in Efficient Long-term Time Series Forecasting",
      "authors": [
        "Qihe Huang",
        "Zhengyang Zhou",
        "Kuo Yang",
        "Zhongchao Yi",
        "Xu Wang",
        "Yang Wang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "timebase",
        "forecasting",
        "minimalism",
        "ltsf",
        "temporal",
        "hqh0728",
        "term",
        "series",
        "secures",
        "long"
      ],
      "summary": "Long-term time series forecasting (LTSF) has traditionally relied on large parameters to capture extended temporal dependencies, resulting in substantial computational costs and inefficiencies in both memory usage and processing time. However, time series data, unlike high-dimensional images or text, often exhibit temporal pattern similarity and low-rank structures, especially in long-term horizons. By leveraging this structure, models can be guided to focus on more essential, concise temporal data, improving both accuracy and computational efficiency. In this paper, we introduce TimeBase, an ultra-lightweight network to harness the power of minimalism in LTSF. TimeBase 1) extracts core basis temporal components and 2) transforms traditional point-level forecasting into efficient segment-level forecasting, achieving optimal utilization of both data and parameters. Extensive experiments on diverse real-world datasets show that TimeBase achieves remarkable efficiency and secures competitive forecasting performance. Additionally, TimeBase can also serve as a very effective plug-and-play complexity reducer for any patch-based forecasting models. Code is available at \\url{https://github.com/hqh0728/TimeBase}.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=GhTdNOMfOD"
        ],
        "venue": [
          "/venue/GhTdNOMfOD@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=GhTdNOMfOD"
        ],
        "detail": [
          "https://openreview.net/forum?id=GhTdNOMfOD"
        ]
      },
      "scores": {
        "pdf": 22,
        "kimi": 3
      },
      "raw_excerpt": "TimeBase: The Power of Minimalism in Efficient Long-term Time Series Forecasting [PDF 22 ] [Copy] [Kimi 3 ] [REL] Authors : Qihe Huang , Zhengyang Zhou , Kuo Yang , Zhongchao Yi , Xu Wang , Yang Wang Long-term time series forecasting (LTSF) has traditionally relied on large parameters to capture extended temporal dependencies, resulting in substantial computational costs and inefficiencies in both memory usage and processing time. However, time series data, unlike high-dimensional images or text, often exhibit temporal pattern similarity and low-rank structures, especially in long-term horizons. By leveraging this structure, models can be guided to focus on more essential, concise temporal data, improving both accuracy and computational efficiency. In this paper, we introduce TimeBase, an ultra-lightweight network to harness the power of minimalism in LTSF. TimeBase 1) extracts core basis temporal components and 2) transforms traditional point-level forecasting into efficient segment-level forecasting, achieving optimal utilization of both data and parameters. Extensive experiments on diverse real-world datasets show that TimeBase achieves remarkable efficiency and secures competitive forecasting performance. Additionally, TimeBase can also serve as a very effective plug-and-play complexity reducer for any patch-based forecasting models. Code is available at \\url{https://github.com/hqh0728/TimeBase}. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Gn6L4QRKf7@OpenReview",
      "index": 61,
      "title": "On the Power of Context-Enhanced Learning in LLMs",
      "authors": [
        "Xingyu Zhu",
        "Abhishek Panigrahi",
        "Sanjeev Arora"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "context",
        "enhanced",
        "learning",
        "icl",
        "llms",
        "gradient",
        "appears",
        "copyright",
        "regressive",
        "setting"
      ],
      "summary": "We formalize a new concept for LLMs, **context-enhanced learning**. It involves standard gradient-based learning on text except that the context is enhanced with additional data on which no auto-regressive gradients are computed. This setting is a gradient-based analog of usual in-context learning (ICL) and appears in some recent works.Using a multi-step reasoning task, we prove in a simplified setting that context-enhanced learning can be **exponentially more sample-efficient** than standard learning when the model is capable of ICL. At a mechanistic level, we find that the benefit of context-enhancement arises from a more accurate gradient learning signal.We also experimentally demonstrate that it appears hard to detect or recover learning materials that were used in the context during training. This may have implications for data security as well as copyright.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Gn6L4QRKf7"
        ],
        "venue": [
          "/venue/Gn6L4QRKf7@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Gn6L4QRKf7"
        ],
        "detail": [
          "https://openreview.net/forum?id=Gn6L4QRKf7"
        ]
      },
      "scores": {
        "pdf": 7,
        "kimi": 4
      },
      "raw_excerpt": "On the Power of Context-Enhanced Learning in LLMs [PDF 7 ] [Copy] [Kimi 4 ] [REL] Authors : Xingyu Zhu , Abhishek Panigrahi , Sanjeev Arora We formalize a new concept for LLMs, **context-enhanced learning**. It involves standard gradient-based learning on text except that the context is enhanced with additional data on which no auto-regressive gradients are computed. This setting is a gradient-based analog of usual in-context learning (ICL) and appears in some recent works.Using a multi-step reasoning task, we prove in a simplified setting that context-enhanced learning can be **exponentially more sample-efficient** than standard learning when the model is capable of ICL. At a mechanistic level, we find that the benefit of context-enhancement arises from a more accurate gradient learning signal.We also experimentally demonstrate that it appears hard to detect or recover learning materials that were used in the context during training. This may have implications for data security as well as copyright. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Go0DdhjATH@OpenReview",
      "index": 62,
      "title": "Policy Regularization on Globally Accessible States in Cross-Dynamics Reinforcement Learning",
      "authors": [
        "Zhenghai Xue",
        "Lang Feng",
        "Jiacheng Xu",
        "Kang Kang",
        "xiang wen",
        "Bo An",
        "Shuicheng YAN"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "asor",
        "policy",
        "ifo",
        "accessible",
        "imitation",
        "expert",
        "dynamics",
        "globally",
        "inaccessible",
        "states"
      ],
      "summary": "To learn from data collected in diverse dynamics, Imitation from Observation (IfO) methods leverage expert state trajectories based on thepremise that recovering expert state distributions in other dynamics facilitates policy learning in the current one. However, Imitation Learning inherently imposes a performance upper bound of learned policies. Additionally, as the environment dynamics change, certain expert states may become inaccessible, rendering their distributions less valuable for imitation. To address this, we propose a novel framework that integrates reward maximization with IfO, employing F-distance regularized policy optimization. This framework enforces constraints on globally accessible states—those with nonzero visitation frequency across all considered dynamics—mitigating the challenge posed by inaccessible states. By instantiating F-distance in different ways, we derive two theoretical analysis and develop a practical algorithm called Accessible State Oriented Policy Regularization (ASOR). ASOR serves as a general-purpose module that can be incorporated into various RL approaches, including offline RL and off-policy RL. Extensive experiments across multiple benchmarks demonstrate ASOR’s effectiveness in enhancing state-of-the-art cross-domain policy transfer algorithms, significantly improving their performance.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Go0DdhjATH"
        ],
        "venue": [
          "/venue/Go0DdhjATH@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Go0DdhjATH"
        ],
        "detail": [
          "https://openreview.net/forum?id=Go0DdhjATH"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 3
      },
      "raw_excerpt": "Policy Regularization on Globally Accessible States in Cross-Dynamics Reinforcement Learning [PDF 4 ] [Copy] [Kimi 3 ] [REL] Authors : Zhenghai Xue , Lang Feng , Jiacheng Xu , Kang Kang , xiang wen , Bo An , Shuicheng YAN To learn from data collected in diverse dynamics, Imitation from Observation (IfO) methods leverage expert state trajectories based on thepremise that recovering expert state distributions in other dynamics facilitates policy learning in the current one. However, Imitation Learning inherently imposes a performance upper bound of learned policies. Additionally, as the environment dynamics change, certain expert states may become inaccessible, rendering their distributions less valuable for imitation. To address this, we propose a novel framework that integrates reward maximization with IfO, employing F-distance regularized policy optimization. This framework enforces constraints on globally accessible states—those with nonzero visitation frequency across all considered dynamics—mitigating the challenge posed by inaccessible states. By instantiating F-distance in different ways, we derive two theoretical analysis and develop a practical algorithm called Accessible State Oriented Policy Regularization (ASOR). ASOR serves as a general-purpose module that can be incorporated into various RL approaches, including offline RL and off-policy RL. Extensive experiments across multiple benchmarks demonstrate ASOR’s effectiveness in enhancing state-of-the-art cross-domain policy transfer algorithms, significantly improving their performance. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "GoGuB1yFko@OpenReview",
      "index": 63,
      "title": "Adaptive Multi-prompt Contrastive Network for Few-shot Out-of-distribution Detection",
      "authors": [
        "Xiang Fang",
        "Arvind Easwaran",
        "Blaise Genest"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "ood",
        "prompts",
        "amcn",
        "shot",
        "detection",
        "adaptive",
        "prompt",
        "samples",
        "contrastive",
        "learnable"
      ],
      "summary": "Out-of-distribution (OOD) detection attempts to distinguish outlier samples to prevent models trained on the in-distribution (ID) dataset from producing unavailable outputs. Most OOD detection methods require many ID samples for training, which seriously limits their real-world applications. To this end, we target a challenging setting: few-shot OOD detection, where only a few labeled ID samples are available. Therefore, few-shot OOD detection is much more challenging than the traditional OOD detection setting. Previous few-shot OOD detection works ignore the distinct diversity between different classes. In this paper, we propose a novel network: Adaptive Multi-prompt Contrastive Network (AMCN), which adapts the ID-OOD separation boundary by learning inter- and intra-class distribution. To compensate for the absence of OOD and scarcity of ID image samples, we leverage CLIP, connecting text with images, engineering learnable ID and OOD textual prompts. Specifically, we first generate adaptive prompts (learnable ID prompts, label-fixed OOD prompts, and label-adaptive OOD prompts). Then, we generate an adaptive class boundary for each class by introducing a class-wise threshold. Finally, we propose a prompt-guided ID-OOD separation module to control the margin between ID and OOD prompts. Experimental results show that AMCN outperforms other state-of-the-art works.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=GoGuB1yFko"
        ],
        "venue": [
          "/venue/GoGuB1yFko@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=GoGuB1yFko"
        ],
        "detail": [
          "https://openreview.net/forum?id=GoGuB1yFko"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 1
      },
      "raw_excerpt": "Adaptive Multi-prompt Contrastive Network for Few-shot Out-of-distribution Detection [PDF 5 ] [Copy] [Kimi 1 ] [REL] Authors : Xiang Fang , Arvind Easwaran , Blaise Genest Out-of-distribution (OOD) detection attempts to distinguish outlier samples to prevent models trained on the in-distribution (ID) dataset from producing unavailable outputs. Most OOD detection methods require many ID samples for training, which seriously limits their real-world applications. To this end, we target a challenging setting: few-shot OOD detection, where only a few labeled ID samples are available. Therefore, few-shot OOD detection is much more challenging than the traditional OOD detection setting. Previous few-shot OOD detection works ignore the distinct diversity between different classes. In this paper, we propose a novel network: Adaptive Multi-prompt Contrastive Network (AMCN), which adapts the ID-OOD separation boundary by learning inter- and intra-class distribution. To compensate for the absence of OOD and scarcity of ID image samples, we leverage CLIP, connecting text with images, engineering learnable ID and OOD textual prompts. Specifically, we first generate adaptive prompts (learnable ID prompts, label-fixed OOD prompts, and label-adaptive OOD prompts). Then, we generate an adaptive class boundary for each class by introducing a class-wise threshold. Finally, we propose a prompt-guided ID-OOD separation module to control the margin between ID and OOD prompts. Experimental results show that AMCN outperforms other state-of-the-art works. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Gp7NfP7Erm@OpenReview",
      "index": 64,
      "title": "Towards Robustness and Explainability of Automatic Algorithm Selection",
      "authors": [
        "Xingyu Wu",
        "Jibin Wu",
        "Yu Zhou",
        "Liang Feng",
        "KC Tan"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "algorithm",
        "explainability",
        "dag",
        "selection",
        "robustness",
        "features",
        "distribution",
        "feature",
        "rejected",
        "automatic"
      ],
      "summary": "Algorithm selection aims to identify the optimal performing algorithm before execution. Existing techniques typically focus on the observed correlations between algorithm performance and meta-features. However, little research has explored the underlying mechanisms of algorithm selection, specifically what characteristics an algorithm must possess to effectively tackle problems with certain feature values. This gap not only limits the explainability but also makes existing models vulnerable to data bias and distribution shift. This paper introduces directed acyclic graph (DAG) to describe this mechanism, proposing a novel modeling paradigm that aligns more closely with the fundamental logic of algorithm selection. By leveraging DAG to characterize the algorithm feature distribution conditioned on problem features, our approach enhances robustness against marginal distribution changes and allows for finer-grained predictions through the reconstruction of optimal algorithm features, with the final decision relying on differences between reconstructed and rejected algorithm features. Furthermore, we demonstrate that, the learned DAG and the proposed counterfactual calculations offer our approach with both model-level and instance-level explainability.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Gp7NfP7Erm"
        ],
        "venue": [
          "/venue/Gp7NfP7Erm@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Gp7NfP7Erm"
        ],
        "detail": [
          "https://openreview.net/forum?id=Gp7NfP7Erm"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": null
      },
      "raw_excerpt": "Towards Robustness and Explainability of Automatic Algorithm Selection [PDF 4 ] [Copy] [Kimi ] [REL] Authors : Xingyu Wu , Jibin Wu , Yu Zhou , Liang Feng , KC Tan Algorithm selection aims to identify the optimal performing algorithm before execution. Existing techniques typically focus on the observed correlations between algorithm performance and meta-features. However, little research has explored the underlying mechanisms of algorithm selection, specifically what characteristics an algorithm must possess to effectively tackle problems with certain feature values. This gap not only limits the explainability but also makes existing models vulnerable to data bias and distribution shift. This paper introduces directed acyclic graph (DAG) to describe this mechanism, proposing a novel modeling paradigm that aligns more closely with the fundamental logic of algorithm selection. By leveraging DAG to characterize the algorithm feature distribution conditioned on problem features, our approach enhances robustness against marginal distribution changes and allows for finer-grained predictions through the reconstruction of optimal algorithm features, with the final decision relying on differences between reconstructed and rejected algorithm features. Furthermore, we demonstrate that, the learned DAG and the proposed counterfactual calculations offer our approach with both model-level and instance-level explainability. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "HxCuvx2uUi@OpenReview",
      "index": 65,
      "title": "Log-Sum-Exponential Estimator for Off-Policy Evaluation and Learning",
      "authors": [
        "Armin Behnamnia",
        "Gholamali Aminian",
        "Alireza Aghaei",
        "Chengchun Shi",
        "Vincent Tan",
        "Hamid R Rabiee"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "lse",
        "estimator",
        "policy",
        "propensity",
        "epsilon",
        "evaluation",
        "logged",
        "feedback",
        "variance",
        "bandit"
      ],
      "summary": "Off-policy learning and evaluation leverage logged bandit feedback datasets, which contain context, action, propensity score, and feedback for each data point. These scenarios face significant challenges due to high variance and poor performance with low-quality propensity scores and heavy-tailed reward distributions. We address these issues by introducing a novel estimator based on the log-sum-exponential (LSE) operator, which outperforms traditional inverse propensity score estimators. Our LSE estimator demonstrates variance reduction and robustness under heavy-tailed conditions. For off-policy evaluation, we derive upper bounds on the estimator's bias and variance. In the off-policy learning scenario, we establish bounds on the regret—the performance gap between our LSE estimator and the optimal policy—assuming bounded ( 1 + ϵ ) ( 1 + ϵ ) -th moment of weighted reward. Notably, we achieve a convergence rate of O ( n − ϵ / ( 1 + ϵ ) ) O ( n − ϵ / ( 1 + ϵ ) ) for the regret bounds, where ϵ ∈ [ 0 , 1 ] ϵ ∈ [ 0 , 1 ] and n n is the size of logged bandit feedback dataset. Theoretical analysis is complemented by comprehensive empirical evaluations in both off-policy learning and evaluation scenarios, confirming the practical advantages of our approach. The code for our estimator is available at the following link: https://github.com/armin-behnamnia/lse-offpolicy-learning .",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=HxCuvx2uUi"
        ],
        "venue": [
          "/venue/HxCuvx2uUi@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=HxCuvx2uUi"
        ],
        "detail": [
          "https://openreview.net/forum?id=HxCuvx2uUi"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Log-Sum-Exponential Estimator for Off-Policy Evaluation and Learning [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Armin Behnamnia , Gholamali Aminian , Alireza Aghaei , Chengchun Shi , Vincent Tan , Hamid R Rabiee Off-policy learning and evaluation leverage logged bandit feedback datasets, which contain context, action, propensity score, and feedback for each data point. These scenarios face significant challenges due to high variance and poor performance with low-quality propensity scores and heavy-tailed reward distributions. We address these issues by introducing a novel estimator based on the log-sum-exponential (LSE) operator, which outperforms traditional inverse propensity score estimators. Our LSE estimator demonstrates variance reduction and robustness under heavy-tailed conditions. For off-policy evaluation, we derive upper bounds on the estimator's bias and variance. In the off-policy learning scenario, we establish bounds on the regret—the performance gap between our LSE estimator and the optimal policy—assuming bounded ( 1 + ϵ ) ( 1 + ϵ ) -th moment of weighted reward. Notably, we achieve a convergence rate of O ( n − ϵ / ( 1 + ϵ ) ) O ( n − ϵ / ( 1 + ϵ ) ) for the regret bounds, where ϵ ∈ [ 0 , 1 ] ϵ ∈ [ 0 , 1 ] and n n is the size of logged bandit feedback dataset. Theoretical analysis is complemented by comprehensive empirical evaluations in both off-policy learning and evaluation scenarios, confirming the practical advantages of our approach. The code for our estimator is available at the following link: https://github.com/armin-behnamnia/lse-offpolicy-learning . Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "I4jNAbqHnM@OpenReview",
      "index": 66,
      "title": "The Number of Trials Matters in Infinite-Horizon General-Utility Markov Decision Processes",
      "authors": [
        "Pedro Santos",
        "Alberto Sardinha",
        "Francisco S. Melo"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "gumdps",
        "trials",
        "discounted",
        "infinite",
        "visitation",
        "policy",
        "number",
        "horizon",
        "mdps",
        "gumdp"
      ],
      "summary": "The general-utility Markov decision processes (GUMDPs) framework generalizes the MDPs framework by considering objective functions that depend on the frequency of visitation of state-action pairs induced by a given policy. In this work, we contribute with the first analysis on the impact of the number of trials, i.e., the number of randomly sampled trajectories, in infinite-horizon GUMDPs. We show that, as opposed to standard MDPs, the number of trials plays a key-role in infinite-horizon GUMDPs and the expected performance of a given policy depends, in general, on the number of trials. We consider both discounted and average GUMDPs, where the objective function depends, respectively, on discounted and average frequencies of visitation of state-action pairs. First, we study policy evaluation under discounted GUMDPs, proving lower and upper bounds on the mismatch between the finite and infinite trials formulations for GUMDPs. Second, we address average GUMDPs, studying how different classes of GUMDPs impact the mismatch between the finite and infinite trials formulations. Third, we provide a set of empirical results to support our claims, highlighting how the number of trajectories and the structure of the underlying GUMDP influence policy evaluation.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=I4jNAbqHnM"
        ],
        "venue": [
          "/venue/I4jNAbqHnM@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=I4jNAbqHnM"
        ],
        "detail": [
          "https://openreview.net/forum?id=I4jNAbqHnM"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": null
      },
      "raw_excerpt": "The Number of Trials Matters in Infinite-Horizon General-Utility Markov Decision Processes [PDF 1 ] [Copy] [Kimi ] [REL] Authors : Pedro Santos , Alberto Sardinha , Francisco S. Melo The general-utility Markov decision processes (GUMDPs) framework generalizes the MDPs framework by considering objective functions that depend on the frequency of visitation of state-action pairs induced by a given policy. In this work, we contribute with the first analysis on the impact of the number of trials, i.e., the number of randomly sampled trajectories, in infinite-horizon GUMDPs. We show that, as opposed to standard MDPs, the number of trials plays a key-role in infinite-horizon GUMDPs and the expected performance of a given policy depends, in general, on the number of trials. We consider both discounted and average GUMDPs, where the objective function depends, respectively, on discounted and average frequencies of visitation of state-action pairs. First, we study policy evaluation under discounted GUMDPs, proving lower and upper bounds on the mismatch between the finite and infinite trials formulations for GUMDPs. Second, we address average GUMDPs, studying how different classes of GUMDPs impact the mismatch between the finite and infinite trials formulations. Third, we provide a set of empirical results to support our claims, highlighting how the number of trajectories and the structure of the underlying GUMDP influence policy evaluation. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "IKCfxWtTsu@OpenReview",
      "index": 67,
      "title": "PCEvolve: Private Contrastive Evolution for Synthetic Dataset Generation via Few-Shot Private Data and Generative APIs",
      "authors": [
        "Jianqing Zhang",
        "Yang Liu",
        "Jie Fu",
        "Yang Hua",
        "Tianyuan Zou",
        "Jian Cao",
        "Qiang Yang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "private",
        "pcevolve",
        "apis",
        "api",
        "synthetic",
        "shot",
        "contrastive",
        "evolution",
        "generative",
        "data"
      ],
      "summary": "The rise of generative APIs has fueled interest in privacy-preserving synthetic data generation. While the Private Evolution (PE) algorithm generates Differential Privacy (DP) synthetic images using diffusion model APIs, it struggles with few-shot private data due to the limitations of its DP-protected similarity voting approach. In practice, the few-shot private data challenge is particularly prevalent in specialized domains like healthcare and industry. To address this challenge, we propose a novel API-assisted algorithm, Private Contrastive Evolution (PCEvolve), which iteratively mines inherent inter-class contrastive relationships in few-shot private data beyond individual data points and seamlessly integrates them into an adapted Exponential Mechanism (EM) to optimize DP’s utility in an evolution loop. We conduct extensive experiments on four specialized datasets, demonstrating that PCEvolve outperforms PE and other API-assisted baselines. These results highlight the potential of leveraging API access with private data for quality evaluation, enabling the generation of high-quality DP synthetic images and paving the way for more accessible and effective privacy-preserving generative API applications. Our code is available at https://github.com/TsingZ0/PCEvolve.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=IKCfxWtTsu"
        ],
        "venue": [
          "/venue/IKCfxWtTsu@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=IKCfxWtTsu"
        ],
        "detail": [
          "https://openreview.net/forum?id=IKCfxWtTsu"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 1
      },
      "raw_excerpt": "PCEvolve: Private Contrastive Evolution for Synthetic Dataset Generation via Few-Shot Private Data and Generative APIs [PDF 5 ] [Copy] [Kimi 1 ] [REL] Authors : Jianqing Zhang , Yang Liu , Jie Fu , Yang Hua , Tianyuan Zou , Jian Cao , Qiang Yang The rise of generative APIs has fueled interest in privacy-preserving synthetic data generation. While the Private Evolution (PE) algorithm generates Differential Privacy (DP) synthetic images using diffusion model APIs, it struggles with few-shot private data due to the limitations of its DP-protected similarity voting approach. In practice, the few-shot private data challenge is particularly prevalent in specialized domains like healthcare and industry. To address this challenge, we propose a novel API-assisted algorithm, Private Contrastive Evolution (PCEvolve), which iteratively mines inherent inter-class contrastive relationships in few-shot private data beyond individual data points and seamlessly integrates them into an adapted Exponential Mechanism (EM) to optimize DP’s utility in an evolution loop. We conduct extensive experiments on four specialized datasets, demonstrating that PCEvolve outperforms PE and other API-assisted baselines. These results highlight the potential of leveraging API access with private data for quality evaluation, enabling the generation of high-quality DP synthetic images and paving the way for more accessible and effective privacy-preserving generative API applications. Our code is available at https://github.com/TsingZ0/PCEvolve. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "JxnOZwFNcU@OpenReview",
      "index": 68,
      "title": "Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection",
      "authors": [
        "Matteo Zecchin",
        "Sangwoo Park",
        "Osvaldo Simeone"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "altt",
        "ltt",
        "mht",
        "testing",
        "hyperparameter",
        "learn",
        "test",
        "selection",
        "rounds",
        "adaptive"
      ],
      "summary": "We introduce adaptive learn-then-test (aLTT), an efficient hyperparameter selection procedure that provides finite-sample statistical guarantees on the population risk of AI models. Unlike the existing learn-then-test (LTT) technique, which relies on conventional p-value-based multiple hypothesis testing (MHT), aLTT implements sequential data-dependent MHT with early termination by leveraging e-processes. As a result, aLTT can reduce the number of testing rounds, making it particularly well-suited for scenarios in which testing is costly or presents safety risks. Apart from maintaining statistical validity, in applications such as online policy selection for offline reinforcement learning and prompt engineering, aLTT is shown to achieve the same performance as LTT while requiring only a fraction of the testing rounds.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=JxnOZwFNcU"
        ],
        "venue": [
          "/venue/JxnOZwFNcU@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=JxnOZwFNcU"
        ],
        "detail": [
          "https://openreview.net/forum?id=JxnOZwFNcU"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Matteo Zecchin , Sangwoo Park , Osvaldo Simeone We introduce adaptive learn-then-test (aLTT), an efficient hyperparameter selection procedure that provides finite-sample statistical guarantees on the population risk of AI models. Unlike the existing learn-then-test (LTT) technique, which relies on conventional p-value-based multiple hypothesis testing (MHT), aLTT implements sequential data-dependent MHT with early termination by leveraging e-processes. As a result, aLTT can reduce the number of testing rounds, making it particularly well-suited for scenarios in which testing is costly or presents safety risks. Apart from maintaining statistical validity, in applications such as online policy selection for offline reinforcement learning and prompt engineering, aLTT is shown to achieve the same performance as LTT while requiring only a fraction of the testing rounds. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "K2CckZjNy0@OpenReview",
      "index": 69,
      "title": "AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders",
      "authors": [
        "Zhengxuan Wu",
        "Aryaman Arora",
        "Atticus Geiger",
        "Zheng Wang",
        "Jing Huang",
        "Dan Jurafsky",
        "Christopher Manning",
        "Christopher Potts"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "axbench",
        "steering",
        "finetuning",
        "reft",
        "saes",
        "prompting",
        "autoencoders",
        "representation",
        "sparse",
        "interpretability"
      ],
      "summary": "Fine-grained steering of language model outputs is essential for safety and reliability. Prompting and finetuning are widely used to achieve these goals, but interpretability researchers have proposed a variety of representation-based techniques as well, including sparse autoencoders (SAEs), linear artificial tomography, supervised steering vectors, linear probes, and representation finetuning. At present, there is no benchmark for making direct comparisons between these proposals. Therefore, we introduce AxBench, a large-scale benchmark for steering and concept detection, and report experiments on Gemma-2-2B and 9B. For steering, we find that prompting outperforms all existing methods, followed by finetuning. For concept detection, representation-based methods such as difference-in-means, perform the best. On both evaluations, SAEs are not competitive. We introduce a novel weakly-supervised representational method (Rank-1 Representation Finetuning; ReFT-r1), which is competitive on both tasks while providing the interpretability advantages that prompting lacks. Along with AxBench, we train and publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=K2CckZjNy0"
        ],
        "venue": [
          "/venue/K2CckZjNy0@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=K2CckZjNy0"
        ],
        "detail": [
          "https://openreview.net/forum?id=K2CckZjNy0"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": null
      },
      "raw_excerpt": "AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders [PDF 1 ] [Copy] [Kimi ] [REL] Authors : Zhengxuan Wu , Aryaman Arora , Atticus Geiger , Zheng Wang , Jing Huang , Dan Jurafsky , Christopher Manning , Christopher Potts Fine-grained steering of language model outputs is essential for safety and reliability. Prompting and finetuning are widely used to achieve these goals, but interpretability researchers have proposed a variety of representation-based techniques as well, including sparse autoencoders (SAEs), linear artificial tomography, supervised steering vectors, linear probes, and representation finetuning. At present, there is no benchmark for making direct comparisons between these proposals. Therefore, we introduce AxBench, a large-scale benchmark for steering and concept detection, and report experiments on Gemma-2-2B and 9B. For steering, we find that prompting outperforms all existing methods, followed by finetuning. For concept detection, representation-based methods such as difference-in-means, perform the best. On both evaluations, SAEs are not competitive. We introduce a novel weakly-supervised representational method (Rank-1 Representation Finetuning; ReFT-r1), which is competitive on both tasks while providing the interpretability advantages that prompting lacks. Along with AxBench, we train and publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "KRosBwvhDx@OpenReview",
      "index": 70,
      "title": "Do We Really Need Message Passing in Brain Network Modeling?",
      "authors": [
        "Liang Yang",
        "Yuwei Liu",
        "Jiaming Zhuo",
        "Di Jin",
        "Chuan Wang",
        "Zhen Wang",
        "Xiaochun Cao"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "bqn",
        "brain",
        "message",
        "passing",
        "lywjun",
        "network",
        "demo",
        "gnns",
        "graph",
        "transformers"
      ],
      "summary": "Brain network analysis plays a critical role in brain disease prediction and diagnosis. Graph mining tools have made remarkable progress. Graph neural networks (GNNs) and Transformers, which rely on the message-passing scheme, recently dominated this field due to their powerful expressive ability on graph data. Unfortunately, by considering brain network construction using pairwise Pearson’s coefficients between any pairs of ROIs, model analysis and experimental verification reveal that *the message-passing under both GNNs and Transformers can NOT be fully explored and exploited*. Surprisingly, this paper observes the significant performance and efficiency enhancements of the Hadamard product compared to the matrix product, which is the matrix form of message passing, in processing the brain network. Inspired by this finding, a novel Brain Quadratic Network (BQN) is proposed by incorporating quadratic networks, which possess better universal approximation properties. Moreover, theoretical analysis demonstrates that BQN implicitly performs community detection along with representation learning. Extensive evaluations verify the superiority of the proposed BQN compared to the message-passing-based brain network modeling. Source code is available at [https://github.com/LYWJUN/BQN-demo](https://github.com/LYWJUN/BQN-demo).",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=KRosBwvhDx"
        ],
        "venue": [
          "/venue/KRosBwvhDx@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=KRosBwvhDx"
        ],
        "detail": [
          "https://openreview.net/forum?id=KRosBwvhDx"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": null
      },
      "raw_excerpt": "Do We Really Need Message Passing in Brain Network Modeling? [PDF 5 ] [Copy] [Kimi ] [REL] Authors : Liang Yang , Yuwei Liu , Jiaming Zhuo , Di Jin , Chuan Wang , Zhen Wang , Xiaochun Cao Brain network analysis plays a critical role in brain disease prediction and diagnosis. Graph mining tools have made remarkable progress. Graph neural networks (GNNs) and Transformers, which rely on the message-passing scheme, recently dominated this field due to their powerful expressive ability on graph data. Unfortunately, by considering brain network construction using pairwise Pearson’s coefficients between any pairs of ROIs, model analysis and experimental verification reveal that *the message-passing under both GNNs and Transformers can NOT be fully explored and exploited*. Surprisingly, this paper observes the significant performance and efficiency enhancements of the Hadamard product compared to the matrix product, which is the matrix form of message passing, in processing the brain network. Inspired by this finding, a novel Brain Quadratic Network (BQN) is proposed by incorporating quadratic networks, which possess better universal approximation properties. Moreover, theoretical analysis demonstrates that BQN implicitly performs community detection along with representation learning. Extensive evaluations verify the superiority of the proposed BQN compared to the message-passing-based brain network modeling. Source code is available at [https://github.com/LYWJUN/BQN-demo](https://github.com/LYWJUN/BQN-demo). Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "KZo2XhcSg6@OpenReview",
      "index": 71,
      "title": "LipsNet++: Unifying Filter and Controller into a Policy Network",
      "authors": [
        "Xujie Song",
        "Liangfa Chen",
        "Tong Liu",
        "Wenxuan Wang",
        "Yinuo Wang",
        "Shentao Qin",
        "Yinsong Ma",
        "Jingliang Duan",
        "Shengbo Li"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "lipsnet",
        "filter",
        "policy",
        "controller",
        "layer",
        "control",
        "action",
        "fluctuation",
        "causes",
        "noise"
      ],
      "summary": "Deep reinforcement learning (RL) is effective for decision-making and control tasks like autonomous driving and embodied AI. However, RL policies often suffer from the action fluctuation problem in real-world applications, resulting in severe actuator wear, safety risk, and performance degradation. This paper identifies the two fundamental causes of action fluctuation: observation noise and policy non-smoothness. We propose LipsNet++, a novel policy network with Fourier filter layer and Lipschitz controller layer to separately address both causes. The filter layer incorporates a trainable filter matrix that automatically extracts important frequencies while suppressing noise frequencies in the observations. The controller layer introduces a Jacobian regularization technique to achieve a low Lipschitz constant, ensuring smooth fitting of a policy function. These two layers function analogously to the filter and controller in classical control theory, suggesting that filtering and control capabilities can be seamlessly integrated into a single policy network. Both simulated and real-world experiments demonstrate that LipsNet++ achieves the state-of-the-art noise robustness and action smoothness. The code and videos are publicly available at https://xjsong99.github.io/LipsNet_v2.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=KZo2XhcSg6"
        ],
        "venue": [
          "/venue/KZo2XhcSg6@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=KZo2XhcSg6"
        ],
        "detail": [
          "https://openreview.net/forum?id=KZo2XhcSg6"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": null
      },
      "raw_excerpt": "LipsNet++: Unifying Filter and Controller into a Policy Network [PDF 4 ] [Copy] [Kimi ] [REL] Authors : Xujie Song , Liangfa Chen , Tong Liu , Wenxuan Wang , Yinuo Wang , Shentao Qin , Yinsong Ma , Jingliang Duan , Shengbo Li Deep reinforcement learning (RL) is effective for decision-making and control tasks like autonomous driving and embodied AI. However, RL policies often suffer from the action fluctuation problem in real-world applications, resulting in severe actuator wear, safety risk, and performance degradation. This paper identifies the two fundamental causes of action fluctuation: observation noise and policy non-smoothness. We propose LipsNet++, a novel policy network with Fourier filter layer and Lipschitz controller layer to separately address both causes. The filter layer incorporates a trainable filter matrix that automatically extracts important frequencies while suppressing noise frequencies in the observations. The controller layer introduces a Jacobian regularization technique to achieve a low Lipschitz constant, ensuring smooth fitting of a policy function. These two layers function analogously to the filter and controller in classical control theory, suggesting that filtering and control capabilities can be seamlessly integrated into a single policy network. Both simulated and real-world experiments demonstrate that LipsNet++ achieves the state-of-the-art noise robustness and action smoothness. The code and videos are publicly available at https://xjsong99.github.io/LipsNet_v2. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "IYLNdCII48@OpenReview",
      "index": 72,
      "title": "CACTI: Leveraging Copy Masking and Contextual Information to Improve Tabular Data Imputation",
      "authors": [
        "Aditya Gorla",
        "Ryan Wang",
        "Zhengtong Liu",
        "Ulzee An",
        "Sriram Sankararaman"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "missingness",
        "cacti",
        "contextual",
        "imputation",
        "copy",
        "masking",
        "tabular",
        "leveraging",
        "patterns",
        "random"
      ],
      "summary": "We present CACTI, a masked autoencoding approach for imputing tabular data that leverages the structure in missingness patterns and contextual information. Our approach employs a novel median truncated copy masking training strategy that encourages the model to learn from empirical patterns of missingness while incorporating semantic relationships between features — captured by column names and text descriptions — to better represent feature dependence. These dual sources of inductive bias enable CACTIto outperform state-of-the-art methods — an average R 2 R 2 gain of 7.8\\% over the next best method (13.4%, 6.1%, and 5.3% under missing not at random, at random and completely at random, respectively) — across a diverse range of datasets and missingness conditions. Our results highlight the value of leveraging dataset-specific contextual information and missingness patterns to enhance imputation performance.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=IYLNdCII48"
        ],
        "venue": [
          "/venue/IYLNdCII48@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=IYLNdCII48"
        ],
        "detail": [
          "https://openreview.net/forum?id=IYLNdCII48"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": null
      },
      "raw_excerpt": "CACTI: Leveraging Copy Masking and Contextual Information to Improve Tabular Data Imputation [PDF 2 ] [Copy] [Kimi ] [REL] Authors : Aditya Gorla , Ryan Wang , Zhengtong Liu , Ulzee An , Sriram Sankararaman We present CACTI, a masked autoencoding approach for imputing tabular data that leverages the structure in missingness patterns and contextual information. Our approach employs a novel median truncated copy masking training strategy that encourages the model to learn from empirical patterns of missingness while incorporating semantic relationships between features — captured by column names and text descriptions — to better represent feature dependence. These dual sources of inductive bias enable CACTIto outperform state-of-the-art methods — an average R 2 R 2 gain of 7.8\\% over the next best method (13.4%, 6.1%, and 5.3% under missing not at random, at random and completely at random, respectively) — across a diverse range of datasets and missingness conditions. Our results highlight the value of leveraging dataset-specific contextual information and missingness patterns to enhance imputation performance. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Lie2rOCgkh@OpenReview",
      "index": 73,
      "title": "Causal Attribution Analysis for Continuous Outcomes",
      "authors": [
        "Shanshan Luo",
        "Yu yixuan",
        "Chunchen LIU",
        "Feng Xie",
        "zhi geng"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "posterior",
        "estimands",
        "causal",
        "outcome",
        "attribution",
        "continuous",
        "binarizing",
        "ignorability",
        "hypertension",
        "outcomes"
      ],
      "summary": "Previous studies have extensively addressed the attribution problem for binary outcome variables. However, in many practical scenarios, the outcome variable is continuous, and simply binarizing it may result in information loss or biased conclusions. To address this issue, we propose a series of posterior causal estimands for retrospectively evaluating multiple correlated causes from a continuous outcome. These estimands include posterior intervention effects, posterior total causal effects, and posterior natural direct effects. Under assumptions of sequential ignorability, monotonicity, and perfect positive rank, we show that the posterior causal estimands of interest are identifiable and present the corresponding identification equations. We also provide a simple but effective estimation procedure and establish asymptotic properties of the proposed estimators. An artificial hypertension example and a real developmental toxicity dataset are employed to illustrate our method.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Lie2rOCgkh"
        ],
        "venue": [
          "/venue/Lie2rOCgkh@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Lie2rOCgkh"
        ],
        "detail": [
          "https://openreview.net/forum?id=Lie2rOCgkh"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 2
      },
      "raw_excerpt": "Causal Attribution Analysis for Continuous Outcomes [PDF 4 ] [Copy] [Kimi 2 ] [REL] Authors : Shanshan Luo , Yu yixuan , Chunchen LIU , Feng Xie , zhi geng Previous studies have extensively addressed the attribution problem for binary outcome variables. However, in many practical scenarios, the outcome variable is continuous, and simply binarizing it may result in information loss or biased conclusions. To address this issue, we propose a series of posterior causal estimands for retrospectively evaluating multiple correlated causes from a continuous outcome. These estimands include posterior intervention effects, posterior total causal effects, and posterior natural direct effects. Under assumptions of sequential ignorability, monotonicity, and perfect positive rank, we show that the posterior causal estimands of interest are identifiable and present the corresponding identification equations. We also provide a simple but effective estimation procedure and establish asymptotic properties of the proposed estimators. An artificial hypertension example and a real developmental toxicity dataset are employed to illustrate our method. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Lktwi30g63@OpenReview",
      "index": 74,
      "title": "When and How Does CLIP Enable Domain and Compositional Generalization?",
      "authors": [
        "Elias Kempf",
        "Simon Schrodi",
        "Max Argus",
        "Thomas Brox"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "generalization",
        "domain",
        "clip",
        "compositional",
        "diversity",
        "unseen",
        "questions",
        "generalize",
        "training",
        "unanswered"
      ],
      "summary": "The remarkable generalization performance of contrastive vision-language models like CLIP is often attributed to the diversity of their training distributions. However, key questions remain unanswered: Can CLIP generalize to an entirely unseen domain when trained on a diverse mixture of domains (domain generalization)? Can it generalize to unseen classes within partially seen domains (compositional generalization)? What factors affect such generalization? To answer these questions, we trained CLIP models on systematically constructed training distributions with controlled domain diversity and object class exposure. Our experiments show that domain diversity is essential for both domain and compositional generalization, yet compositional generalization can be surprisingly weaker than domain generalization when the training distribution contains a suboptimal subset of the test domain. Through data-centric *and* mechanistic analyses, we find that successful generalization requires the learning of sufficiently shared representations in intermediate layers and circuits.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Lktwi30g63"
        ],
        "venue": [
          "/venue/Lktwi30g63@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Lktwi30g63"
        ],
        "detail": [
          "https://openreview.net/forum?id=Lktwi30g63"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": null
      },
      "raw_excerpt": "When and How Does CLIP Enable Domain and Compositional Generalization? [PDF 5 ] [Copy] [Kimi ] [REL] Authors : Elias Kempf , Simon Schrodi , Max Argus , Thomas Brox The remarkable generalization performance of contrastive vision-language models like CLIP is often attributed to the diversity of their training distributions. However, key questions remain unanswered: Can CLIP generalize to an entirely unseen domain when trained on a diverse mixture of domains (domain generalization)? Can it generalize to unseen classes within partially seen domains (compositional generalization)? What factors affect such generalization? To answer these questions, we trained CLIP models on systematically constructed training distributions with controlled domain diversity and object class exposure. Our experiments show that domain diversity is essential for both domain and compositional generalization, yet compositional generalization can be surprisingly weaker than domain generalization when the training distribution contains a suboptimal subset of the test domain. Through data-centric *and* mechanistic analyses, we find that successful generalization requires the learning of sufficiently shared representations in intermediate layers and circuits. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "GKqoqGCHTq@OpenReview",
      "index": 75,
      "title": "Improving Consistency Models with Generator-Augmented Flows",
      "authors": [
        "Thibaut Issenhuth",
        "Sangchul Lee",
        "Ludovic Dos Santos",
        "Jean-Yves Franceschi",
        "Chansoo Kim",
        "alain rakotomamonjy"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "consistency",
        "thibautissenhuth",
        "distillation",
        "discrepancy",
        "generator",
        "training",
        "transports",
        "imitate",
        "velocity",
        "corresponding"
      ],
      "summary": "Consistency models imitate the multi-step sampling of score-based diffusion in a single forward pass of a neural network.They can be learned in two ways: consistency distillation and consistency training. The former relies on the true velocity field of the corresponding differential equation, approximated by a pre-trained neural network.In contrast, the latter uses a single-sample Monte Carlo estimate of this velocity field.The related estimation error induces a discrepancy between consistency distillation and training that, we show, still holds in the continuous-time limit.To alleviate this issue, we propose a novel flow that transports noisy data towards their corresponding outputs derived from a consistency model.We prove that this flow reduces the previously identified discrepancy and the noise-data transport cost.Consequently, our method not only accelerates consistency training convergence but also enhances its overall performance. The code is available at https://github.com/thibautissenhuth/consistency_GC.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=GKqoqGCHTq"
        ],
        "venue": [
          "/venue/GKqoqGCHTq@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=GKqoqGCHTq"
        ],
        "detail": [
          "https://openreview.net/forum?id=GKqoqGCHTq"
        ]
      },
      "scores": {
        "pdf": 7,
        "kimi": 1
      },
      "raw_excerpt": "Improving Consistency Models with Generator-Augmented Flows [PDF 7 ] [Copy] [Kimi 1 ] [REL] Authors : Thibaut Issenhuth , Sangchul Lee , Ludovic Dos Santos , Jean-Yves Franceschi , Chansoo Kim , alain rakotomamonjy Consistency models imitate the multi-step sampling of score-based diffusion in a single forward pass of a neural network.They can be learned in two ways: consistency distillation and consistency training. The former relies on the true velocity field of the corresponding differential equation, approximated by a pre-trained neural network.In contrast, the latter uses a single-sample Monte Carlo estimate of this velocity field.The related estimation error induces a discrepancy between consistency distillation and training that, we show, still holds in the continuous-time limit.To alleviate this issue, we propose a novel flow that transports noisy data towards their corresponding outputs derived from a consistency model.We prove that this flow reduces the previously identified discrepancy and the noise-data transport cost.Consequently, our method not only accelerates consistency training convergence but also enhances its overall performance. The code is available at https://github.com/thibautissenhuth/consistency_GC. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "M7mVzCV6uU@OpenReview",
      "index": 76,
      "title": "Federated Generalised Variational Inference: A Robust Probabilistic Federated Learning Framework",
      "authors": [
        "Terje Mildner",
        "Oliver Hamelijnck",
        "Paris Giampouras",
        "Theodoros Damoulas"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "fedgvi",
        "federated",
        "misspecification",
        "robust",
        "variational",
        "probabilistic",
        "inference",
        "likelihood",
        "ashman",
        "robustness"
      ],
      "summary": "We introduce FedGVI, a probabilistic Federated Learning (FL) framework that is robust to both prior and likelihood misspecification. FedGVI addresses limitations in both frequentist and Bayesian FL by providing unbiased predictions under model misspecification, with calibrated uncertainty quantification. Our approach generalises previous FL approaches, specifically Partitioned Variational Inference (Ashman et al., 2022), by allowing robust and conjugate updates, decreasing computational complexity at the clients. We offer theoretical analysis in terms of fixed-point convergence, optimality of the cavity distribution, and provable robustness to likelihood misspecification. Further, we empirically demonstrate the effectiveness of FedGVI in terms of improved robustness and predictive performance on multiple synthetic and real world classification data sets.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=M7mVzCV6uU"
        ],
        "venue": [
          "/venue/M7mVzCV6uU@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=M7mVzCV6uU"
        ],
        "detail": [
          "https://openreview.net/forum?id=M7mVzCV6uU"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": null
      },
      "raw_excerpt": "Federated Generalised Variational Inference: A Robust Probabilistic Federated Learning Framework [PDF 4 ] [Copy] [Kimi ] [REL] Authors : Terje Mildner , Oliver Hamelijnck , Paris Giampouras , Theodoros Damoulas We introduce FedGVI, a probabilistic Federated Learning (FL) framework that is robust to both prior and likelihood misspecification. FedGVI addresses limitations in both frequentist and Bayesian FL by providing unbiased predictions under model misspecification, with calibrated uncertainty quantification. Our approach generalises previous FL approaches, specifically Partitioned Variational Inference (Ashman et al., 2022), by allowing robust and conjugate updates, decreasing computational complexity at the clients. We offer theoretical analysis in terms of fixed-point convergence, optimality of the cavity distribution, and provable robustness to likelihood misspecification. Further, we empirically demonstrate the effectiveness of FedGVI in terms of improved robustness and predictive performance on multiple synthetic and real world classification data sets. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "MHaSq1LlTe@OpenReview",
      "index": 77,
      "title": "Signed Laplacians for Constrained Graph Clustering",
      "authors": [
        "John Stewart Fabila-Carrasco",
        "He Sun"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "clustering",
        "signed",
        "constrained",
        "setminus",
        "laplacians",
        "subset",
        "problem",
        "minimises",
        "streamlining",
        "cheeger"
      ],
      "summary": "Given two weighted graphs G = ( V , E , w G ) G = ( V , E , w G ) and H = ( V , F , w H ) H = ( V , F , w H ) defined on the same vertex set, the constrained clustering problem seeks to find a subset S ⊂ V S ⊂ V that minimises the cut ratio between w G ( S , V ∖ S ) w G ( S , V ∖ S ) and w H ( S , V ∖ S ) w H ( S , V ∖ S ) . In this work, we establish a Cheeger-type inequality that relates the solution of the constrained clustering problem to the spectral properties of G G and H H . To reduce computational complexity, we utilise the signed Laplacian of H H , streamlining calculations while maintaining accuracy. By solving a generalised eigenvalue problem, our proposed algorithm achieves notable performance improvements, particularly in challenging scenarios where traditional spectral clustering methods struggle. We demonstrate its practical effectiveness through experiments on both synthetic and real-world datasets.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=MHaSq1LlTe"
        ],
        "venue": [
          "/venue/MHaSq1LlTe@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=MHaSq1LlTe"
        ],
        "detail": [
          "https://openreview.net/forum?id=MHaSq1LlTe"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "Signed Laplacians for Constrained Graph Clustering [PDF 3 ] [Copy] [Kimi 1 ] [REL] Authors : John Stewart Fabila-Carrasco , He Sun Given two weighted graphs G = ( V , E , w G ) G = ( V , E , w G ) and H = ( V , F , w H ) H = ( V , F , w H ) defined on the same vertex set, the constrained clustering problem seeks to find a subset S ⊂ V S ⊂ V that minimises the cut ratio between w G ( S , V ∖ S ) w G ( S , V ∖ S ) and w H ( S , V ∖ S ) w H ( S , V ∖ S ) . In this work, we establish a Cheeger-type inequality that relates the solution of the constrained clustering problem to the spectral properties of G G and H H . To reduce computational complexity, we utilise the signed Laplacian of H H , streamlining calculations while maintaining accuracy. By solving a generalised eigenvalue problem, our proposed algorithm achieves notable performance improvements, particularly in challenging scenarios where traditional spectral clustering methods struggle. We demonstrate its practical effectiveness through experiments on both synthetic and real-world datasets. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "MkCnPNOLMk@OpenReview",
      "index": 78,
      "title": "Towards Better-than-2 Approximation for Constrained Correlation Clustering",
      "authors": [
        "Andreas Kalavas",
        "Evangelos Kipouridis",
        "Nithin Varma"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "constrained",
        "clustering",
        "clusters",
        "approximation",
        "correlation",
        "zuylen",
        "cluster",
        "mandating",
        "better",
        "edges"
      ],
      "summary": "In the Correlation Clustering problem, we are given an undirected graph and are tasked with computing a clustering (partition of the nodes) that minimizes the sum of the number of edges across different clusters and the number of non-edges within clusters. In the constrained version of this problem, the goal is to compute a clustering that satisfies additional hard constraints mandating certain pairs to be in the same cluster and certain pairs to be in different clusters. Constrained Correlation Clustering is APX-Hard, and the best known approximation factor is 3 (van Zuylen et al. [SODA '07]). In this work, we show that in order to obtain a better-than-2 approximation, solving the (exponentially large) Constrained Cluster LP would be sufficient.[The peer-reviewed version of this article claimed an efficient algorithm for solving the Constrained Cluster LP. An error in the proof, that the authors discovered after the review process, led them to revise the results to be conditional on the existence of a valid LP solution.]",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=MkCnPNOLMk"
        ],
        "venue": [
          "/venue/MkCnPNOLMk@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=MkCnPNOLMk"
        ],
        "detail": [
          "https://openreview.net/forum?id=MkCnPNOLMk"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": null
      },
      "raw_excerpt": "Towards Better-than-2 Approximation for Constrained Correlation Clustering [PDF 3 ] [Copy] [Kimi ] [REL] Authors : Andreas Kalavas , Evangelos Kipouridis , Nithin Varma In the Correlation Clustering problem, we are given an undirected graph and are tasked with computing a clustering (partition of the nodes) that minimizes the sum of the number of edges across different clusters and the number of non-edges within clusters. In the constrained version of this problem, the goal is to compute a clustering that satisfies additional hard constraints mandating certain pairs to be in the same cluster and certain pairs to be in different clusters. Constrained Correlation Clustering is APX-Hard, and the best known approximation factor is 3 (van Zuylen et al. [SODA '07]). In this work, we show that in order to obtain a better-than-2 approximation, solving the (exponentially large) Constrained Cluster LP would be sufficient.[The peer-reviewed version of this article claimed an efficient algorithm for solving the Constrained Cluster LP. An error in the proof, that the authors discovered after the review process, led them to revise the results to be conditional on the existence of a valid LP solution.] Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "O0oe7hPtbl@OpenReview",
      "index": 79,
      "title": "Gridded Transformer Neural Processes for Spatio-Temporal Data",
      "authors": [
        "Matthew Ashman",
        "Cristiana Diaconu",
        "Eric Langezaal",
        "Adrian Weller",
        "Richard E Turner"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "gridded",
        "tnps",
        "spatio",
        "processes",
        "temporal",
        "data",
        "transformer",
        "neural",
        "pseudo",
        "scale"
      ],
      "summary": "Effective modelling of large-scale spatio-temporal datasets is essential for many domains, yet existing approaches often impose rigid constraints on the input data, such as requiring them to lie on fixed-resolution grids. With the rise of foundation models, the ability to process diverse, heterogeneous data structures is becoming increasingly important. Neural processes (NPs), particularly transformer neural processes (TNPs), offer a promising framework for such tasks, but struggle to scale to large spatio-temporal datasets due to the lack of an efficient attention mechanism. To address this, we introduce gridded pseudo-token TNPs which employ specialised encoders and decoders to handle unstructured data and utilise a processor comprising gridded pseudo-tokens with efficient attention mechanisms. Furthermore, we develop equivariant gridded TNPs for applications where exact or approximate translation equivariance is a useful inductive bias, improving accuracy and training efficiency. Our method consistently outperforms a range of strong baselines in various synthetic and real-world regression tasks involving large-scale data, while maintaining competitive computational efficiency. Experiments with weather data highlight the potential of gridded TNPs and serve as just one example of a domain where they can have a significant impact.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=O0oe7hPtbl"
        ],
        "venue": [
          "/venue/O0oe7hPtbl@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=O0oe7hPtbl"
        ],
        "detail": [
          "https://openreview.net/forum?id=O0oe7hPtbl"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 2
      },
      "raw_excerpt": "Gridded Transformer Neural Processes for Spatio-Temporal Data [PDF 4 ] [Copy] [Kimi 2 ] [REL] Authors : Matthew Ashman , Cristiana Diaconu , Eric Langezaal , Adrian Weller , Richard E Turner Effective modelling of large-scale spatio-temporal datasets is essential for many domains, yet existing approaches often impose rigid constraints on the input data, such as requiring them to lie on fixed-resolution grids. With the rise of foundation models, the ability to process diverse, heterogeneous data structures is becoming increasingly important. Neural processes (NPs), particularly transformer neural processes (TNPs), offer a promising framework for such tasks, but struggle to scale to large spatio-temporal datasets due to the lack of an efficient attention mechanism. To address this, we introduce gridded pseudo-token TNPs which employ specialised encoders and decoders to handle unstructured data and utilise a processor comprising gridded pseudo-tokens with efficient attention mechanisms. Furthermore, we develop equivariant gridded TNPs for applications where exact or approximate translation equivariance is a useful inductive bias, improving accuracy and training efficiency. Our method consistently outperforms a range of strong baselines in various synthetic and real-world regression tasks involving large-scale data, while maintaining competitive computational efficiency. Experiments with weather data highlight the potential of gridded TNPs and serve as just one example of a domain where they can have a significant impact. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "O6q2BHK1BL@OpenReview",
      "index": 80,
      "title": "Local Identifying Causal Relations in the Presence of Latent Variables",
      "authors": [
        "Zheng Li",
        "Zeyu Liu",
        "Feng Xie",
        "Hao Zhang",
        "Chunchen LIU",
        "zhi geng"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "causal",
        "identifying",
        "relationships",
        "variables",
        "latent",
        "pag",
        "local",
        "observational",
        "ancestral",
        "algorithms"
      ],
      "summary": "We tackle the problem of identifying whether a variable is the cause of a specified target using observational data. State-of-the-art causal learning algorithms that handle latent variables typically rely on identifying the global causal structure, often represented as a partial ancestral graph (PAG), to infer causal relationships. Although effective, these approaches are often redundant and computationally expensive when the focus is limited to a specific causal relationship. In this work, we introduce novel local characterizations that are necessary and sufficient for various types of causal relationships between two variables, enabling us to bypass the need for global structure learning. Leveraging these local insights, we develop efficient and fully localized algorithms that accurately identify causal relationships from observational data. We theoretically demonstrate the soundness and completeness of our approach. Extensive experiments on benchmark networks and real-world datasets further validate the effectiveness and efficiency of our method.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=O6q2BHK1BL"
        ],
        "venue": [
          "/venue/O6q2BHK1BL@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=O6q2BHK1BL"
        ],
        "detail": [
          "https://openreview.net/forum?id=O6q2BHK1BL"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": null
      },
      "raw_excerpt": "Local Identifying Causal Relations in the Presence of Latent Variables [PDF 3 ] [Copy] [Kimi ] [REL] Authors : Zheng Li , Zeyu Liu , Feng Xie , Hao Zhang , Chunchen LIU , zhi geng We tackle the problem of identifying whether a variable is the cause of a specified target using observational data. State-of-the-art causal learning algorithms that handle latent variables typically rely on identifying the global causal structure, often represented as a partial ancestral graph (PAG), to infer causal relationships. Although effective, these approaches are often redundant and computationally expensive when the focus is limited to a specific causal relationship. In this work, we introduce novel local characterizations that are necessary and sufficient for various types of causal relationships between two variables, enabling us to bypass the need for global structure learning. Leveraging these local insights, we develop efficient and fully localized algorithms that accurately identify causal relationships from observational data. We theoretically demonstrate the soundness and completeness of our approach. Extensive experiments on benchmark networks and real-world datasets further validate the effectiveness and efficiency of our method. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "OJ6WE7F8tK@OpenReview",
      "index": 81,
      "title": "Direct Discriminative Optimization: Your Likelihood-Based Visual Generative Model is Secretly a GAN Discriminator",
      "authors": [
        "Kaiwen Zheng",
        "Yongxin Chen",
        "Huayu Chen",
        "Guande He",
        "Ming-Yu Liu",
        "Jun Zhu",
        "Qinsheng Zhang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "ddo",
        "likelihood",
        "discriminator",
        "direct",
        "imagenet",
        "generative",
        "mle",
        "512",
        "256",
        "discriminative"
      ],
      "summary": "While likelihood-based generative models, particularly diffusion and autoregressive models, have achieved remarkable fidelity in visual generation, the maximum likelihood estimation (MLE) objective, which minimizes the forward KL divergence, inherently suffers from a mode-covering tendency that limits the generation quality under limited model capacity. In this work, we propose Direct Discriminative Optimization (DDO) as a unified framework that integrates likelihood-based generative training and GAN-type discrimination to bypass this fundamental constraint by exploiting reverse KL and self-generated negative signals. Our key insight is to parameterize a discriminator implicitly using the likelihood ratio between a learnable target model and a fixed reference model, drawing parallels with the philosophy of Direct Preference Optimization (DPO). Unlike GANs, this parameterization eliminates the need for joint training of generator and discriminator networks, allowing for direct, efficient, and effective finetuning of a well-trained model to its full potential beyond the limits of MLE. DDO can be performed iteratively in a self-play manner for progressive model refinement, with each round requiring less than 1\\% of pretraining epochs. Our experiments demonstrate the effectiveness of DDO by significantly advancing the previous SOTA diffusion model EDM, reducing FID scores from 1.79/1.58/1.96 to new records of 1.30/0.97/1.26 on CIFAR-10/ImageNet-64/ImageNet 512 × × 512 datasets without any guidance mechanisms, and by consistently improving both guidance-free and CFG-enhanced FIDs of visual autoregressive models on ImageNet 256 × × 256.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=OJ6WE7F8tK"
        ],
        "venue": [
          "/venue/OJ6WE7F8tK@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=OJ6WE7F8tK"
        ],
        "detail": [
          "https://openreview.net/forum?id=OJ6WE7F8tK"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 2
      },
      "raw_excerpt": "Direct Discriminative Optimization: Your Likelihood-Based Visual Generative Model is Secretly a GAN Discriminator [PDF 4 ] [Copy] [Kimi 2 ] [REL] Authors : Kaiwen Zheng , Yongxin Chen , Huayu Chen , Guande He , Ming-Yu Liu , Jun Zhu , Qinsheng Zhang While likelihood-based generative models, particularly diffusion and autoregressive models, have achieved remarkable fidelity in visual generation, the maximum likelihood estimation (MLE) objective, which minimizes the forward KL divergence, inherently suffers from a mode-covering tendency that limits the generation quality under limited model capacity. In this work, we propose Direct Discriminative Optimization (DDO) as a unified framework that integrates likelihood-based generative training and GAN-type discrimination to bypass this fundamental constraint by exploiting reverse KL and self-generated negative signals. Our key insight is to parameterize a discriminator implicitly using the likelihood ratio between a learnable target model and a fixed reference model, drawing parallels with the philosophy of Direct Preference Optimization (DPO). Unlike GANs, this parameterization eliminates the need for joint training of generator and discriminator networks, allowing for direct, efficient, and effective finetuning of a well-trained model to its full potential beyond the limits of MLE. DDO can be performed iteratively in a self-play manner for progressive model refinement, with each round requiring less than 1\\% of pretraining epochs. Our experiments demonstrate the effectiveness of DDO by significantly advancing the previous SOTA diffusion model EDM, reducing FID scores from 1.79/1.58/1.96 to new records of 1.30/0.97/1.26 on CIFAR-10/ImageNet-64/ImageNet 512 × × 512 datasets without any guidance mechanisms, and by consistently improving both guidance-free and CFG-enhanced FIDs of visual autoregressive models on ImageNet 256 × × 256. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Obet2x6GNl@OpenReview",
      "index": 82,
      "title": "Algorithms with Calibrated Machine Learning Predictions",
      "authors": [
        "Judy Hanwen Shen",
        "Ellen Vitercik",
        "Anders Wikum"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "calibrated",
        "advice",
        "ski",
        "rental",
        "algorithms",
        "predictions",
        "machine",
        "job",
        "scheduling",
        "online"
      ],
      "summary": "The field of *algorithms with predictions* incorporates machine learning advice in the design of online algorithms to improve real-world performance. A central consideration is the extent to which predictions can be trusted—while existing approaches often require users to specify an aggregate trust level, modern machine learning models can provide estimates of prediction-level uncertainty. In this paper, we propose *calibration* as a principled and practical tool to bridge this gap, demonstrating the benefits of calibrated advice through two case studies: the *ski rental* and *online job scheduling* problems. For ski rental, we design an algorithm that achieves near-optimal prediction-dependent performance and prove that, in high-variance settings, calibrated advice offers more effective guidance than alternative methods for uncertainty quantification. For job scheduling, we demonstrate that using a calibrated predictor leads to significant performance improvements over existing methods. Evaluations on real-world data validate our theoretical findings, highlighting the practical impact of calibration for algorithms with predictions.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Obet2x6GNl"
        ],
        "venue": [
          "/venue/Obet2x6GNl@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Obet2x6GNl"
        ],
        "detail": [
          "https://openreview.net/forum?id=Obet2x6GNl"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": null
      },
      "raw_excerpt": "Algorithms with Calibrated Machine Learning Predictions [PDF 2 ] [Copy] [Kimi ] [REL] Authors : Judy Hanwen Shen , Ellen Vitercik , Anders Wikum The field of *algorithms with predictions* incorporates machine learning advice in the design of online algorithms to improve real-world performance. A central consideration is the extent to which predictions can be trusted—while existing approaches often require users to specify an aggregate trust level, modern machine learning models can provide estimates of prediction-level uncertainty. In this paper, we propose *calibration* as a principled and practical tool to bridge this gap, demonstrating the benefits of calibrated advice through two case studies: the *ski rental* and *online job scheduling* problems. For ski rental, we design an algorithm that achieves near-optimal prediction-dependent performance and prove that, in high-variance settings, calibrated advice offers more effective guidance than alternative methods for uncertainty quantification. For job scheduling, we demonstrate that using a calibrated predictor leads to significant performance improvements over existing methods. Evaluations on real-world data validate our theoretical findings, highlighting the practical impact of calibration for algorithms with predictions. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "OpineZj5bj@OpenReview",
      "index": 83,
      "title": "Revisiting Continuity of Image Tokens for Cross-domain Few-shot Learning",
      "authors": [
        "Shuai Yi",
        "Yixiong Zou",
        "Yuhua Li",
        "Ruixuan Li"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "continuity",
        "domain",
        "vit",
        "tokens",
        "cdfsl",
        "gaps",
        "smaller",
        "image",
        "shot",
        "domains"
      ],
      "summary": "Vision Transformer (ViT) has achieved remarkable success due to its large-scale pretraining on general domains, but it still faces challenges when applying it to downstream distant domains that have only scarce training data, which gives rise to the Cross-Domain Few-Shot Learning (CDFSL) task. Inspired by Self-Attention's insensitivity to token orders, we find an interesting phenomenon neglected in current works: disrupting the continuity of image tokens (i.e., making pixels not smoothly transited across patches) in ViT leads to a noticeable performance decline in the general (source) domain but only a marginal decrease in downstream target domains. This questions the role of image tokens' continuity in ViT's generalization under large domain gaps. In this paper, we delve into this phenomenon for an interpretation. We find continuity aids ViT in learning larger spatial patterns, which are harder to transfer than smaller ones, enlarging domain distances. Meanwhile, it implies that only smaller patterns within each patch could be transferred under extreme domain gaps. Based on this interpretation, we further propose a simple yet effective method for CDFSL that better disrupts the continuity of image tokens, encouraging the model to rely less on large patterns and more on smaller ones. Extensive experiments show the effectiveness of our method in reducing domain gaps and outperforming state-of-the-art works. Codes and models are available at https://github.com/shuaiyi308/ReCIT.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=OpineZj5bj"
        ],
        "venue": [
          "/venue/OpineZj5bj@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=OpineZj5bj"
        ],
        "detail": [
          "https://openreview.net/forum?id=OpineZj5bj"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Revisiting Continuity of Image Tokens for Cross-domain Few-shot Learning [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Shuai Yi , Yixiong Zou , Yuhua Li , Ruixuan Li Vision Transformer (ViT) has achieved remarkable success due to its large-scale pretraining on general domains, but it still faces challenges when applying it to downstream distant domains that have only scarce training data, which gives rise to the Cross-Domain Few-Shot Learning (CDFSL) task. Inspired by Self-Attention's insensitivity to token orders, we find an interesting phenomenon neglected in current works: disrupting the continuity of image tokens (i.e., making pixels not smoothly transited across patches) in ViT leads to a noticeable performance decline in the general (source) domain but only a marginal decrease in downstream target domains. This questions the role of image tokens' continuity in ViT's generalization under large domain gaps. In this paper, we delve into this phenomenon for an interpretation. We find continuity aids ViT in learning larger spatial patterns, which are harder to transfer than smaller ones, enlarging domain distances. Meanwhile, it implies that only smaller patterns within each patch could be transferred under extreme domain gaps. Based on this interpretation, we further propose a simple yet effective method for CDFSL that better disrupts the continuity of image tokens, encouraging the model to rely less on large patterns and more on smaller ones. Extensive experiments show the effectiveness of our method in reducing domain gaps and outperforming state-of-the-art works. Codes and models are available at https://github.com/shuaiyi308/ReCIT. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "PUzNwYmb3l@OpenReview",
      "index": 84,
      "title": "Efficient First-Order Optimization on the Pareto Set for Multi-Objective Learning under Preference Guidance",
      "authors": [
        "Lisha Chen",
        "Quan Xiao",
        "Ellen Fukuda",
        "Xinyi Chen",
        "Kun Yuan",
        "Tianyi Chen"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "objective",
        "preference",
        "problem",
        "pareto",
        "multi",
        "bilevel",
        "semivectorial",
        "optimization",
        "merit",
        "reformulation"
      ],
      "summary": "Multi-objective learning under user-specified preference is common in real-world problems such as multi-lingual speech recognition under fairness. In this work, we frame such a problem as a semivectorial bilevel optimization problem, whose goal is to optimize a pre-defined preference function, subject to the constraint that the model parameters are weakly Pareto optimal. To solve this problem, we convert the multi-objective constraints to a single-objective constraint through a merit function with an easy-to-evaluate gradient, and then, we use a penalty-based reformulation of the bilevel optimization problem. We theoretically establish the properties of the merit function, and the relations of solutions for the penalty reformulation and the constrained formulation. Then we propose algorithms to solve the reformulated single-level problem, and establish its convergence guarantees. We test the method on various synthetic and real-world problems. The results demonstrate the effectiveness of the proposed method in finding preference-guided optimal solutions to the multi-objective problem.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=PUzNwYmb3l"
        ],
        "venue": [
          "/venue/PUzNwYmb3l@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=PUzNwYmb3l"
        ],
        "detail": [
          "https://openreview.net/forum?id=PUzNwYmb3l"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": null
      },
      "raw_excerpt": "Efficient First-Order Optimization on the Pareto Set for Multi-Objective Learning under Preference Guidance [PDF 3 ] [Copy] [Kimi ] [REL] Authors : Lisha Chen , Quan Xiao , Ellen Fukuda , Xinyi Chen , Kun Yuan , Tianyi Chen Multi-objective learning under user-specified preference is common in real-world problems such as multi-lingual speech recognition under fairness. In this work, we frame such a problem as a semivectorial bilevel optimization problem, whose goal is to optimize a pre-defined preference function, subject to the constraint that the model parameters are weakly Pareto optimal. To solve this problem, we convert the multi-objective constraints to a single-objective constraint through a merit function with an easy-to-evaluate gradient, and then, we use a penalty-based reformulation of the bilevel optimization problem. We theoretically establish the properties of the merit function, and the relations of solutions for the penalty reformulation and the constrained formulation. Then we propose algorithms to solve the reformulated single-level problem, and establish its convergence guarantees. We test the method on various synthetic and real-world problems. The results demonstrate the effectiveness of the proposed method in finding preference-guided optimal solutions to the multi-objective problem. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Ppcf30NGL0@OpenReview",
      "index": 85,
      "title": "New Bounds for Sparse Variational Gaussian Processes",
      "authors": [
        "Michalis Titsias"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "variational",
        "sparse",
        "bound",
        "gaussian",
        "tractable",
        "posterior",
        "processes",
        "assumption",
        "extra",
        "distribution"
      ],
      "summary": "Sparse variational Gaussian processes (GPs) construct tractable posterior approximations to GP models. At the core of these methods is the assumption that the true posterior distribution over training function values f f and inducing variables u u is approximated by a variational distribution that incorporates the conditional GP prior p ( f | u ) p ( f | u ) in its factorization. While this assumption is considered as fundamental, we show that for model training we can relax it through the use of a more general variational distribution q ( f | u ) q ( f | u ) that depends on N N extra parameters, where N N is the number of training examples. In GP regression, we can analytically optimize the evidence lower bound over the extra parameters and express a tractable collapsed bound that is tighter than the previous bound. The new bound is also amenable to stochastic optimization and its implementation requires minor modifications to existing sparse GP code. Further, we also describe extensions to non-Gaussian likelihoods. On several datasets we demonstrate that our method can reduce bias when learning the hyperparameters and can lead to better predictive performance.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Ppcf30NGL0"
        ],
        "venue": [
          "/venue/Ppcf30NGL0@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Ppcf30NGL0"
        ],
        "detail": [
          "https://openreview.net/forum?id=Ppcf30NGL0"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": null
      },
      "raw_excerpt": "New Bounds for Sparse Variational Gaussian Processes [PDF 3 ] [Copy] [Kimi ] [REL] Author : Michalis Titsias Sparse variational Gaussian processes (GPs) construct tractable posterior approximations to GP models. At the core of these methods is the assumption that the true posterior distribution over training function values f f and inducing variables u u is approximated by a variational distribution that incorporates the conditional GP prior p ( f | u ) p ( f | u ) in its factorization. While this assumption is considered as fundamental, we show that for model training we can relax it through the use of a more general variational distribution q ( f | u ) q ( f | u ) that depends on N N extra parameters, where N N is the number of training examples. In GP regression, we can analytically optimize the evidence lower bound over the extra parameters and express a tractable collapsed bound that is tighter than the previous bound. The new bound is also amenable to stochastic optimization and its implementation requires minor modifications to existing sparse GP code. Further, we also describe extensions to non-Gaussian likelihoods. On several datasets we demonstrate that our method can reduce bias when learning the hyperparameters and can lead to better predictive performance. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "PzSG5nKe1q@OpenReview",
      "index": 86,
      "title": "RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning",
      "authors": [
        "Jonas Gehring",
        "Kunhao Zheng",
        "Jade Copet",
        "Vegard Mella",
        "Taco Cohen",
        "Gabriel Synnaeve"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "llms",
        "feedback",
        "rlef",
        "execution",
        "code",
        "reinforcement",
        "grounding",
        "steps",
        "leverage",
        "70b"
      ],
      "summary": "Large language models (LLMs) deployed as agents solve user-specified tasks over multiple steps while keeping the required manual engagement to a minimum. Crucially, such LLMs need to ground their generations in any feedback obtained to reliably achieve the desired outcomes. We propose an end-to-end reinforcement learning method for teaching models to leverage execution feedback in the realm of code synthesis, where state-of-the-art LLMs struggle to improve code iteratively compared to independent sampling. We benchmark on competitive programming tasks and achieve large performance gains with both small (8B parameters) and large (70B) models, outperforming previous work while reducing the number of samples required by an order of magnitude. Our analysis of inference-time behavior demonstrates that our method produces LLMs that effectively leverage automatic feedback over multiple steps.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=PzSG5nKe1q"
        ],
        "venue": [
          "/venue/PzSG5nKe1q@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=PzSG5nKe1q"
        ],
        "detail": [
          "https://openreview.net/forum?id=PzSG5nKe1q"
        ]
      },
      "scores": {
        "pdf": 9,
        "kimi": 8
      },
      "raw_excerpt": "RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning [PDF 9 ] [Copy] [Kimi 8 ] [REL] Authors : Jonas Gehring , Kunhao Zheng , Jade Copet , Vegard Mella , Taco Cohen , Gabriel Synnaeve Large language models (LLMs) deployed as agents solve user-specified tasks over multiple steps while keeping the required manual engagement to a minimum. Crucially, such LLMs need to ground their generations in any feedback obtained to reliably achieve the desired outcomes. We propose an end-to-end reinforcement learning method for teaching models to leverage execution feedback in the realm of code synthesis, where state-of-the-art LLMs struggle to improve code iteratively compared to independent sampling. We benchmark on competitive programming tasks and achieve large performance gains with both small (8B parameters) and large (70B) models, outperforming previous work while reducing the number of samples required by an order of magnitude. Our analysis of inference-time behavior demonstrates that our method produces LLMs that effectively leverage automatic feedback over multiple steps. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Q3rGQUGgWo@OpenReview",
      "index": 87,
      "title": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation",
      "authors": [
        "jiayue Liu",
        "Zhongchao Yi",
        "Zhengyang Zhou",
        "Qihe Huang",
        "Kuo Yang",
        "Xu Wang",
        "Yang Wang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "synevo",
        "spatiotemporal",
        "rodger",
        "evolutional",
        "cross",
        "domain",
        "lau",
        "container",
        "learners",
        "neuroai"
      ],
      "summary": "Discovering regularities from spatiotemporal systems can benefit various scientific and social planning. Current spatiotemporal learners usually train an independent model from a specific source data that leads to limited transferability among sources, where even correlated tasks requires new design and training. The key towards increasing cross-domain knowledge is to enable collective intelligence and model evolution. In this paper, inspired by neuroscience theories, we theoretically derive the increased information boundary via learning cross-domain collective intelligence and propose a Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the model independence and enables cross-domain knowledge to be shared and aggregated. Specifically, we first re-order the sample groups to imitate the human curriculum learning, and devise two complementary learners, elastic common container and task-independent extractor to allow model growth and task-wise commonality and personality disentanglement. Then an adaptive dynamic coupler with a new difference metric determines whether the new sample group should be incorporated into common container to achieve model evolution under various domains. Experiments show that SynEVO improves the generalization capacity by at most 42\\% under cross-domain scenarios and SynEVO provides a paradigm of NeuroAI for knowledge transfer and adaptation.Code available at [https://github.com/Rodger-Lau/SynEVO](https://github.com/Rodger-Lau/SynEVO).",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Q3rGQUGgWo"
        ],
        "venue": [
          "/venue/Q3rGQUGgWo@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Q3rGQUGgWo"
        ],
        "detail": [
          "https://openreview.net/forum?id=Q3rGQUGgWo"
        ]
      },
      "scores": {
        "pdf": 6,
        "kimi": 2
      },
      "raw_excerpt": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation [PDF 6 ] [Copy] [Kimi 2 ] [REL] Authors : jiayue Liu , Zhongchao Yi , Zhengyang Zhou , Qihe Huang , Kuo Yang , Xu Wang , Yang Wang Discovering regularities from spatiotemporal systems can benefit various scientific and social planning. Current spatiotemporal learners usually train an independent model from a specific source data that leads to limited transferability among sources, where even correlated tasks requires new design and training. The key towards increasing cross-domain knowledge is to enable collective intelligence and model evolution. In this paper, inspired by neuroscience theories, we theoretically derive the increased information boundary via learning cross-domain collective intelligence and propose a Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the model independence and enables cross-domain knowledge to be shared and aggregated. Specifically, we first re-order the sample groups to imitate the human curriculum learning, and devise two complementary learners, elastic common container and task-independent extractor to allow model growth and task-wise commonality and personality disentanglement. Then an adaptive dynamic coupler with a new difference metric determines whether the new sample group should be incorporated into common container to achieve model evolution under various domains. Experiments show that SynEVO improves the generalization capacity by at most 42\\% under cross-domain scenarios and SynEVO provides a paradigm of NeuroAI for knowledge transfer and adaptation.Code available at [https://github.com/Rodger-Lau/SynEVO](https://github.com/Rodger-Lau/SynEVO). Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "QC4dfobOLQ@OpenReview",
      "index": 88,
      "title": "Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws",
      "authors": [
        "Xiyuan Wei",
        "Ming Lin",
        "Fanjiang Ye",
        "Fengguang Song",
        "Liangliang Cao",
        "My T. Thai",
        "Tianbao Yang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "drrho",
        "clip",
        "steering",
        "reference",
        "model",
        "insights",
        "dro",
        "generalization",
        "improves",
        "optimization"
      ],
      "summary": "This paper formalizes an emerging learning paradigm that uses a trained model as a reference to guide and enhance the training of a target model through strategic data selection or weighting, named **model steering**. While ad-hoc methods have been used in various contexts, including the training of large foundation models, its underlying principles remain insufficiently understood, leading to sub-optimal performance. In this work, we propose a theory-driven framework for model steering called **DRRho risk minimization**, which is rooted in Distributionally Robust Optimization (DRO). Through a generalization analysis, we provide theoretical insights into why this approach improves generalization and data efficiency compared to training without a reference model. To the best of our knowledge, this is the first time such theoretical insights are provided for the new learning paradigm, which significantly enhance our understanding and practice of model steering. Building on these insights and the connection between contrastive learning and DRO, we introduce a novel method for Contrastive Language-Image Pretraining (CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments validate the theoretical insights, reveal a superior scaling law compared to CLIP without a reference model, and demonstrate its strength over existing heuristic approaches. Code is released at [github.com/Optimization-AI/DRRho-CLIP](https://github.com/Optimization-AI/DRRho-CLIP)",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=QC4dfobOLQ"
        ],
        "venue": [
          "/venue/QC4dfobOLQ@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=QC4dfobOLQ"
        ],
        "detail": [
          "https://openreview.net/forum?id=QC4dfobOLQ"
        ]
      },
      "scores": {
        "pdf": 6,
        "kimi": 3
      },
      "raw_excerpt": "Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws [PDF 6 ] [Copy] [Kimi 3 ] [REL] Authors : Xiyuan Wei , Ming Lin , Fanjiang Ye , Fengguang Song , Liangliang Cao , My T. Thai , Tianbao Yang This paper formalizes an emerging learning paradigm that uses a trained model as a reference to guide and enhance the training of a target model through strategic data selection or weighting, named **model steering**. While ad-hoc methods have been used in various contexts, including the training of large foundation models, its underlying principles remain insufficiently understood, leading to sub-optimal performance. In this work, we propose a theory-driven framework for model steering called **DRRho risk minimization**, which is rooted in Distributionally Robust Optimization (DRO). Through a generalization analysis, we provide theoretical insights into why this approach improves generalization and data efficiency compared to training without a reference model. To the best of our knowledge, this is the first time such theoretical insights are provided for the new learning paradigm, which significantly enhance our understanding and practice of model steering. Building on these insights and the connection between contrastive learning and DRO, we introduce a novel method for Contrastive Language-Image Pretraining (CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments validate the theoretical insights, reveal a superior scaling law compared to CLIP without a reference model, and demonstrate its strength over existing heuristic approaches. Code is released at [github.com/Optimization-AI/DRRho-CLIP](https://github.com/Optimization-AI/DRRho-CLIP) Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "S2K5MyRjrL@OpenReview",
      "index": 89,
      "title": "Enhancing Certified Robustness via Block Reflector Orthogonal Layers and Logit Annealing Loss",
      "authors": [
        "Bo-Han Lai",
        "Pin-Han Huang",
        "Bo-Han Kung",
        "Shang-Tse Chen"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "certified",
        "lipschitz",
        "bro",
        "robustness",
        "reflector",
        "bronet",
        "orthogonal",
        "annealing",
        "loss",
        "block"
      ],
      "summary": "Lipschitz neural networks are well-known for providing certified robustness in deep learning. In this paper, we present a novel, efficient Block Reflector Orthogonal (BRO) layer that enhances the capability of orthogonal layers on constructing more expressive Lipschitz neural architectures. In addition, by theoretically analyzing the nature of Lipschitz neural networks, we introduce a new loss function that employs an annealing mechanism to increase margin for most data points. This enables Lipschitz models to provide better certified robustness. By employing our BRO layer and loss function, we design BRONet — a simple yet effective Lipschitz neural network that achieves state-of-the-art certified robustness. Extensive experiments and empirical analysis on CIFAR-10/100, Tiny-ImageNet, and ImageNet validate that our method outperforms existing baselines. The implementation is available at [GitHub Link](https://github.com/ntuaislab/BRONet).",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=S2K5MyRjrL"
        ],
        "venue": [
          "/venue/S2K5MyRjrL@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=S2K5MyRjrL"
        ],
        "detail": [
          "https://openreview.net/forum?id=S2K5MyRjrL"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Enhancing Certified Robustness via Block Reflector Orthogonal Layers and Logit Annealing Loss [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Bo-Han Lai , Pin-Han Huang , Bo-Han Kung , Shang-Tse Chen Lipschitz neural networks are well-known for providing certified robustness in deep learning. In this paper, we present a novel, efficient Block Reflector Orthogonal (BRO) layer that enhances the capability of orthogonal layers on constructing more expressive Lipschitz neural architectures. In addition, by theoretically analyzing the nature of Lipschitz neural networks, we introduce a new loss function that employs an annealing mechanism to increase margin for most data points. This enables Lipschitz models to provide better certified robustness. By employing our BRO layer and loss function, we design BRONet — a simple yet effective Lipschitz neural network that achieves state-of-the-art certified robustness. Extensive experiments and empirical analysis on CIFAR-10/100, Tiny-ImageNet, and ImageNet validate that our method outperforms existing baselines. The implementation is available at [GitHub Link](https://github.com/ntuaislab/BRONet). Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "SnZ7SKykHh@OpenReview",
      "index": 90,
      "title": "PokéChamp: an Expert-level Minimax Language Agent",
      "authors": [
        "Seth Karten",
        "Andy Nguyen",
        "Chi Jin"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "pokéchamp",
        "pokémon",
        "minimax",
        "llm",
        "bot",
        "agent",
        "elo",
        "powered",
        "player",
        "battle"
      ],
      "summary": "We introduce PokéChamp, a minimax agent powered by Large Language Models (LLMs) for Pokémon battles. Built on a general framework for two-player competitive games, PokéChamp leverages the generalist capabilities of LLMs to enhance minimax tree search. Specifically, LLMs replace three key modules: (1) player action sampling, (2) opponent modeling, and (3) value function estimation, enabling the agent to effectively utilize gameplay history and human knowledge to reduce the search space and address partial observability. Notably, our framework requires no additional LLM training. We evaluate PokéChamp in the popular Gen 9 OU format. When powered by GPT-4o, it achieves a win rate of 76\\% against the best existing LLM-based bot and 84\\% against the strongest rule-based bot, demonstrating its superior performance. Even with an open-source 8-billion-parameter Llama 3.1 model, PokéChamp consistently outperforms the previous best LLM-based bot, Pokéllmon powered by GPT-4o, with a 64\\% win rate. PokéChamp attains a projected Elo of 1300-1500 on the Pokémon Showdown online ladder, placing it among the top 30\\%-10\\% of human players. In addition, this work compiles the largest real-player Pokémon battle dataset, featuring over 3 million games, including more than 500k high-Elo matches. Based on this dataset, we establish a series of battle benchmarks and puzzles to evaluate specific battling skills. We further provide key updates to the local game engine. This work establishes Pokémon as a benchmark to integrate LLM technologies with game-theoretic algorithms addressing general multi-agent problems. Videos, code, and dataset are available online.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=SnZ7SKykHh"
        ],
        "venue": [
          "/venue/SnZ7SKykHh@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=SnZ7SKykHh"
        ],
        "detail": [
          "https://openreview.net/forum?id=SnZ7SKykHh"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 4
      },
      "raw_excerpt": "PokéChamp: an Expert-level Minimax Language Agent [PDF 3 ] [Copy] [Kimi 4 ] [REL] Authors : Seth Karten , Andy Nguyen , Chi Jin We introduce PokéChamp, a minimax agent powered by Large Language Models (LLMs) for Pokémon battles. Built on a general framework for two-player competitive games, PokéChamp leverages the generalist capabilities of LLMs to enhance minimax tree search. Specifically, LLMs replace three key modules: (1) player action sampling, (2) opponent modeling, and (3) value function estimation, enabling the agent to effectively utilize gameplay history and human knowledge to reduce the search space and address partial observability. Notably, our framework requires no additional LLM training. We evaluate PokéChamp in the popular Gen 9 OU format. When powered by GPT-4o, it achieves a win rate of 76\\% against the best existing LLM-based bot and 84\\% against the strongest rule-based bot, demonstrating its superior performance. Even with an open-source 8-billion-parameter Llama 3.1 model, PokéChamp consistently outperforms the previous best LLM-based bot, Pokéllmon powered by GPT-4o, with a 64\\% win rate. PokéChamp attains a projected Elo of 1300-1500 on the Pokémon Showdown online ladder, placing it among the top 30\\%-10\\% of human players. In addition, this work compiles the largest real-player Pokémon battle dataset, featuring over 3 million games, including more than 500k high-Elo matches. Based on this dataset, we establish a series of battle benchmarks and puzzles to evaluate specific battling skills. We further provide key updates to the local game engine. This work establishes Pokémon as a benchmark to integrate LLM technologies with game-theoretic algorithms addressing general multi-agent problems. Videos, code, and dataset are available online. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "T5IZ32ImAB@OpenReview",
      "index": 91,
      "title": "Graph Diffusion for Robust Multi-Agent Coordination",
      "authors": [
        "Xianghua Zeng",
        "Hang Su",
        "Zhengyi Wang",
        "Zhiyuan LIN"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "coordination",
        "agent",
        "mcgd",
        "multi",
        "diffusion",
        "robustness",
        "environments",
        "graph",
        "attributes",
        "policy"
      ],
      "summary": "Offline multi-agent reinforcement learning (MARL) struggles to estimate out-of-distribution states and actions due to the absence of real-time environmental feedback. While diffusion models show promise in addressing these challenges, their application primarily focuses on independently diffusing the historical trajectories of individual agents, neglecting crucial multi-agent coordination dynamics and reducing policy robustness in dynamic environments. In this paper, we propose MCGD, a novel Multi-agent Coordination framework based on Graph Diffusion models to improve the effectiveness and robustness of collaborative policies. Specifically, we begin by constructing a sparse coordination graph that includes continuous node attributes and discrete edge attributes to effectively identify the underlying dynamics of multi-agent interactions. Next, we derive transition probabilities between edge categories and present adaptive categorical diffusion to capture the structure diversity of multi-agent coordination. Leveraging this coordination structure, we define neighbor-dependent forward noise and develop anisotropic diffusion to enhance the action diversity of each agent. Extensive experiments across various multi-agent environments demonstrate that MCGD significantly outperforms existing state-of-the-art baselines in coordination performance and policy robustness in dynamic environments.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=T5IZ32ImAB"
        ],
        "venue": [
          "/venue/T5IZ32ImAB@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=T5IZ32ImAB"
        ],
        "detail": [
          "https://openreview.net/forum?id=T5IZ32ImAB"
        ]
      },
      "scores": {
        "pdf": 11,
        "kimi": 6
      },
      "raw_excerpt": "Graph Diffusion for Robust Multi-Agent Coordination [PDF 11 ] [Copy] [Kimi 6 ] [REL] Authors : Xianghua Zeng , Hang Su , Zhengyi Wang , Zhiyuan LIN Offline multi-agent reinforcement learning (MARL) struggles to estimate out-of-distribution states and actions due to the absence of real-time environmental feedback. While diffusion models show promise in addressing these challenges, their application primarily focuses on independently diffusing the historical trajectories of individual agents, neglecting crucial multi-agent coordination dynamics and reducing policy robustness in dynamic environments. In this paper, we propose MCGD, a novel Multi-agent Coordination framework based on Graph Diffusion models to improve the effectiveness and robustness of collaborative policies. Specifically, we begin by constructing a sparse coordination graph that includes continuous node attributes and discrete edge attributes to effectively identify the underlying dynamics of multi-agent interactions. Next, we derive transition probabilities between edge categories and present adaptive categorical diffusion to capture the structure diversity of multi-agent coordination. Leveraging this coordination structure, we define neighbor-dependent forward noise and develop anisotropic diffusion to enhance the action diversity of each agent. Extensive experiments across various multi-agent environments demonstrate that MCGD significantly outperforms existing state-of-the-art baselines in coordination performance and policy robustness in dynamic environments. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "TmJvacopmV@OpenReview",
      "index": 92,
      "title": "Discrepancy Minimization in Input-Sparsity Time",
      "authors": [
        "Yichuan Deng",
        "Xiaoyu Li",
        "Zhao Song",
        "OMRI WEINSTEIN"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "bansal",
        "larsen",
        "widetilde",
        "nnz",
        "discrepancy",
        "coloring",
        "mathrm",
        "algorithm",
        "soda",
        "sparsity"
      ],
      "summary": "A recent work by [Larsen, SODA 2023] introduced a faster combinatorial alternative to Bansal's SDP algorithm for finding a coloring x ∈ { − 1 , 1 } n x ∈ { − 1 , 1 } n that approximately minimizes the discrepancy d i s c ( A , x ) : = ∥ A x ∥ ∞ d i s c ( A , x ) := ‖ A x ‖ ∞ of a real-valued m × n m × n matrix A A . Larsen's algorithm runs in O ˜ ( m n 2 ) O ~ ( m n 2 ) time compared to Bansal's O ˜ ( m n 4.5 ) O ~ ( m n 4.5 ) -time algorithm, with a slightly weaker logarithmic approximation ratio in terms of the hereditary discrepancy of A A [Bansal, FOCS 2010]. We present a combinatorial O ˜ ( n n z ( A ) + n 3 ) O ~ ( n n z ( A ) + n 3 ) -time algorithm with the same approximation guarantee as Larsen's, optimal for tall matrices where m = p o l y ( n ) m = p o l y ( n ) . Using a more intricate analysis and fast matrix multiplication, we further achieve a runtime of O ˜ ( n n z ( A ) + n 2.53 ) O ~ ( n n z ( A ) + n 2.53 ) , breaking the cubic barrier for square matrices and surpassing the limitations of linear-programming approaches [Eldan and Singh, RS\\&A 2018]. Our algorithm relies on two key ideas: (i) a new sketching technique for finding a projection matrix with a short ℓ 2 ℓ 2 -basis using implicit leverage-score sampling, and (ii) a data structure for efficiently implementing the iterative Edge-Walk partial-coloring algorithm [Lovett and Meka, SICOMP 2015], and using an alternative analysis to enable ``lazy'' batch updates with low-rank corrections. Our results nearly close the computational gap between real-valued and binary matrices, for which input-sparsity time coloring was recently obtained by [Jain, Sah and Sawhney, SODA 2023].",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=TmJvacopmV"
        ],
        "venue": [
          "/venue/TmJvacopmV@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=TmJvacopmV"
        ],
        "detail": [
          "https://openreview.net/forum?id=TmJvacopmV"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Discrepancy Minimization in Input-Sparsity Time [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Yichuan Deng , Xiaoyu Li , Zhao Song , OMRI WEINSTEIN A recent work by [Larsen, SODA 2023] introduced a faster combinatorial alternative to Bansal's SDP algorithm for finding a coloring x ∈ { − 1 , 1 } n x ∈ { − 1 , 1 } n that approximately minimizes the discrepancy d i s c ( A , x ) : = ∥ A x ∥ ∞ d i s c ( A , x ) := ‖ A x ‖ ∞ of a real-valued m × n m × n matrix A A . Larsen's algorithm runs in O ˜ ( m n 2 ) O ~ ( m n 2 ) time compared to Bansal's O ˜ ( m n 4.5 ) O ~ ( m n 4.5 ) -time algorithm, with a slightly weaker logarithmic approximation ratio in terms of the hereditary discrepancy of A A [Bansal, FOCS 2010]. We present a combinatorial O ˜ ( n n z ( A ) + n 3 ) O ~ ( n n z ( A ) + n 3 ) -time algorithm with the same approximation guarantee as Larsen's, optimal for tall matrices where m = p o l y ( n ) m = p o l y ( n ) . Using a more intricate analysis and fast matrix multiplication, we further achieve a runtime of O ˜ ( n n z ( A ) + n 2.53 ) O ~ ( n n z ( A ) + n 2.53 ) , breaking the cubic barrier for square matrices and surpassing the limitations of linear-programming approaches [Eldan and Singh, RS\\&A 2018]. Our algorithm relies on two key ideas: (i) a new sketching technique for finding a projection matrix with a short ℓ 2 ℓ 2 -basis using implicit leverage-score sampling, and (ii) a data structure for efficiently implementing the iterative Edge-Walk partial-coloring algorithm [Lovett and Meka, SICOMP 2015], and using an alternative analysis to enable ``lazy'' batch updates with low-rank corrections. Our results nearly close the computational gap between real-valued and binary matrices, for which input-sparsity time coloring was recently obtained by [Jain, Sah and Sawhney, SODA 2023]. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "U354tbTjav@OpenReview",
      "index": 93,
      "title": "Return of the Latent Space COWBOYS: Re-thinking the use of VAEs for Bayesian Optimisation of Structured Spaces",
      "authors": [
        "Henry Moss",
        "Sebastian Ober",
        "Tom Diethe"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "optimisation",
        "cowboys",
        "latent",
        "bayesian",
        "vae",
        "decoupled",
        "space",
        "structured",
        "vaes",
        "surrogate"
      ],
      "summary": "Bayesian optimisation in the latent space of a VAE is a powerful framework for optimisation tasks over complex structured domains, such as the space of valid molecules. However, existing approaches tightly couple the surrogate and generative models, which can lead to suboptimal performance when the latent space is not tailored to specific tasks, which in turn has led to the proposal of increasingly sophisticated algorithms. In this work, we explore a new direction, instead proposing a decoupled approach that trains a generative model and a GP surrogate separately, then combines them via a simple yet principled Bayesian update rule. This separation allows each component to focus on its strengths— structure generation from the VAE and predictive modelling by the GP. We show that our decoupled approach improves our ability to identify high-potential candidates in molecular optimisation problems under constrained evaluation budgets.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=U354tbTjav"
        ],
        "venue": [
          "/venue/U354tbTjav@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=U354tbTjav"
        ],
        "detail": [
          "https://openreview.net/forum?id=U354tbTjav"
        ]
      },
      "scores": {
        "pdf": 6,
        "kimi": null
      },
      "raw_excerpt": "Return of the Latent Space COWBOYS: Re-thinking the use of VAEs for Bayesian Optimisation of Structured Spaces [PDF 6 ] [Copy] [Kimi ] [REL] Authors : Henry Moss , Sebastian Ober , Tom Diethe Bayesian optimisation in the latent space of a VAE is a powerful framework for optimisation tasks over complex structured domains, such as the space of valid molecules. However, existing approaches tightly couple the surrogate and generative models, which can lead to suboptimal performance when the latent space is not tailored to specific tasks, which in turn has led to the proposal of increasingly sophisticated algorithms. In this work, we explore a new direction, instead proposing a decoupled approach that trains a generative model and a GP surrogate separately, then combines them via a simple yet principled Bayesian update rule. This separation allows each component to focus on its strengths— structure generation from the VAE and predictive modelling by the GP. We show that our decoupled approach improves our ability to identify high-potential candidates in molecular optimisation problems under constrained evaluation budgets. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "U64wEbM7NB@OpenReview",
      "index": 94,
      "title": "Trusted Multi-View Classification with Expert Knowledge Constraints",
      "authors": [
        "Xinyan Liang",
        "Shijie Wang",
        "Yuhua Qian",
        "Qian Guo",
        "Liang Du",
        "Bingbing Jiang",
        "Tingjin Luo",
        "Feijiang Li"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "tmcek",
        "expert",
        "mvc",
        "view",
        "classification",
        "trusted",
        "knowledge",
        "multi",
        "interpretability",
        "safety"
      ],
      "summary": "Multi-view classification (MVC) based on the Dempster-Shafer theory has gained significant recognition for its reliability in safety-critical applications. However, existing methods predominantly focus on providing confidence levels for decision outcomes without explaining the reasoning behind these decisions. Moreover, the reliance on first-order statistical magnitudes of belief masses often inadequately capture the intrinsic uncertainty within the evidence. To address these limitations, we propose a novel framework termed Trusted Multi-view Classification Constrained with Expert Knowledge (TMCEK). TMCEK integrates expert knowledge to enhance feature-level interpretability and introduces a distribution-aware subjective opinion mechanism to derive more reliable and realistic confidence estimates. The theoretical superiority of the proposed uncertainty measure over conventional approaches is rigorously established. Extensive experiments conducted on three multi-view datasets for sleep stage classification demonstrate that TMCEK achieves state-of-the-art performance while offering interpretability at both the feature and decision levels. These results position TMCEK as a robust and interpretable solution for MVC in safety-critical domains. The code is available at https://github.com/jie019/TMCEK_ICML2025.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=U64wEbM7NB"
        ],
        "venue": [
          "/venue/U64wEbM7NB@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=U64wEbM7NB"
        ],
        "detail": [
          "https://openreview.net/forum?id=U64wEbM7NB"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Trusted Multi-View Classification with Expert Knowledge Constraints [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Xinyan Liang , Shijie Wang , Yuhua Qian , Qian Guo , Liang Du , Bingbing Jiang , Tingjin Luo , Feijiang Li Multi-view classification (MVC) based on the Dempster-Shafer theory has gained significant recognition for its reliability in safety-critical applications. However, existing methods predominantly focus on providing confidence levels for decision outcomes without explaining the reasoning behind these decisions. Moreover, the reliance on first-order statistical magnitudes of belief masses often inadequately capture the intrinsic uncertainty within the evidence. To address these limitations, we propose a novel framework termed Trusted Multi-view Classification Constrained with Expert Knowledge (TMCEK). TMCEK integrates expert knowledge to enhance feature-level interpretability and introduces a distribution-aware subjective opinion mechanism to derive more reliable and realistic confidence estimates. The theoretical superiority of the proposed uncertainty measure over conventional approaches is rigorously established. Extensive experiments conducted on three multi-view datasets for sleep stage classification demonstrate that TMCEK achieves state-of-the-art performance while offering interpretability at both the feature and decision levels. These results position TMCEK as a robust and interpretable solution for MVC in safety-critical domains. The code is available at https://github.com/jie019/TMCEK_ICML2025. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "UFlyLkvyAE@OpenReview",
      "index": 95,
      "title": "Graph Adaptive Autoregressive Moving Average Models",
      "authors": [
        "Moshe Eliasof",
        "Alessio Gravina",
        "Andrea Ceni",
        "Claudio Gallicchio",
        "Davide Bacciu",
        "Carola-Bibiane Schönlieb"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "grama",
        "arma",
        "graph",
        "ssms",
        "equivariance",
        "autoregressive",
        "moving",
        "permutation",
        "selective",
        "adaptive"
      ],
      "summary": "Graph State Space Models (SSMs) have recently been introduced to enhance Graph Neural Networks (GNNs) in modeling long-range interactions. Despite their success, existing methods either compromise on permutation equivariance or limit their focus to pairwise interactions rather than sequences. Building on the connection between Autoregressive Moving Average (ARMA) and SSM, in this paper, we introduce GRAMA, a Graph Adaptive method based on a learnable ARMA framework that addresses these limitations. By transforming from static to sequential graph data, GRAMA leverages the strengths of the ARMA framework, while preserving permutation equivariance. Moreover, GRAMA incorporates a selective attention mechanism for dynamic learning of ARMA coefficients, enabling efficient and flexible long-range information propagation. We also establish theoretical connections between GRAMA and Selective SSMs, providing insights into its ability to capture long-range dependencies. Experiments on 26 synthetic and real-world datasets demonstrate that GRAMA consistently outperforms backbone models and performs competitively with state-of-the-art methods.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=UFlyLkvyAE"
        ],
        "venue": [
          "/venue/UFlyLkvyAE@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=UFlyLkvyAE"
        ],
        "detail": [
          "https://openreview.net/forum?id=UFlyLkvyAE"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": null
      },
      "raw_excerpt": "Graph Adaptive Autoregressive Moving Average Models [PDF 5 ] [Copy] [Kimi ] [REL] Authors : Moshe Eliasof , Alessio Gravina , Andrea Ceni , Claudio Gallicchio , Davide Bacciu , Carola-Bibiane Schönlieb Graph State Space Models (SSMs) have recently been introduced to enhance Graph Neural Networks (GNNs) in modeling long-range interactions. Despite their success, existing methods either compromise on permutation equivariance or limit their focus to pairwise interactions rather than sequences. Building on the connection between Autoregressive Moving Average (ARMA) and SSM, in this paper, we introduce GRAMA, a Graph Adaptive method based on a learnable ARMA framework that addresses these limitations. By transforming from static to sequential graph data, GRAMA leverages the strengths of the ARMA framework, while preserving permutation equivariance. Moreover, GRAMA incorporates a selective attention mechanism for dynamic learning of ARMA coefficients, enabling efficient and flexible long-range information propagation. We also establish theoretical connections between GRAMA and Selective SSMs, providing insights into its ability to capture long-range dependencies. Experiments on 26 synthetic and real-world datasets demonstrate that GRAMA consistently outperforms backbone models and performs competitively with state-of-the-art methods. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "F0sinjQMnv@OpenReview",
      "index": 96,
      "title": "Identifying Causal Direction via Variational Bayesian Compression",
      "authors": [
        "Quang-Duy Tran",
        "Bao Duong",
        "Phuoc Nguyen",
        "Thin Nguyen"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "codelengths",
        "causal",
        "complexity",
        "direction",
        "fitness",
        "variational",
        "bayesian",
        "approaches",
        "codelength",
        "evaluable"
      ],
      "summary": "Telling apart the cause and effect between two random variables with purely observational data is a challenging problem that finds applications in various scientific disciplines. A key principle utilized in this task is the algorithmic Markov condition, which postulates that the joint distribution, when factorized according to the causal direction, yields a more succinct codelength compared to the anti-causal direction. Previous approaches approximate these codelengths by relying on simple functions or Gaussian processes (GPs) with easily evaluable complexity, compromising between model fitness and computational complexity. To overcome these limitations, we propose leveraging the variational Bayesian learning of neural networks as an interpretation of the codelengths. Consequently, we can enhance the model fitness while promoting the succinctness of the codelengths, while avoiding the significant computational complexity of the GP-based approaches. Extensive experiments on both synthetic and real-world benchmarks in cause-effect identification demonstrate the effectiveness of our proposed method, surpassing the overall performance of related complexity-based and structural causal model regression-based approaches.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=F0sinjQMnv"
        ],
        "venue": [
          "/venue/F0sinjQMnv@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=F0sinjQMnv"
        ],
        "detail": [
          "https://openreview.net/forum?id=F0sinjQMnv"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "Identifying Causal Direction via Variational Bayesian Compression [PDF 3 ] [Copy] [Kimi 1 ] [REL] Authors : Quang-Duy Tran , Bao Duong , Phuoc Nguyen , Thin Nguyen Telling apart the cause and effect between two random variables with purely observational data is a challenging problem that finds applications in various scientific disciplines. A key principle utilized in this task is the algorithmic Markov condition, which postulates that the joint distribution, when factorized according to the causal direction, yields a more succinct codelength compared to the anti-causal direction. Previous approaches approximate these codelengths by relying on simple functions or Gaussian processes (GPs) with easily evaluable complexity, compromising between model fitness and computational complexity. To overcome these limitations, we propose leveraging the variational Bayesian learning of neural networks as an interpretation of the codelengths. Consequently, we can enhance the model fitness while promoting the succinctness of the codelengths, while avoiding the significant computational complexity of the GP-based approaches. Extensive experiments on both synthetic and real-world benchmarks in cause-effect identification demonstrate the effectiveness of our proposed method, surpassing the overall performance of related complexity-based and structural causal model regression-based approaches. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "EUH4VUCXay@OpenReview",
      "index": 97,
      "title": "am-ELO: A Stable Framework for Arena-based LLM Evaluation",
      "authors": [
        "Zirui Liu",
        "Jiatong Li",
        "Yan Zhuang",
        "Qi Liu",
        "Shuanghong Shen",
        "Jie Ouyang",
        "Mingyue Cheng",
        "Shijin Wang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "elo",
        "arena",
        "rating",
        "evaluation",
        "mle",
        "annotator",
        "stable",
        "abilities",
        "framework",
        "ranking"
      ],
      "summary": "Arena-based evaluation is a fundamental yet significant evaluation paradigm for modern AI models, especially large language models (LLMs). Existing framework based on ELO rating system suffers from the inevitable instability problem due to ranking inconsistency and the lack of attention to the varying abilities of annotators. In this paper, we introduce a novel stable arena framework to address these issues by enhancing the ELO Rating System. Specifically, we replace the iterative update method with a Maximum Likelihood Estimation (MLE) approach, m-ELO, and provide theoretical proof of the consistency and stability of the MLE approach for model ranking. Additionally, we proposed the am-ELO, which modify the Elo Rating’s probability function to incorporate annotator abilities, enabling the simultaneous estimation of model scores and annotator reliability. Experiments demonstrate that this method ensures stability, proving that this framework offers a more robust, accurate, and stable evaluation method for LLMs.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=EUH4VUCXay"
        ],
        "venue": [
          "/venue/EUH4VUCXay@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=EUH4VUCXay"
        ],
        "detail": [
          "https://openreview.net/forum?id=EUH4VUCXay"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": null
      },
      "raw_excerpt": "am-ELO: A Stable Framework for Arena-based LLM Evaluation [PDF 2 ] [Copy] [Kimi ] [REL] Authors : Zirui Liu , Jiatong Li , Yan Zhuang , Qi Liu , Shuanghong Shen , Jie Ouyang , Mingyue Cheng , Shijin Wang Arena-based evaluation is a fundamental yet significant evaluation paradigm for modern AI models, especially large language models (LLMs). Existing framework based on ELO rating system suffers from the inevitable instability problem due to ranking inconsistency and the lack of attention to the varying abilities of annotators. In this paper, we introduce a novel stable arena framework to address these issues by enhancing the ELO Rating System. Specifically, we replace the iterative update method with a Maximum Likelihood Estimation (MLE) approach, m-ELO, and provide theoretical proof of the consistency and stability of the MLE approach for model ranking. Additionally, we proposed the am-ELO, which modify the Elo Rating’s probability function to incorporate annotator abilities, enabling the simultaneous estimation of model scores and annotator reliability. Experiments demonstrate that this method ensures stability, proving that this framework offers a more robust, accurate, and stable evaluation method for LLMs. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "BUONdewsBa@OpenReview",
      "index": 98,
      "title": "Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective",
      "authors": [
        "Yujin Oh",
        "Pengfei Jin",
        "Sangjoon Park",
        "Sekeun Kim",
        "Siyeop yoon",
        "Jin Kim",
        "Kyungsang Kim",
        "Xiang Li",
        "Quanzheng Li"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "dmoe",
        "medical",
        "segmentation",
        "fairness",
        "clinical",
        "image",
        "control",
        "imbalanced",
        "demographic",
        "aware"
      ],
      "summary": "Ensuring fairness in medical image segmentation is critical due to biases in imbalanced clinical data acquisition caused by demographic attributes (e.g., age, sex, race) and clinical factors (e.g., disease severity). To address these challenges, we introduce Distribution-aware Mixture of Experts (dMoE), inspired by optimal control theory. We provide a comprehensive analysis of its underlying mechanisms and clarify dMoE's role in adapting to heterogeneous distributions in medical image segmentation. Furthermore, we integrate dMoE into multiple network architectures, demonstrating its broad applicability across diverse medical image analysis tasks. By incorporating demographic and clinical factors, dMoE achieves state-of-the-art performance on two 2D benchmark datasets and a 3D in-house dataset. Our results highlight the effectiveness of dMoE in mitigating biases from imbalanced distributions, offering a promising approach to bridging control theory and medical image segmentation within fairness learning paradigms. The source code is available at https://github.com/tvseg/dMoE.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=BUONdewsBa"
        ],
        "venue": [
          "/venue/BUONdewsBa@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=BUONdewsBa"
        ],
        "detail": [
          "https://openreview.net/forum?id=BUONdewsBa"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": null
      },
      "raw_excerpt": "Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective [PDF 3 ] [Copy] [Kimi ] [REL] Authors : Yujin Oh , Pengfei Jin , Sangjoon Park , Sekeun Kim , Siyeop yoon , Jin Kim , Kyungsang Kim , Xiang Li , Quanzheng Li Ensuring fairness in medical image segmentation is critical due to biases in imbalanced clinical data acquisition caused by demographic attributes (e.g., age, sex, race) and clinical factors (e.g., disease severity). To address these challenges, we introduce Distribution-aware Mixture of Experts (dMoE), inspired by optimal control theory. We provide a comprehensive analysis of its underlying mechanisms and clarify dMoE's role in adapting to heterogeneous distributions in medical image segmentation. Furthermore, we integrate dMoE into multiple network architectures, demonstrating its broad applicability across diverse medical image analysis tasks. By incorporating demographic and clinical factors, dMoE achieves state-of-the-art performance on two 2D benchmark datasets and a 3D in-house dataset. Our results highlight the effectiveness of dMoE in mitigating biases from imbalanced distributions, offering a promising approach to bridging control theory and medical image segmentation within fairness learning paradigms. The source code is available at https://github.com/tvseg/dMoE. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "5liHhkgvAn@OpenReview",
      "index": 99,
      "title": "SDP-CROWN: Efficient Bound Propagation for Neural Network Verification with Tightness of Semidefinite Programming",
      "authors": [
        "Hong-Ming Chiu",
        "Hao Chen",
        "Huan Zhang",
        "Richard Zhang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "sdp",
        "crown",
        "tightness",
        "neuron",
        "bound",
        "verifiers",
        "propagation",
        "verification",
        "semidefinite",
        "inter"
      ],
      "summary": "Neural network verifiers based on linear bound propagation scale impressively to massive models but can be surprisingly loose when neuron coupling is crucial. Conversely, semidefinite programming (SDP) verifiers capture inter-neuron coupling naturally, but their cubic complexity restricts them to only small models. In this paper, we propose SDP-CROWN, a novel hybrid verification framework that combines the tightness of SDP relaxations with the scalability of bound-propagation verifiers. At the core of SDP-CROWN is a new linear bound---derived via SDP principles---that explicitly captures ℓ 2 ℓ 2 -norm-based inter-neuron coupling while adding only one extra parameter per layer. This bound can be integrated seamlessly into any linear bound-propagation pipeline, preserving the inherent scalability of such methods yet significantly improving tightness. In theory, we prove that our inter-neuron bound can be up to a factor of n − − √ n tighter than traditional per-neuron bounds. In practice, when incorporated into the state-of-the-art α α -CROWN verifier, we observe markedly improved verification performance on large models with up to 65 thousand neurons and 2.47 million parameters, achieving tightness that approaches that of costly SDP-based methods.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=5liHhkgvAn"
        ],
        "venue": [
          "/venue/5liHhkgvAn@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=5liHhkgvAn"
        ],
        "detail": [
          "https://openreview.net/forum?id=5liHhkgvAn"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "SDP-CROWN: Efficient Bound Propagation for Neural Network Verification with Tightness of Semidefinite Programming [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Hong-Ming Chiu , Hao Chen , Huan Zhang , Richard Zhang Neural network verifiers based on linear bound propagation scale impressively to massive models but can be surprisingly loose when neuron coupling is crucial. Conversely, semidefinite programming (SDP) verifiers capture inter-neuron coupling naturally, but their cubic complexity restricts them to only small models. In this paper, we propose SDP-CROWN, a novel hybrid verification framework that combines the tightness of SDP relaxations with the scalability of bound-propagation verifiers. At the core of SDP-CROWN is a new linear bound---derived via SDP principles---that explicitly captures ℓ 2 ℓ 2 -norm-based inter-neuron coupling while adding only one extra parameter per layer. This bound can be integrated seamlessly into any linear bound-propagation pipeline, preserving the inherent scalability of such methods yet significantly improving tightness. In theory, we prove that our inter-neuron bound can be up to a factor of n − − √ n tighter than traditional per-neuron bounds. In practice, when incorporated into the state-of-the-art α α -CROWN verifier, we observe markedly improved verification performance on large models with up to 65 thousand neurons and 2.47 million parameters, achieving tightness that approaches that of costly SDP-based methods. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "0cEZyhHEks@OpenReview",
      "index": 100,
      "title": "Taming Knowledge Conflicts in Language Models",
      "authors": [
        "Gaotang Li",
        "Yuzhong Chen",
        "Hanghang Tong"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "juice",
        "heads",
        "memory",
        "contextual",
        "knowledge",
        "conflict",
        "conflicts",
        "parametric",
        "attention",
        "superposition"
      ],
      "summary": "Language Models (LMs) often encounter knowledge conflicts when parametric memory contradicts contextual knowledge. Previous works attribute this conflict to the interplay between \"memory heads\" and \"context heads\", attention heads assumed to promote either memory or context exclusively. In this study, we go beyond this fundamental assumption by uncovering a critical phenomenon we term the *superposition of contextual information and parametric memory*, where highly influential attention heads simultaneously contribute to both memory and context. Building upon this insight, we propose Just Run Twice (JuICE), a test-time attention intervention method that steers LMs toward either parametric beliefs or contextual knowledge without requiring fine-tuning. JuICE identifies a set of reliable attention heads and leverages a dual-run approach to mitigate the superposition effects. Extensive experiments across 11 datasets and 6 model architectures demonstrate that JuICE sets the new state-of-the-art performance and robust generalization, achieving significant and consistent improvement across different domains under various conflict types. Finally, we theoretically analyze knowledge conflict and the superposition of contextual information and parametric memory in attention heads, which further elucidates the effectiveness of JuICE in these settings. Our code is available at https://github.com/GaotangLi/JUICE.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=0cEZyhHEks"
        ],
        "venue": [
          "/venue/0cEZyhHEks@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=0cEZyhHEks"
        ],
        "detail": [
          "https://openreview.net/forum?id=0cEZyhHEks"
        ]
      },
      "scores": {
        "pdf": 7,
        "kimi": 4
      },
      "raw_excerpt": "Taming Knowledge Conflicts in Language Models [PDF 7 ] [Copy] [Kimi 4 ] [REL] Authors : Gaotang Li , Yuzhong Chen , Hanghang Tong Language Models (LMs) often encounter knowledge conflicts when parametric memory contradicts contextual knowledge. Previous works attribute this conflict to the interplay between \"memory heads\" and \"context heads\", attention heads assumed to promote either memory or context exclusively. In this study, we go beyond this fundamental assumption by uncovering a critical phenomenon we term the *superposition of contextual information and parametric memory*, where highly influential attention heads simultaneously contribute to both memory and context. Building upon this insight, we propose Just Run Twice (JuICE), a test-time attention intervention method that steers LMs toward either parametric beliefs or contextual knowledge without requiring fine-tuning. JuICE identifies a set of reliable attention heads and leverages a dual-run approach to mitigate the superposition effects. Extensive experiments across 11 datasets and 6 model architectures demonstrate that JuICE sets the new state-of-the-art performance and robust generalization, achieving significant and consistent improvement across different domains under various conflict types. Finally, we theoretically analyze knowledge conflict and the superposition of contextual information and parametric memory in attention heads, which further elucidates the effectiveness of JuICE in these settings. Our code is available at https://github.com/GaotangLi/JUICE. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Pokj70ZAxJ@OpenReview",
      "index": 101,
      "title": "Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation",
      "authors": [
        "Jintao Tong",
        "Ran Ma",
        "Yixiong Zou",
        "Guangyao Chen",
        "Yuhua Li",
        "Ruixuan Li"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "domain",
        "dfn",
        "decoupler",
        "adapter",
        "shot",
        "fss",
        "serves",
        "finetuning",
        "svn",
        "naturally"
      ],
      "summary": "Cross-domain few-shot segmentation (CD-FSS) is proposed to first pre-train the model on a source-domain dataset with sufficient samples, and then transfer the model to target-domain datasets where only a few training samples are available for efficient finetuning. There are majorly two challenges in this task: (1) the domain gap and (2) finetuning with scarce data. To solve these challenges, we revisit the adapter-based methods, and discover an intriguing insight not explored in previous works: the adapter not only helps the fine-tuning of downstream tasks but also naturally serves as a domain information decoupler. Then, we delve into this finding for an interpretation, and we find the model's inherent structure could lead to a natural decoupling of domain information. Building upon this insight, we propose the Domain Feature Navigator (DFN), which is a structure-based decoupler instead of loss-based ones like current works, to capture domain-specific information, thereby directing the model's attention towards domain-agnostic knowledge. Moreover, to prevent the potential excessive overfitting of DFN during the source-domain training, we further design the SAM-SVN method to constrain DFN from learning sample-specific knowledge. On target domains, we freeze the model and fine-tune the DFN to learn knowledge specific to target domains. Extensive experiments demonstrate that our method surpasses the state-of-the-art method in CD-FSS significantly by 2.69% and 4.68% average MIoU in 1-shot and 5-shot scenarios, respectively.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Pokj70ZAxJ"
        ],
        "venue": [
          "/venue/Pokj70ZAxJ@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Pokj70ZAxJ"
        ],
        "detail": [
          "https://openreview.net/forum?id=Pokj70ZAxJ"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 1
      },
      "raw_excerpt": "Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation [PDF 5 ] [Copy] [Kimi 1 ] [REL] Authors : Jintao Tong , Ran Ma , Yixiong Zou , Guangyao Chen , Yuhua Li , Ruixuan Li Cross-domain few-shot segmentation (CD-FSS) is proposed to first pre-train the model on a source-domain dataset with sufficient samples, and then transfer the model to target-domain datasets where only a few training samples are available for efficient finetuning. There are majorly two challenges in this task: (1) the domain gap and (2) finetuning with scarce data. To solve these challenges, we revisit the adapter-based methods, and discover an intriguing insight not explored in previous works: the adapter not only helps the fine-tuning of downstream tasks but also naturally serves as a domain information decoupler. Then, we delve into this finding for an interpretation, and we find the model's inherent structure could lead to a natural decoupling of domain information. Building upon this insight, we propose the Domain Feature Navigator (DFN), which is a structure-based decoupler instead of loss-based ones like current works, to capture domain-specific information, thereby directing the model's attention towards domain-agnostic knowledge. Moreover, to prevent the potential excessive overfitting of DFN during the source-domain training, we further design the SAM-SVN method to constrain DFN from learning sample-specific knowledge. On target domains, we freeze the model and fine-tune the DFN to learn knowledge specific to target domains. Extensive experiments demonstrate that our method surpasses the state-of-the-art method in CD-FSS significantly by 2.69% and 4.68% average MIoU in 1-shot and 5-shot scenarios, respectively. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "LpE54NUnmO@OpenReview",
      "index": 102,
      "title": "G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks",
      "authors": [
        "Guibin Zhang",
        "Yanwei Yue",
        "Xiangguo Sun",
        "Guancheng Wan",
        "Miao Yu",
        "Junfeng Fang",
        "Kun Wang",
        "Tianlong Chen",
        "Dawei Cheng"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "designer",
        "agent",
        "task",
        "architecting",
        "communication",
        "topologies",
        "textbf",
        "humaneval",
        "agents",
        "performing"
      ],
      "summary": "Recent advancements in large language model (LLM)-based agents have demonstrated that collective intelligence can significantly surpass the capabilities of individual agents, primarily due to well-crafted inter-agent communication topologies. Despite the diverse and high-performing designs available, practitioners often face confusion when selecting the most effective pipeline for their specific task: \\textit{Which topology is the best choice for my task, avoiding unnecessary communication token overhead while ensuring high-quality solution?} In response to this dilemma, we introduce G-Designer, an adaptive, efficient, and robust solution for multi-agent deployment, which dynamically designs task-aware, customized communication topologies. Specifically, G-Designer models the multi-agent system as a multi-agent network, leveraging a variational graph auto-encoder to encode both the nodes (agents) and a task-specific virtual node, and decodes a task-adaptive and high-performing communication topology. Extensive experiments on six benchmarks showcase that G-Designer is: \\textbf{(1) high-performing}, achieving superior results on MMLU with accuracy at 84.50 % 84.50 % and on HumanEval with pass@1 at 89.90 % 89.90 % ; \\textbf{(2) task-adaptive}, architecting communication protocols tailored to task difficulty, reducing token consumption by up to 95.33 % 95.33 % on HumanEval; and \\textbf{(3) adversarially robust}, defending against agent adversarial attacks with merely 0.3 % 0.3 % accuracy drop.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=LpE54NUnmO"
        ],
        "venue": [
          "/venue/LpE54NUnmO@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=LpE54NUnmO"
        ],
        "detail": [
          "https://openreview.net/forum?id=LpE54NUnmO"
        ]
      },
      "scores": {
        "pdf": 6,
        "kimi": 4
      },
      "raw_excerpt": "G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks [PDF 6 ] [Copy] [Kimi 4 ] [REL] Authors : Guibin Zhang , Yanwei Yue , Xiangguo Sun , Guancheng Wan , Miao Yu , Junfeng Fang , Kun Wang , Tianlong Chen , Dawei Cheng Recent advancements in large language model (LLM)-based agents have demonstrated that collective intelligence can significantly surpass the capabilities of individual agents, primarily due to well-crafted inter-agent communication topologies. Despite the diverse and high-performing designs available, practitioners often face confusion when selecting the most effective pipeline for their specific task: \\textit{Which topology is the best choice for my task, avoiding unnecessary communication token overhead while ensuring high-quality solution?} In response to this dilemma, we introduce G-Designer, an adaptive, efficient, and robust solution for multi-agent deployment, which dynamically designs task-aware, customized communication topologies. Specifically, G-Designer models the multi-agent system as a multi-agent network, leveraging a variational graph auto-encoder to encode both the nodes (agents) and a task-specific virtual node, and decodes a task-adaptive and high-performing communication topology. Extensive experiments on six benchmarks showcase that G-Designer is: \\textbf{(1) high-performing}, achieving superior results on MMLU with accuracy at 84.50 % 84.50 % and on HumanEval with pass@1 at 89.90 % 89.90 % ; \\textbf{(2) task-adaptive}, architecting communication protocols tailored to task difficulty, reducing token consumption by up to 95.33 % 95.33 % on HumanEval; and \\textbf{(3) adversarially robust}, defending against agent adversarial attacks with merely 0.3 % 0.3 % accuracy drop. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "KKwBo3u3IW@OpenReview",
      "index": 103,
      "title": "Mastering Board Games by External and Internal Planning with Language Models",
      "authors": [
        "John Schultz",
        "Jakub Adamek",
        "Matej Jusup",
        "Marc Lanctot",
        "Michael Kaisers",
        "Sarah Perrin",
        "Daniel Hennes",
        "Jeremy Shar",
        "Cannada Lewis",
        "Anian Ruoss",
        "Tom Zahavy",
        "Petar Veličković",
        "Laurel Prince",
        "Satinder Singh",
        "Eric Malmi",
        "Nenad Tomasev"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "search",
        "board",
        "chess",
        "games",
        "external",
        "planning",
        "chess960",
        "game",
        "language",
        "mastering"
      ],
      "summary": "Advancing planning and reasoning capabilities of Large Language Models (LLMs) is one of the key prerequisites towards unlocking their potential for performing reliably in complex and impactful domains. In this paper, we aim to demonstrate this across board games (Chess, Fischer Random / Chess960, Connect Four, and Hex), and we show that search-based planning can yield significant improvements in LLM game-playing strength. We introduce, compare and contrast two major approaches: In *external search*, the model guides Monte Carlo Tree Search (MCTS) rollouts and evaluations without calls to an external game engine, and in *internal search*, the model is trained to generate in-context a linearized tree of search and a resulting final choice. Both build on a language model pre-trained on relevant domain knowledge, reliably capturing the transition and value functions in the respective environments, with minimal hallucinations. We evaluate our LLM search implementations against game-specific state-of-the-art engines, showcasing substantial improvements in strength over the base model, and reaching Grandmaster-level performance in chess while operating closer to the human search budget. Our proposed approach, combining search with domain knowledge, is not specific to board games, hinting at more general future applications.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=KKwBo3u3IW"
        ],
        "venue": [
          "/venue/KKwBo3u3IW@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=KKwBo3u3IW"
        ],
        "detail": [
          "https://openreview.net/forum?id=KKwBo3u3IW"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 2
      },
      "raw_excerpt": "Mastering Board Games by External and Internal Planning with Language Models [PDF 4 ] [Copy] [Kimi 2 ] [REL] Authors : John Schultz , Jakub Adamek , Matej Jusup , Marc Lanctot , Michael Kaisers , Sarah Perrin , Daniel Hennes , Jeremy Shar , Cannada Lewis , Anian Ruoss , Tom Zahavy , Petar Veličković , Laurel Prince , Satinder Singh , Eric Malmi , Nenad Tomasev Advancing planning and reasoning capabilities of Large Language Models (LLMs) is one of the key prerequisites towards unlocking their potential for performing reliably in complex and impactful domains. In this paper, we aim to demonstrate this across board games (Chess, Fischer Random / Chess960, Connect Four, and Hex), and we show that search-based planning can yield significant improvements in LLM game-playing strength. We introduce, compare and contrast two major approaches: In *external search*, the model guides Monte Carlo Tree Search (MCTS) rollouts and evaluations without calls to an external game engine, and in *internal search*, the model is trained to generate in-context a linearized tree of search and a resulting final choice. Both build on a language model pre-trained on relevant domain knowledge, reliably capturing the transition and value functions in the respective environments, with minimal hallucinations. We evaluate our LLM search implementations against game-specific state-of-the-art engines, showcasing substantial improvements in strength over the base model, and reaching Grandmaster-level performance in chess while operating closer to the human search budget. Our proposed approach, combining search with domain knowledge, is not specific to board games, hinting at more general future applications. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "3pk0p4NGmQ@OpenReview",
      "index": 104,
      "title": "CVE-Bench: A Benchmark for AI Agents’ Ability to Exploit Real-World Web Application Vulnerabilities",
      "authors": [
        "Yuxuan Zhu",
        "Antony Kellermann",
        "Dylan Bowman",
        "Philip Li",
        "Akul Gupta",
        "Adarsh Danda",
        "Richard Fang",
        "Conner Jensen",
        "Eric Ihli",
        "Jason Benn",
        "Jet Geronimo",
        "Avi Dhir",
        "Sudhit Rao",
        "Kaicheng Yu",
        "Twm Stone",
        "Daniel Kang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "vulnerabilities",
        "cve",
        "bench",
        "agents",
        "exploit",
        "world",
        "benchmark",
        "llm",
        "web",
        "real"
      ],
      "summary": "Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture-the-Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized exper-tise to reproduce exploits and a systematic approach to evaluating unpredictable attacks. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our experiments show that the state-of-the-art agent framework can exploit up to 13% of the vulnerabilities.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=3pk0p4NGmQ"
        ],
        "venue": [
          "/venue/3pk0p4NGmQ@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=3pk0p4NGmQ"
        ],
        "detail": [
          "https://openreview.net/forum?id=3pk0p4NGmQ"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 2
      },
      "raw_excerpt": "CVE-Bench: A Benchmark for AI Agents’ Ability to Exploit Real-World Web Application Vulnerabilities [PDF 1 ] [Copy] [Kimi 2 ] [REL] Authors : Yuxuan Zhu , Antony Kellermann , Dylan Bowman , Philip Li , Akul Gupta , Adarsh Danda , Richard Fang , Conner Jensen , Eric Ihli , Jason Benn , Jet Geronimo , Avi Dhir , Sudhit Rao , Kaicheng Yu , Twm Stone , Daniel Kang Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture-the-Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized exper-tise to reproduce exploits and a systematic approach to evaluating unpredictable attacks. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our experiments show that the state-of-the-art agent framework can exploit up to 13% of the vulnerabilities. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "13HPTmZKbM@OpenReview",
      "index": 105,
      "title": "Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting",
      "authors": [
        "Sunny Sanyal",
        "Hayden Prairie",
        "Rudrajit Das",
        "Ali Kavis",
        "Sujay Sanghavi"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "tuning",
        "fine",
        "forgetting",
        "pre",
        "trained",
        "upweighting",
        "metamathqa",
        "easy",
        "upweight",
        "mitigates"
      ],
      "summary": "Fine-tuning a pre-trained model on a downstream task often degrades its original capabilities, a phenomenon known as \"catastrophic forgetting\". This is especially an issue when one does not have access to the data and recipe used to develop the pre-trained model. Under this constraint, most existing methods for mitigating forgetting are inapplicable. To address this challenge, we propose a *sample weighting scheme for the fine-tuning data* solely based on the pre-trained model's losses. Specifically, we upweight the easy samples on which the pre-trained model's loss is low and vice versa to limit the drift from the pre-trained model. Our approach is orthogonal and yet complementary to existing methods; while such methods mostly operate on parameter or gradient space, we concentrate on the sample space. We theoretically analyze the impact of fine-tuning with our method in a linear setting, showing that it stalls learning in a certain subspace, which inhibits overfitting to the target task. We empirically demonstrate the efficacy of our method on both language and vision tasks. As an example, when fine-tuning Gemma 2 2B on MetaMathQA, our method results in only a 0.8 0.8 % drop in accuracy on GSM8K (another math dataset) compared to standard fine-tuning, while preserving 5.4 5.4 % more accuracy on the pre-training datasets.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=13HPTmZKbM"
        ],
        "venue": [
          "/venue/13HPTmZKbM@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=13HPTmZKbM"
        ],
        "detail": [
          "https://openreview.net/forum?id=13HPTmZKbM"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 3
      },
      "raw_excerpt": "Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting [PDF 3 ] [Copy] [Kimi 3 ] [REL] Authors : Sunny Sanyal , Hayden Prairie , Rudrajit Das , Ali Kavis , Sujay Sanghavi Fine-tuning a pre-trained model on a downstream task often degrades its original capabilities, a phenomenon known as \"catastrophic forgetting\". This is especially an issue when one does not have access to the data and recipe used to develop the pre-trained model. Under this constraint, most existing methods for mitigating forgetting are inapplicable. To address this challenge, we propose a *sample weighting scheme for the fine-tuning data* solely based on the pre-trained model's losses. Specifically, we upweight the easy samples on which the pre-trained model's loss is low and vice versa to limit the drift from the pre-trained model. Our approach is orthogonal and yet complementary to existing methods; while such methods mostly operate on parameter or gradient space, we concentrate on the sample space. We theoretically analyze the impact of fine-tuning with our method in a linear setting, showing that it stalls learning in a certain subspace, which inhibits overfitting to the target task. We empirically demonstrate the efficacy of our method on both language and vision tasks. As an example, when fine-tuning Gemma 2 2B on MetaMathQA, our method results in only a 0.8 0.8 % drop in accuracy on GSM8K (another math dataset) compared to standard fine-tuning, while preserving 5.4 5.4 % more accuracy on the pre-training datasets. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "9u5hPIcr6j@OpenReview",
      "index": 106,
      "title": "LotteryCodec: Searching the Implicit Representation in a Random Network for Low-Complexity Image Compression",
      "authors": [
        "Haotian Wu",
        "Gongpu Chen",
        "Pier Luigi Dragotti",
        "Deniz Gunduz"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "lotterycodec",
        "compression",
        "image",
        "hypothesis",
        "initialized",
        "randomly",
        "mask",
        "rewind",
        "overfits",
        "vtm"
      ],
      "summary": "We introduce and validate the lottery codec hypothesis, which states that untrained subnetworks within randomly initialized networks can serve as synthesis networks for overfitted image compression, achieving rate-distortion (RD) performance comparable to trained networks. This hypothesis leads to a new paradigm for image compression by encoding image statistics into the network substructure. Building on this hypothesis, we propose LotteryCodec, which overfits a binary mask to an individual image, leveraging an over-parameterized and randomly initialized network shared by the encoder and the decoder. To address over-parameterization challenges and streamline subnetwork search, we develop a rewind modulation mechanism that improves the RD performance. LotteryCodec outperforms VTM and sets a new state-of-the-art in single-image compression. LotteryCodec also enables adaptive decoding complexity through adjustable mask ratios, offering flexible compression solutions for diverse device constraints and application requirements.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=9u5hPIcr6j"
        ],
        "venue": [
          "/venue/9u5hPIcr6j@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=9u5hPIcr6j"
        ],
        "detail": [
          "https://openreview.net/forum?id=9u5hPIcr6j"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 4
      },
      "raw_excerpt": "LotteryCodec: Searching the Implicit Representation in a Random Network for Low-Complexity Image Compression [PDF 4 ] [Copy] [Kimi 4 ] [REL] Authors : Haotian Wu , Gongpu Chen , Pier Luigi Dragotti , Deniz Gunduz We introduce and validate the lottery codec hypothesis, which states that untrained subnetworks within randomly initialized networks can serve as synthesis networks for overfitted image compression, achieving rate-distortion (RD) performance comparable to trained networks. This hypothesis leads to a new paradigm for image compression by encoding image statistics into the network substructure. Building on this hypothesis, we propose LotteryCodec, which overfits a binary mask to an individual image, leveraging an over-parameterized and randomly initialized network shared by the encoder and the decoder. To address over-parameterization challenges and streamline subnetwork search, we develop a rewind modulation mechanism that improves the RD performance. LotteryCodec outperforms VTM and sets a new state-of-the-art in single-image compression. LotteryCodec also enables adaptive decoding complexity through adjustable mask ratios, offering flexible compression solutions for diverse device constraints and application requirements. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "V61nluxFlR@OpenReview",
      "index": 107,
      "title": "Aligning with Logic: Measuring, Evaluating and Improving Logical Preference Consistency in Large Language Models",
      "authors": [
        "Yinhong Liu",
        "Zhijiang Guo",
        "Tianya Liang",
        "Ehsan Shareghi",
        "Ivan Vulić",
        "Nigel Collier"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "consistency",
        "logical",
        "preference",
        "llms",
        "decision",
        "logic",
        "improving",
        "making",
        "llm",
        "aligning"
      ],
      "summary": "Large Language Models (LLMs) are expected to be predictable and trustworthy to support reliable decision-making systems. Yet current LLMs often show inconsistencies in their judgments. In this work, we examine \\textit{logical preference consistency} as a foundational requirement for building more dependable LLM systems, ensuring stable and coherent decision-making while minimizing erratic or contradictory outputs.To quantify the logical preference consistency, we propose a universal evaluation framework based on three fundamental properties: *transitivity*, *commutativity* and *negation invariance*.Through extensive experimentation across diverse LLMs, we demonstrate that these properties serve as strong indicators of judgment robustness.Furthermore, we introduce a data refinement and augmentation technique, REPAIR, that enhances logical consistency while maintaining alignment with human preferences. Finally, we show that improving consistency leads to better performance in LLM-driven logic-based algorithms, reinforcing stability and coherence in decision-making systems.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=V61nluxFlR"
        ],
        "venue": [
          "/venue/V61nluxFlR@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=V61nluxFlR"
        ],
        "detail": [
          "https://openreview.net/forum?id=V61nluxFlR"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "Aligning with Logic: Measuring, Evaluating and Improving Logical Preference Consistency in Large Language Models [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : Yinhong Liu , Zhijiang Guo , Tianya Liang , Ehsan Shareghi , Ivan Vulić , Nigel Collier Large Language Models (LLMs) are expected to be predictable and trustworthy to support reliable decision-making systems. Yet current LLMs often show inconsistencies in their judgments. In this work, we examine \\textit{logical preference consistency} as a foundational requirement for building more dependable LLM systems, ensuring stable and coherent decision-making while minimizing erratic or contradictory outputs.To quantify the logical preference consistency, we propose a universal evaluation framework based on three fundamental properties: *transitivity*, *commutativity* and *negation invariance*.Through extensive experimentation across diverse LLMs, we demonstrate that these properties serve as strong indicators of judgment robustness.Furthermore, we introduce a data refinement and augmentation technique, REPAIR, that enhances logical consistency while maintaining alignment with human preferences. Finally, we show that improving consistency leads to better performance in LLM-driven logic-based algorithms, reinforcing stability and coherence in decision-making systems. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "RL6d53a5jj@OpenReview",
      "index": 108,
      "title": "Probabilistic Factorial Experimental Design for Combinatorial Interventions",
      "authors": [
        "Divya Shyamal",
        "Jiaqi Zhang",
        "Caroline Uhler"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "treatments",
        "factorial",
        "experimenter",
        "dosage",
        "design",
        "combinatorial",
        "interventions",
        "intervention",
        "probabilistic",
        "optimal"
      ],
      "summary": "A _combinatorial intervention_, consisting of multiple treatments applied to a single unit with potential interactive effects, has substantial applications in fields such as biomedicine, engineering, and beyond. Given p p possible treatments, conducting all possible 2 p 2 p combinatorial interventions can be laborious and quickly becomes infeasible as p p increases. Here we introduce the _probabilistic factorial experimental design_, formalized from how scientists perform lab experiments. In this framework, the experimenter selects a dosage for each possible treatment and applies it to a group of units. Each unit independently receives a random combination of treatments, sampled from a product Bernoulli distribution determined by the dosages. Additionally, the experimenter can carry out such experiments over multiple rounds, adapting the design in an active manner. We address the optimal experimental design problem within a novel intervention model that imposes bounded-degree interactions between treatments. In the passive setting, we provide a closed-form solution for the near-optimal design. Our results prove that a dosage of 1 2 1 2 for each treatment is optimal up to a factor of 1 + O ( ln ( n ) n ) 1 + O ( ln ⁡ ( n ) n ) for estimating any k k -way interaction model, regardless of k k , and imply that O ( k p 3 k ln ( p ) ) O ( k p 3 k ln ⁡ ( p ) ) observations are required to accurately estimate this model. For the multi-round setting, we provide a near-optimal acquisition function that can be numerically optimized. We also explore several extensions of the design problem and finally validate our findings through simulations.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=RL6d53a5jj"
        ],
        "venue": [
          "/venue/RL6d53a5jj@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=RL6d53a5jj"
        ],
        "detail": [
          "https://openreview.net/forum?id=RL6d53a5jj"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Probabilistic Factorial Experimental Design for Combinatorial Interventions [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Divya Shyamal , Jiaqi Zhang , Caroline Uhler A _combinatorial intervention_, consisting of multiple treatments applied to a single unit with potential interactive effects, has substantial applications in fields such as biomedicine, engineering, and beyond. Given p p possible treatments, conducting all possible 2 p 2 p combinatorial interventions can be laborious and quickly becomes infeasible as p p increases. Here we introduce the _probabilistic factorial experimental design_, formalized from how scientists perform lab experiments. In this framework, the experimenter selects a dosage for each possible treatment and applies it to a group of units. Each unit independently receives a random combination of treatments, sampled from a product Bernoulli distribution determined by the dosages. Additionally, the experimenter can carry out such experiments over multiple rounds, adapting the design in an active manner. We address the optimal experimental design problem within a novel intervention model that imposes bounded-degree interactions between treatments. In the passive setting, we provide a closed-form solution for the near-optimal design. Our results prove that a dosage of 1 2 1 2 for each treatment is optimal up to a factor of 1 + O ( ln ( n ) n ) 1 + O ( ln ⁡ ( n ) n ) for estimating any k k -way interaction model, regardless of k k , and imply that O ( k p 3 k ln ( p ) ) O ( k p 3 k ln ⁡ ( p ) ) observations are required to accurately estimate this model. For the multi-round setting, we provide a near-optimal acquisition function that can be numerically optimized. We also explore several extensions of the design problem and finally validate our findings through simulations. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "4Z04wVQ9FY@OpenReview",
      "index": 109,
      "title": "Linearization Turns Neural Operators into Function-Valued Gaussian Processes",
      "authors": [
        "Emilia Magnani",
        "Marvin Pförtner",
        "Tobias Weber",
        "Philipp Hennig"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "operators",
        "neural",
        "linearization",
        "gaussian",
        "currying",
        "valued",
        "pdes",
        "function",
        "luno",
        "bayesian"
      ],
      "summary": "Neural operators generalize neural networks to learn mappings between function spaces from data. They are commonly used to learn solution operators of parametric partial differential equations (PDEs) or propagators of time-dependent PDEs. However, to make them useful in high-stakes simulation scenarios, their inherent predictive error must be quantified reliably. We introduce LUNO, a novel framework for approximate Bayesian uncertainty quantification in trained neural operators. Our approach leverages model linearization to push (Gaussian) weight-space uncertainty forward to the neural operator's predictions.We show that this can be interpreted as a probabilistic version of the concept of currying from functional programming, yielding a function-valued (Gaussian) random process belief. Our framework provides a practical yet theoretically sound way to apply existing Bayesian deep learning methods such as the linearized Laplace approximation to neural operators. Just as the underlying neural operator, our approach is resolution-agnostic by design.The method adds minimal prediction overhead, can be applied post-hoc without retraining the network, and scales to large models and datasets.We evaluate these aspects in a case study on Fourier neural operators.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=4Z04wVQ9FY"
        ],
        "venue": [
          "/venue/4Z04wVQ9FY@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=4Z04wVQ9FY"
        ],
        "detail": [
          "https://openreview.net/forum?id=4Z04wVQ9FY"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Linearization Turns Neural Operators into Function-Valued Gaussian Processes [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Emilia Magnani , Marvin Pförtner , Tobias Weber , Philipp Hennig Neural operators generalize neural networks to learn mappings between function spaces from data. They are commonly used to learn solution operators of parametric partial differential equations (PDEs) or propagators of time-dependent PDEs. However, to make them useful in high-stakes simulation scenarios, their inherent predictive error must be quantified reliably. We introduce LUNO, a novel framework for approximate Bayesian uncertainty quantification in trained neural operators. Our approach leverages model linearization to push (Gaussian) weight-space uncertainty forward to the neural operator's predictions.We show that this can be interpreted as a probabilistic version of the concept of currying from functional programming, yielding a function-valued (Gaussian) random process belief. Our framework provides a practical yet theoretically sound way to apply existing Bayesian deep learning methods such as the linearized Laplace approximation to neural operators. Just as the underlying neural operator, our approach is resolution-agnostic by design.The method adds minimal prediction overhead, can be applied post-hoc without retraining the network, and scales to large models and datasets.We evaluate these aspects in a case study on Fourier neural operators. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "IYOksPHJKT@OpenReview",
      "index": 110,
      "title": "Catch Your Emotion: Sharpening Emotion Perception in Multimodal Large Language Models",
      "authors": [
        "Yiyang Fang",
        "Jian Liang",
        "Wenke Huang",
        "He Li",
        "Kehua Su",
        "Mang Ye"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "emotion",
        "sepm",
        "mllms",
        "emotional",
        "sharpening",
        "visual",
        "perception",
        "multimodal",
        "emotions",
        "cues"
      ],
      "summary": "Multimodal large language models (MLLMs) have achieved impressive progress in tasks such as visual question answering and visual understanding, but they still face significant challenges in emotional reasoning. Current methods to enhance emotional understanding typically rely on fine-tuning or manual annotations, which are resource-intensive and limit scalability. In this work, we focus on improving the ability of MLLMs to capture emotions during the inference phase. Specifically, MLLMs encounter two main issues: they struggle to distinguish between semantically similar emotions, leading to misclassification, and they are overwhelmed by redundant or irrelevant visual information, which distracts from key emotional cues. To address these, we propose Sharpening Emotion Perception in MLLMs (SEPM), which incorporates a Confidence-Guided Coarse-to-Fine Inference framework to refine emotion classification by guiding the model through simpler tasks. Additionally, SEPM employs Focus-on-Emotion Visual Augmentation to reduce visual redundancy by directing the attention of models to relevant emotional cues in images. Experimental results demonstrate that SEPM significantly improves MLLM performance on emotion-related tasks, providing a resource-efficient and scalable solution for emotion recognition.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=IYOksPHJKT"
        ],
        "venue": [
          "/venue/IYOksPHJKT@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=IYOksPHJKT"
        ],
        "detail": [
          "https://openreview.net/forum?id=IYOksPHJKT"
        ]
      },
      "scores": {
        "pdf": 9,
        "kimi": 7
      },
      "raw_excerpt": "Catch Your Emotion: Sharpening Emotion Perception in Multimodal Large Language Models [PDF 9 ] [Copy] [Kimi 7 ] [REL] Authors : Yiyang Fang , Jian Liang , Wenke Huang , He Li , Kehua Su , Mang Ye Multimodal large language models (MLLMs) have achieved impressive progress in tasks such as visual question answering and visual understanding, but they still face significant challenges in emotional reasoning. Current methods to enhance emotional understanding typically rely on fine-tuning or manual annotations, which are resource-intensive and limit scalability. In this work, we focus on improving the ability of MLLMs to capture emotions during the inference phase. Specifically, MLLMs encounter two main issues: they struggle to distinguish between semantically similar emotions, leading to misclassification, and they are overwhelmed by redundant or irrelevant visual information, which distracts from key emotional cues. To address these, we propose Sharpening Emotion Perception in MLLMs (SEPM), which incorporates a Confidence-Guided Coarse-to-Fine Inference framework to refine emotion classification by guiding the model through simpler tasks. Additionally, SEPM employs Focus-on-Emotion Visual Augmentation to reduce visual redundancy by directing the attention of models to relevant emotional cues in images. Experimental results demonstrate that SEPM significantly improves MLLM performance on emotion-related tasks, providing a resource-efficient and scalable solution for emotion recognition. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Mlmpf4Izrj@OpenReview",
      "index": 111,
      "title": "Efficiently Vectorized MCMC on Modern Accelerators",
      "authors": [
        "Hugh Dance",
        "Pierre Glaser",
        "Peter Orbanz",
        "Ryan P. Adams"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "mcmc",
        "vmap",
        "fsms",
        "chain",
        "algorithms",
        "tools",
        "ups",
        "vectorized",
        "synchronization",
        "vectorizing"
      ],
      "summary": "With the advent of automatic vectorization tools (e.g., JAX's vmap), writing multi-chain MCMC algorithms is often now as simple as invoking those tools on single-chain code. Whilst convenient, for various MCMC algorithms this results in a synchronization problem---loosely speaking, at each iteration all chains running in parallel must wait until the last chain has finished drawing its sample. In this work, we show how to design single-chain MCMC algorithms in a way that avoids synchronization overheads when vectorizing with tools like vmap, by using the framework of finite state machines (FSMs). Using a simplified model, we derive an exact theoretical form of the obtainable speed-ups using our approach, and use it to make principled recommendations for optimal algorithm design. We implement several popular MCMC algorithms as FSMs, including Elliptical Slice Sampling, HMC-NUTS, and Delayed Rejection, demonstrating speed-ups of up to an order of magnitude in experiments.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Mlmpf4Izrj"
        ],
        "venue": [
          "/venue/Mlmpf4Izrj@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Mlmpf4Izrj"
        ],
        "detail": [
          "https://openreview.net/forum?id=Mlmpf4Izrj"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Efficiently Vectorized MCMC on Modern Accelerators [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Hugh Dance , Pierre Glaser , Peter Orbanz , Ryan P. Adams With the advent of automatic vectorization tools (e.g., JAX's vmap), writing multi-chain MCMC algorithms is often now as simple as invoking those tools on single-chain code. Whilst convenient, for various MCMC algorithms this results in a synchronization problem---loosely speaking, at each iteration all chains running in parallel must wait until the last chain has finished drawing its sample. In this work, we show how to design single-chain MCMC algorithms in a way that avoids synchronization overheads when vectorizing with tools like vmap, by using the framework of finite state machines (FSMs). Using a simplified model, we derive an exact theoretical form of the obtainable speed-ups using our approach, and use it to make principled recommendations for optimal algorithm design. We implement several popular MCMC algorithms as FSMs, including Elliptical Slice Sampling, HMC-NUTS, and Delayed Rejection, demonstrating speed-ups of up to an order of magnitude in experiments. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "5EbiopWH6e@OpenReview",
      "index": 112,
      "title": "Implicit Language Models are RNNs: Balancing Parallelization and Expressivity",
      "authors": [
        "Mark Schoene",
        "Babak Rahmani",
        "Heiner Kremer",
        "Fabian Falck",
        "Hitesh Ballani",
        "Jannes Gladrow"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "ssms",
        "implicit",
        "rnns",
        "parallelization",
        "expressivity",
        "language",
        "207b",
        "languagemodels",
        "transformers",
        "convergence"
      ],
      "summary": "State-space models (SSMs) and transformers dominate the language modeling landscape. However, they are constrained to a lower computational complexity than classical recurrent neural networks (RNNs), limiting their expressivity. In contrast, RNNs lack parallelization during training, raising fundamental questions about the trade off between parallelization and expressivity. We propose implicit SSMs, which iterate a transformation until convergence to a fixed point. Theoretically, we show that implicit SSMs implement the non-linear state-transitions of RNNs. Empirically, we find that only approximate fixed-point convergence suffices, enabling the design of a scalable training curriculum that largely retains parallelization, with full convergence required only for a small subset of tokens. Our approach demonstrates superior state-tracking capabilities on regular languages, surpassing transformers and SSMs. We further scale implicit SSMs to natural language reasoning tasks and pretraining of large-scale language models up to 1.3B parameters on 207B tokens - representing, to our knowledge, the largest implicit model trained to date. Notably, our implicit models outperform their explicit counterparts on standard benchmarks. Our code is publicly available at github.com/microsoft/implicit_languagemodels",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=5EbiopWH6e"
        ],
        "venue": [
          "/venue/5EbiopWH6e@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=5EbiopWH6e"
        ],
        "detail": [
          "https://openreview.net/forum?id=5EbiopWH6e"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 2
      },
      "raw_excerpt": "Implicit Language Models are RNNs: Balancing Parallelization and Expressivity [PDF 1 ] [Copy] [Kimi 2 ] [REL] Authors : Mark Schoene , Babak Rahmani , Heiner Kremer , Fabian Falck , Hitesh Ballani , Jannes Gladrow State-space models (SSMs) and transformers dominate the language modeling landscape. However, they are constrained to a lower computational complexity than classical recurrent neural networks (RNNs), limiting their expressivity. In contrast, RNNs lack parallelization during training, raising fundamental questions about the trade off between parallelization and expressivity. We propose implicit SSMs, which iterate a transformation until convergence to a fixed point. Theoretically, we show that implicit SSMs implement the non-linear state-transitions of RNNs. Empirically, we find that only approximate fixed-point convergence suffices, enabling the design of a scalable training curriculum that largely retains parallelization, with full convergence required only for a small subset of tokens. Our approach demonstrates superior state-tracking capabilities on regular languages, surpassing transformers and SSMs. We further scale implicit SSMs to natural language reasoning tasks and pretraining of large-scale language models up to 1.3B parameters on 207B tokens - representing, to our knowledge, the largest implicit model trained to date. Notably, our implicit models outperform their explicit counterparts on standard benchmarks. Our code is publicly available at github.com/microsoft/implicit_languagemodels Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Qq5h78Eshy@OpenReview",
      "index": 113,
      "title": "Rapid Overfitting of Multi-Pass SGD in Stochastic Convex Optimization",
      "authors": [
        "Shira Vansover-Hager",
        "Tomer Koren",
        "Roi Livni"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "sgd",
        "pass",
        "sco",
        "overfitting",
        "eta",
        "sqrt",
        "sample",
        "theta",
        "smooth",
        "schliserman"
      ],
      "summary": "We study the out-of-sample performance of multi-pass stochastic gradient descent (SGD) in the fundamental stochastic convex optimization (SCO) model. While one-pass SGD is known to achieve an optimal Θ ( 1 / n − − √ ) Θ ( 1 / n ) excess population loss given a sample of size n n , much less is understood about the multi-pass version of the algorithm which is widely used in practice. Somewhat surprisingly, we show that in the general non-smooth case of SCO, just a few epochs of SGD can already hurt its out-of-sample performance significantly and lead to overfitting. In particular, using a step size η = Θ ( 1 / n − − √ ) η = Θ ( 1 / n ) , which gives the optimal rate after one pass, can lead to population loss as large as Ω ( 1 ) Ω ( 1 ) after just one additional pass. More generally, we show that the population loss from the second pass onward is of the order Θ ( 1 / ( η T ) + η T − − √ ) Θ ( 1 / ( η T ) + η T ) , where T T is the total number of steps. These results reveal a certain phase-transition in the out-of-sample behavior of SGD after the first epoch, as well as a sharp separation between the rates of overfitting in the smooth and non-smooth cases of SCO. Additionally, we extend our results to with-replacement SGD, proving that the same asymptotic bounds hold after O ( n log n ) O ( n log ⁡ n ) steps. Finally, we also prove a lower bound of Ω ( η n − − √ ) Ω ( η n ) on the generalization gap of one-pass SGD in dimension d = O ˜ ( n ) d = O ~ ( n ) , improving on recent results of Koren et al. (2022) and Schliserman et al. (2024).",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Qq5h78Eshy"
        ],
        "venue": [
          "/venue/Qq5h78Eshy@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Qq5h78Eshy"
        ],
        "detail": [
          "https://openreview.net/forum?id=Qq5h78Eshy"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 1
      },
      "raw_excerpt": "Rapid Overfitting of Multi-Pass SGD in Stochastic Convex Optimization [PDF 4 ] [Copy] [Kimi 1 ] [REL] Authors : Shira Vansover-Hager , Tomer Koren , Roi Livni We study the out-of-sample performance of multi-pass stochastic gradient descent (SGD) in the fundamental stochastic convex optimization (SCO) model. While one-pass SGD is known to achieve an optimal Θ ( 1 / n − − √ ) Θ ( 1 / n ) excess population loss given a sample of size n n , much less is understood about the multi-pass version of the algorithm which is widely used in practice. Somewhat surprisingly, we show that in the general non-smooth case of SCO, just a few epochs of SGD can already hurt its out-of-sample performance significantly and lead to overfitting. In particular, using a step size η = Θ ( 1 / n − − √ ) η = Θ ( 1 / n ) , which gives the optimal rate after one pass, can lead to population loss as large as Ω ( 1 ) Ω ( 1 ) after just one additional pass. More generally, we show that the population loss from the second pass onward is of the order Θ ( 1 / ( η T ) + η T − − √ ) Θ ( 1 / ( η T ) + η T ) , where T T is the total number of steps. These results reveal a certain phase-transition in the out-of-sample behavior of SGD after the first epoch, as well as a sharp separation between the rates of overfitting in the smooth and non-smooth cases of SCO. Additionally, we extend our results to with-replacement SGD, proving that the same asymptotic bounds hold after O ( n log n ) O ( n log ⁡ n ) steps. Finally, we also prove a lower bound of Ω ( η n − − √ ) Ω ( η n ) on the generalization gap of one-pass SGD in dimension d = O ˜ ( n ) d = O ~ ( n ) , improving on recent results of Koren et al. (2022) and Schliserman et al. (2024). Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "WISfJyOA6M@OpenReview",
      "index": 114,
      "title": "PhySpec: Physically Consistent Spectral Reconstruction via Orthogonal Subspace Decomposition and Self-Supervised Meta-Auxiliary Learning",
      "authors": [
        "Xingxing Yang",
        "Jie Chen",
        "Zaifeng Yang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "maxl",
        "hsi",
        "physpec",
        "reconstruction",
        "physical",
        "hsis",
        "rgb",
        "physically",
        "subspace",
        "meta"
      ],
      "summary": "This paper presents a novel approach to hyperspectral image (HSI) reconstruction from RGB images, addressing fundamental limitations in existing learning-based methods from a physical perspective. We discuss and aim to address the ``colorimetric dilemma\": failure to consistently reproduce ground-truth RGB from predicted HSI, thereby compromising physical integrity and reliability in practical applications. To tackle this issue, we propose PhySpec, a physically consistent framework for robust HSI reconstruction. Our approach fundamentally exploits the intrinsic physical relationship between HSIs and corresponding RGBs by employing orthogonal subspace decomposition, which enables explicit estimation of camera spectral sensitivity (CSS). This ensures that our reconstructed spectra align with well-established physical principles, enhancing their reliability and fidelity. Moreover, to efficiently use internal information from test samples, we propose a self-supervised meta-auxiliary learning (MAXL) strategy that rapidly adapts the trained parameters to unseen samples using only a few gradient descent steps at test time, while simultaneously constraining the generated HSIs to accurately recover ground-truth RGB values. Thus, MAXL reinforces the physical integrity of the reconstruction process. Extensive qualitative and quantitative evaluations validate the efficacy of our proposed framework, showing superior performance compared to SOTA methods.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=WISfJyOA6M"
        ],
        "venue": [
          "/venue/WISfJyOA6M@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=WISfJyOA6M"
        ],
        "detail": [
          "https://openreview.net/forum?id=WISfJyOA6M"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "PhySpec: Physically Consistent Spectral Reconstruction via Orthogonal Subspace Decomposition and Self-Supervised Meta-Auxiliary Learning [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Xingxing Yang , Jie Chen , Zaifeng Yang This paper presents a novel approach to hyperspectral image (HSI) reconstruction from RGB images, addressing fundamental limitations in existing learning-based methods from a physical perspective. We discuss and aim to address the ``colorimetric dilemma\": failure to consistently reproduce ground-truth RGB from predicted HSI, thereby compromising physical integrity and reliability in practical applications. To tackle this issue, we propose PhySpec, a physically consistent framework for robust HSI reconstruction. Our approach fundamentally exploits the intrinsic physical relationship between HSIs and corresponding RGBs by employing orthogonal subspace decomposition, which enables explicit estimation of camera spectral sensitivity (CSS). This ensures that our reconstructed spectra align with well-established physical principles, enhancing their reliability and fidelity. Moreover, to efficiently use internal information from test samples, we propose a self-supervised meta-auxiliary learning (MAXL) strategy that rapidly adapts the trained parameters to unseen samples using only a few gradient descent steps at test time, while simultaneously constraining the generated HSIs to accurately recover ground-truth RGB values. Thus, MAXL reinforces the physical integrity of the reconstruction process. Extensive qualitative and quantitative evaluations validate the efficacy of our proposed framework, showing superior performance compared to SOTA methods. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "WR0ahlhOoy@OpenReview",
      "index": 115,
      "title": "Improving Zero-Shot Adversarial Robustness in Vision-Language Models by Closed-form Alignment of Adversarial Path Simplices",
      "authors": [
        "Junhao Dong",
        "Piotr Koniusz",
        "Yifei Zhang",
        "Hao Zhu",
        "Weiming Liu",
        "Xinghua Qu",
        "Yew Soon ONG"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "adversarial",
        "simplices",
        "adversaries",
        "clean",
        "vlm",
        "shot",
        "vision",
        "intermediate",
        "decision",
        "zero"
      ],
      "summary": "Vision-Language Models (VLMs) such as CLIP excel at zero-shot classification due to large-scale pre-training but are vulnerable to adversarial examples. Adversarial fine-tuning robustifies zero-shot models by aligning prediction scores of individual adversaries with their clean counterparts, which typically overlooks intermediate adversarial samples along the adversarial trajectory crossing the decision boundary. Such intermediate adversaries and their vicinity produce informative representations capturing the decision boundary in detail. They can be improved by sampling adversarial candidates from simplices formed by joining two consecutive vertices on the adversarial trajectory and their clean counterpart. However, sampling simplices for adversaries is very costly. To train robust VLM, we overcome these limitations by Taylor expansion and formulating an upper-bound of alignment loss that depends on the Jacobian/Hessian obtained at clean samples. As regions between clean and intermediate adversarial samples capture a larger decision landscape, we robustify VLM by plausible adversaries from simplices by our closed-form formulation equivalent to infinite uniform sampling of the simplex. We obtain state-of-the-art robustness across 15 datasets and diverse vision-language tasks.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=WR0ahlhOoy"
        ],
        "venue": [
          "/venue/WR0ahlhOoy@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=WR0ahlhOoy"
        ],
        "detail": [
          "https://openreview.net/forum?id=WR0ahlhOoy"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "Improving Zero-Shot Adversarial Robustness in Vision-Language Models by Closed-form Alignment of Adversarial Path Simplices [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : Junhao Dong , Piotr Koniusz , Yifei Zhang , Hao Zhu , Weiming Liu , Xinghua Qu , Yew Soon ONG Vision-Language Models (VLMs) such as CLIP excel at zero-shot classification due to large-scale pre-training but are vulnerable to adversarial examples. Adversarial fine-tuning robustifies zero-shot models by aligning prediction scores of individual adversaries with their clean counterparts, which typically overlooks intermediate adversarial samples along the adversarial trajectory crossing the decision boundary. Such intermediate adversaries and their vicinity produce informative representations capturing the decision boundary in detail. They can be improved by sampling adversarial candidates from simplices formed by joining two consecutive vertices on the adversarial trajectory and their clean counterpart. However, sampling simplices for adversaries is very costly. To train robust VLM, we overcome these limitations by Taylor expansion and formulating an upper-bound of alignment loss that depends on the Jacobian/Hessian obtained at clean samples. As regions between clean and intermediate adversarial samples capture a larger decision landscape, we robustify VLM by plausible adversaries from simplices by our closed-form formulation equivalent to infinite uniform sampling of the simplex. We obtain state-of-the-art robustness across 15 datasets and diverse vision-language tasks. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "UKR3HsAFkC@OpenReview",
      "index": 116,
      "title": "Achieving Linear Speedup and Near-Optimal Complexity for Decentralized Optimization over Row-stochastic Networks",
      "authors": [
        "Liyuan Liang",
        "Xinyi Chen",
        "Gan Luo",
        "Kun Yuan"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "row",
        "stochastic",
        "decentralized",
        "diag",
        "optimization",
        "speedup",
        "pull",
        "attain",
        "achieving",
        "lower"
      ],
      "summary": "A key challenge in decentralized optimization is determining the optimal convergence rate and designing algorithms to achieve it. While this problem has been extensively addressed for doubly-stochastic and column-stochastic mixing matrices, the row-stochastic scenario remains unexplored. This paper bridges this gap by introducing effective metrics to capture the influence of row-stochastic mixing matrices and establishing the first convergence lower bound for decentralized learning over row-stochastic networks. However, existing algorithms fail to attain this lower bound due to two key issues: deviation in the descent direction caused by the adapted gradient tracking (GT) and instability introduced by the Pull-Diag protocol. To address descent deviation, we propose a novel analysis framework demonstrating that Pull-Diag-GT achieves linear speedup—the first such result for row-stochastic decentralized optimization. Moreover, by incorporating a multi-step gossip (MG) protocol, we resolve the instability issue and attain the lower bound, achieving near-optimal complexity for decentralized optimization over row-stochastic networks.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=UKR3HsAFkC"
        ],
        "venue": [
          "/venue/UKR3HsAFkC@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=UKR3HsAFkC"
        ],
        "detail": [
          "https://openreview.net/forum?id=UKR3HsAFkC"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "Achieving Linear Speedup and Near-Optimal Complexity for Decentralized Optimization over Row-stochastic Networks [PDF 3 ] [Copy] [Kimi 1 ] [REL] Authors : Liyuan Liang , Xinyi Chen , Gan Luo , Kun Yuan A key challenge in decentralized optimization is determining the optimal convergence rate and designing algorithms to achieve it. While this problem has been extensively addressed for doubly-stochastic and column-stochastic mixing matrices, the row-stochastic scenario remains unexplored. This paper bridges this gap by introducing effective metrics to capture the influence of row-stochastic mixing matrices and establishing the first convergence lower bound for decentralized learning over row-stochastic networks. However, existing algorithms fail to attain this lower bound due to two key issues: deviation in the descent direction caused by the adapted gradient tracking (GT) and instability introduced by the Pull-Diag protocol. To address descent deviation, we propose a novel analysis framework demonstrating that Pull-Diag-GT achieves linear speedup—the first such result for row-stochastic decentralized optimization. Moreover, by incorporating a multi-step gossip (MG) protocol, we resolve the instability issue and attain the lower bound, achieving near-optimal complexity for decentralized optimization over row-stochastic networks. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "WbP2OwMULq@OpenReview",
      "index": 117,
      "title": "HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation",
      "authors": [
        "Tianwei Lin",
        "Wenqiao Zhang",
        "Sijing Li",
        "Yuqian Yuan",
        "Binhe Yu",
        "Haoyuan Li",
        "Wanggui He",
        "Hao Jiang",
        "Mengze Li",
        "Song xiaohui",
        "Siliang Tang",
        "Jun Xiao",
        "Hui Lin",
        "Yueting Zhuang",
        "Beng Chin Ooi"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "healthgpt",
        "comprehension",
        "medical",
        "generation",
        "heterogeneous",
        "language",
        "dcdmllm",
        "vision",
        "adaptation",
        "visual"
      ],
      "summary": "We present **HealthGPT**, a powerful Medical Large Vision-Language Model (Med-LVLM) that integrates medical visual comprehension and generation capabilities within a unified autoregressive paradigm. Our bootstrapping philosophy is to progressively adapt heterogeneous comprehension and generation knowledge to pre-trained Large Language Models (LLMs). This is achieved through a novel heterogeneous low-rank adaptation **(H-LoRA)** technique, which is complemented by a tailored hierarchical visual perception **(HVP)** approach and a three-stage learning strategy **(TLS)**. To effectively learn the HealthGPT, we devise a comprehensive medical domain-specific comprehension and generation dataset called **VL-Health**. Experimental results demonstrate exceptional performance and scalability of HealthGPT in medical visual unified tasks. Our project can be accessed at https://github.com/DCDmllm/HealthGPT.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=WbP2OwMULq"
        ],
        "venue": [
          "/venue/WbP2OwMULq@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=WbP2OwMULq"
        ],
        "detail": [
          "https://openreview.net/forum?id=WbP2OwMULq"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 2
      },
      "raw_excerpt": "HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation [PDF 4 ] [Copy] [Kimi 2 ] [REL] Authors : Tianwei Lin , Wenqiao Zhang , Sijing Li , Yuqian Yuan , Binhe Yu , Haoyuan Li , Wanggui He , Hao Jiang , Mengze Li , Song xiaohui , Siliang Tang , Jun Xiao , Hui Lin , Yueting Zhuang , Beng Chin Ooi We present **HealthGPT**, a powerful Medical Large Vision-Language Model (Med-LVLM) that integrates medical visual comprehension and generation capabilities within a unified autoregressive paradigm. Our bootstrapping philosophy is to progressively adapt heterogeneous comprehension and generation knowledge to pre-trained Large Language Models (LLMs). This is achieved through a novel heterogeneous low-rank adaptation **(H-LoRA)** technique, which is complemented by a tailored hierarchical visual perception **(HVP)** approach and a three-stage learning strategy **(TLS)**. To effectively learn the HealthGPT, we devise a comprehensive medical domain-specific comprehension and generation dataset called **VL-Health**. Experimental results demonstrate exceptional performance and scalability of HealthGPT in medical visual unified tasks. Our project can be accessed at https://github.com/DCDmllm/HealthGPT. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "WxY61MmHYo@OpenReview",
      "index": 118,
      "title": "Scaling Laws for Task-Optimized Models of the Primate Visual Ventral Stream",
      "authors": [
        "Abdulkadir Gokce",
        "Martin Schrimpf"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "primate",
        "ventral",
        "scaling",
        "alignment",
        "brain",
        "stream",
        "visual",
        "models",
        "datasets",
        "laws"
      ],
      "summary": "When trained on large-scale object classification datasets, certain artificial neural network models begin to approximate core object recognition behaviors and neural response patterns in the primate brain. While recent machine learning advances suggest that scaling compute, model size, and dataset size improves task performance, the impact of scaling on brain alignment remains unclear. In this study, we explore scaling laws for modeling the primate visual ventral stream by systematically evaluating over 600 models trained under controlled conditions on benchmarks spanning V1, V2, V4, IT and behavior. We find that while behavioral alignment continues to scale with larger models, neural alignment saturates. This observation remains true across model architectures and training datasets, even though models with stronger inductive biases and datasets with higher-quality images are more compute-efficient. Increased scaling is especially beneficial for higher-level visual areas, where small models trained on few samples exhibit only poor alignment. Our results suggest that while scaling current architectures and datasets might suffice for alignment with human core object recognition behavior, it will not yield improved models of the brain's visual ventral stream, highlighting the need for novel strategies in building brain models.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=WxY61MmHYo"
        ],
        "venue": [
          "/venue/WxY61MmHYo@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=WxY61MmHYo"
        ],
        "detail": [
          "https://openreview.net/forum?id=WxY61MmHYo"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Scaling Laws for Task-Optimized Models of the Primate Visual Ventral Stream [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Abdulkadir Gokce , Martin Schrimpf When trained on large-scale object classification datasets, certain artificial neural network models begin to approximate core object recognition behaviors and neural response patterns in the primate brain. While recent machine learning advances suggest that scaling compute, model size, and dataset size improves task performance, the impact of scaling on brain alignment remains unclear. In this study, we explore scaling laws for modeling the primate visual ventral stream by systematically evaluating over 600 models trained under controlled conditions on benchmarks spanning V1, V2, V4, IT and behavior. We find that while behavioral alignment continues to scale with larger models, neural alignment saturates. This observation remains true across model architectures and training datasets, even though models with stronger inductive biases and datasets with higher-quality images are more compute-efficient. Increased scaling is especially beneficial for higher-level visual areas, where small models trained on few samples exhibit only poor alignment. Our results suggest that while scaling current architectures and datasets might suffice for alignment with human core object recognition behavior, it will not yield improved models of the brain's visual ventral stream, highlighting the need for novel strategies in building brain models. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "XXFBqfwnUp@OpenReview",
      "index": 119,
      "title": "Learning the RoPEs: Better 2D and 3D Position Encodings with STRING",
      "authors": [
        "Connor Schenck",
        "Isaac Reid",
        "Mithun Jacob",
        "Alex Bewley",
        "Joshua Ainslie",
        "David Rendleman",
        "Deepali Jain",
        "Mohit Sharma",
        "Kumar Avinava Dubey",
        "Ayzaan Wahid",
        "Sumeet Singh",
        "René Wagner",
        "Tianli Ding",
        "Chuyuan Fu",
        "Arunkumar Byravan",
        "Jacob J Varley",
        "Alexey Gritsenko",
        "Matthias Minderer",
        "Dmitry Kalashnikov",
        "Jonathan Tompson",
        "Vikas Sindhwani",
        "Krzysztof Choromanski"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "string",
        "encodings",
        "robotics",
        "position",
        "textbf",
        "controllers",
        "ropes",
        "token",
        "translationally",
        "rotary"
      ],
      "summary": "We introduce STRING STRING : Separable Translationally Invariant Position Encodings. STRING extends Rotary Position Encodings, a recently proposed and widely used algorithm in large language models, via a unifying theoretical framework. Importantly, STRING still provides exact exact translation invariance, including token coordinates of arbitrary dimensionality, whilst maintaining a low computational footprint. These properties are especially important in robotics, where efficient 3D token representation is key. We integrate STRING into Vision Transformers with RGB(-D) inputs (color plus optional depth), showing substantial gains, e.g. in open-vocabulary object detection and for robotics controllers.We complement our experiments with a rigorous mathematical analysis, proving the universality of our methods. Videos of STRING-based robotics controllers can be found here: https://sites.google.com/view/string-robotics.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=XXFBqfwnUp"
        ],
        "venue": [
          "/venue/XXFBqfwnUp@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=XXFBqfwnUp"
        ],
        "detail": [
          "https://openreview.net/forum?id=XXFBqfwnUp"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "Learning the RoPEs: Better 2D and 3D Position Encodings with STRING [PDF 3 ] [Copy] [Kimi 1 ] [REL] Authors : Connor Schenck , Isaac Reid , Mithun Jacob , Alex Bewley , Joshua Ainslie , David Rendleman , Deepali Jain , Mohit Sharma , Kumar Avinava Dubey , Ayzaan Wahid , Sumeet Singh , René Wagner , Tianli Ding , Chuyuan Fu , Arunkumar Byravan , Jacob J Varley , Alexey Gritsenko , Matthias Minderer , Dmitry Kalashnikov , Jonathan Tompson , Vikas Sindhwani , Krzysztof Choromanski We introduce STRING STRING : Separable Translationally Invariant Position Encodings. STRING extends Rotary Position Encodings, a recently proposed and widely used algorithm in large language models, via a unifying theoretical framework. Importantly, STRING still provides exact exact translation invariance, including token coordinates of arbitrary dimensionality, whilst maintaining a low computational footprint. These properties are especially important in robotics, where efficient 3D token representation is key. We integrate STRING into Vision Transformers with RGB(-D) inputs (color plus optional depth), showing substantial gains, e.g. in open-vocabulary object detection and for robotics controllers.We complement our experiments with a rigorous mathematical analysis, proving the universality of our methods. Videos of STRING-based robotics controllers can be found here: https://sites.google.com/view/string-robotics. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Y19ngWhN0b@OpenReview",
      "index": 120,
      "title": "Weakly-Supervised Contrastive Learning for Imprecise Class Labels",
      "authors": [
        "Zi-Hao Zhou",
        "Jun-Jie Wang",
        "Tong Wei",
        "Min-Ling Zhang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "contrastive",
        "supervised",
        "wsc",
        "imprecise",
        "speechless",
        "10308",
        "learning",
        "weakly",
        "labels",
        "similarity"
      ],
      "summary": "Contrastive learning has achieved remarkable success in learning effective representations, with supervised contrastive learning often outperforming self-supervised approaches. However, in real-world scenarios, data annotations are often ambiguous or inaccurate, meaning that class labels may not reliably indicate whether two examples belong to the same class. This limitation restricts the applicability of supervised contrastive learning. To address this challenge, we introduce the concept of ``continuous semantic similarity'' to define positive and negative pairs. Instead of directly relying on imprecise class labels, we measure the semantic similarity between example pairs, which quantifies how closely they belong to the same category by iteratively refining weak supervisory signals. Based on this concept, we propose a graph-theoretic framework for weakly-supervised contrastive learning, where semantic similarity serves as the graph weights. Our framework is highly versatile and can be applied to many weakly-supervised learning scenarios. We demonstrate its effectiveness through experiments in two common settings, i.e., noisy label and partial label learning, where existing methods can be easily integrated to significantly improve performance. Theoretically, we establish an error bound for our approach, showing that it can approximate supervised contrastive learning under mild conditions. The implementation code is available at [https://github.com/Speechless-10308/WSC](https://github.com/Speechless-10308/WSC).",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Y19ngWhN0b"
        ],
        "venue": [
          "/venue/Y19ngWhN0b@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Y19ngWhN0b"
        ],
        "detail": [
          "https://openreview.net/forum?id=Y19ngWhN0b"
        ]
      },
      "scores": {
        "pdf": 7,
        "kimi": 3
      },
      "raw_excerpt": "Weakly-Supervised Contrastive Learning for Imprecise Class Labels [PDF 7 ] [Copy] [Kimi 3 ] [REL] Authors : Zi-Hao Zhou , Jun-Jie Wang , Tong Wei , Min-Ling Zhang Contrastive learning has achieved remarkable success in learning effective representations, with supervised contrastive learning often outperforming self-supervised approaches. However, in real-world scenarios, data annotations are often ambiguous or inaccurate, meaning that class labels may not reliably indicate whether two examples belong to the same class. This limitation restricts the applicability of supervised contrastive learning. To address this challenge, we introduce the concept of ``continuous semantic similarity'' to define positive and negative pairs. Instead of directly relying on imprecise class labels, we measure the semantic similarity between example pairs, which quantifies how closely they belong to the same category by iteratively refining weak supervisory signals. Based on this concept, we propose a graph-theoretic framework for weakly-supervised contrastive learning, where semantic similarity serves as the graph weights. Our framework is highly versatile and can be applied to many weakly-supervised learning scenarios. We demonstrate its effectiveness through experiments in two common settings, i.e., noisy label and partial label learning, where existing methods can be easily integrated to significantly improve performance. Theoretically, we establish an error bound for our approach, showing that it can approximate supervised contrastive learning under mild conditions. The implementation code is available at [https://github.com/Speechless-10308/WSC](https://github.com/Speechless-10308/WSC). Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "YucuAuXMpT@OpenReview",
      "index": 121,
      "title": "Not all solutions are created equal: An analytical dissociation of functional and representational similarity in deep linear neural networks",
      "authors": [
        "Lukas Braun",
        "Erin Grant",
        "Andrew Saxe"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "representational",
        "similarity",
        "functional",
        "networks",
        "representations",
        "analysable",
        "connectionism",
        "dissociation",
        "neural",
        "analytical"
      ],
      "summary": "A foundational principle of connectionism is that perception, action, and cognition emerge from parallel computations among simple, interconnected units that generate and rely on neural representations. Accordingly, researchers employ multivariate pattern analysis to decode and compare the neural codes of artificial and biological networks, aiming to uncover their functions. However, there is limited analytical understanding of how a network’s representation and function relate, despite this being essential to any quantitative notion of underlying function or functional similarity. We address this question using fully analysable two-layer linear networks and numerical simulations in nonlinear networks. We find that function and representation are dissociated, allowing representational similarity without functional similarity and vice versa. Further, we show that neither robustness to input noise nor the level of generalisation error constrain representations to the task. In contrast, networks robust to parameter noise have limited representational flexibility and must employ task-specific representations. Our findings suggest that representational alignment reflects computational advantages beyond functional alignment alone, with significant implications for interpreting and comparing the representations of connectionist systems",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=YucuAuXMpT"
        ],
        "venue": [
          "/venue/YucuAuXMpT@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=YucuAuXMpT"
        ],
        "detail": [
          "https://openreview.net/forum?id=YucuAuXMpT"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Not all solutions are created equal: An analytical dissociation of functional and representational similarity in deep linear neural networks [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Lukas Braun , Erin Grant , Andrew Saxe A foundational principle of connectionism is that perception, action, and cognition emerge from parallel computations among simple, interconnected units that generate and rely on neural representations. Accordingly, researchers employ multivariate pattern analysis to decode and compare the neural codes of artificial and biological networks, aiming to uncover their functions. However, there is limited analytical understanding of how a network’s representation and function relate, despite this being essential to any quantitative notion of underlying function or functional similarity. We address this question using fully analysable two-layer linear networks and numerical simulations in nonlinear networks. We find that function and representation are dissociated, allowing representational similarity without functional similarity and vice versa. Further, we show that neither robustness to input noise nor the level of generalisation error constrain representations to the task. In contrast, networks robust to parameter noise have limited representational flexibility and must employ task-specific representations. Our findings suggest that representational alignment reflects computational advantages beyond functional alignment alone, with significant implications for interpreting and comparing the representations of connectionist systems Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Yv416IYTFp@OpenReview",
      "index": 122,
      "title": "PASS: Private Attributes Protection with Stochastic Data Substitution",
      "authors": [
        "Yizhuo Chen",
        "Chun-Fu (Richard) Chen",
        "Hsiang Hsu",
        "Shaohan Hu",
        "Tarek Abdelzaher"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "pass",
        "private",
        "attributes",
        "protection",
        "services",
        "substitution",
        "soundly",
        "substantiates",
        "data",
        "inadvertently"
      ],
      "summary": "The growing Machine Learning (ML) services require extensive collections of user data, which may inadvertently include people's private information irrelevant to the services. Various studies have been proposed to protect private attributes by removing them from the data while maintaining the utilities of the data for downstream tasks. Nevertheless, as we theoretically and empirically show in the paper, these methods reveal severe vulnerability because of a common weakness rooted in their adversarial training based strategies. To overcome this limitation, we propose a novel approach, PASS, designed to stochastically substitute the original sample with another one according to certain probabilities, which is trained with a novel loss function soundly derived from information-theoretic objective defined for utility-preserving private attributes protection. The comprehensive evaluation of PASS on various datasets of different modalities, including facial images, human activity sensory signals, and voice recording datasets, substantiates PASS's effectiveness and generalizability.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Yv416IYTFp"
        ],
        "venue": [
          "/venue/Yv416IYTFp@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Yv416IYTFp"
        ],
        "detail": [
          "https://openreview.net/forum?id=Yv416IYTFp"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": null
      },
      "raw_excerpt": "PASS: Private Attributes Protection with Stochastic Data Substitution [PDF 1 ] [Copy] [Kimi ] [REL] Authors : Yizhuo Chen , Chun-Fu (Richard) Chen , Hsiang Hsu , Shaohan Hu , Tarek Abdelzaher The growing Machine Learning (ML) services require extensive collections of user data, which may inadvertently include people's private information irrelevant to the services. Various studies have been proposed to protect private attributes by removing them from the data while maintaining the utilities of the data for downstream tasks. Nevertheless, as we theoretically and empirically show in the paper, these methods reveal severe vulnerability because of a common weakness rooted in their adversarial training based strategies. To overcome this limitation, we propose a novel approach, PASS, designed to stochastically substitute the original sample with another one according to certain probabilities, which is trained with a novel loss function soundly derived from information-theoretic objective defined for utility-preserving private attributes protection. The comprehensive evaluation of PASS on various datasets of different modalities, including facial images, human activity sensory signals, and voice recording datasets, substantiates PASS's effectiveness and generalizability. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Zm2M92TZyO@OpenReview",
      "index": 123,
      "title": "Leveraging Diffusion Model as Pseudo-Anomalous Graph Generator for Graph-Level Anomaly Detection",
      "authors": [
        "Jinyu Cai",
        "Yunhe Zhang",
        "Fusheng Liu",
        "See-Kiong Ng"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "agdiff",
        "glad",
        "graph",
        "anomalous",
        "pseudo",
        "diffusion",
        "anomalies",
        "graphs",
        "generating",
        "normality"
      ],
      "summary": "A fundamental challenge in graph-level anomaly detection (GLAD) is the scarcity of anomalous graph data, as the training dataset typically contains only normal graphs or very few anomalies. This imbalance hinders the development of robust detection models. In this paper, we propose **A**nomalous **G**raph **Diff**usion (AGDiff), a framework that explores the potential of diffusion models in generating pseudo-anomalous graphs for GLAD. Unlike existing diffusion-based methods that focus on modeling data normality, AGDiff leverages the latent diffusion framework to incorporate subtle perturbations into graph representations, thereby generating pseudo-anomalous graphs that closely resemble normal ones. By jointly training a classifier to distinguish these generated graph anomalies from normal graphs, AGDiff learns more discriminative decision boundaries. The shift from solely modeling normality to explicitly generating and learning from pseudo graph anomalies enables AGDiff to effectively identify complex anomalous patterns that other approaches might overlook. Comprehensive experimental results demonstrate that the proposed AGDiff significantly outperforms several state-of-the-art GLAD baselines.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Zm2M92TZyO"
        ],
        "venue": [
          "/venue/Zm2M92TZyO@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Zm2M92TZyO"
        ],
        "detail": [
          "https://openreview.net/forum?id=Zm2M92TZyO"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "Leveraging Diffusion Model as Pseudo-Anomalous Graph Generator for Graph-Level Anomaly Detection [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : Jinyu Cai , Yunhe Zhang , Fusheng Liu , See-Kiong Ng A fundamental challenge in graph-level anomaly detection (GLAD) is the scarcity of anomalous graph data, as the training dataset typically contains only normal graphs or very few anomalies. This imbalance hinders the development of robust detection models. In this paper, we propose **A**nomalous **G**raph **Diff**usion (AGDiff), a framework that explores the potential of diffusion models in generating pseudo-anomalous graphs for GLAD. Unlike existing diffusion-based methods that focus on modeling data normality, AGDiff leverages the latent diffusion framework to incorporate subtle perturbations into graph representations, thereby generating pseudo-anomalous graphs that closely resemble normal ones. By jointly training a classifier to distinguish these generated graph anomalies from normal graphs, AGDiff learns more discriminative decision boundaries. The shift from solely modeling normality to explicitly generating and learning from pseudo graph anomalies enables AGDiff to effectively identify complex anomalous patterns that other approaches might overlook. Comprehensive experimental results demonstrate that the proposed AGDiff significantly outperforms several state-of-the-art GLAD baselines. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "ZrhGq664om@OpenReview",
      "index": 124,
      "title": "Neural Collapse Beyond the Unconstrained Features Model: Landscape, Dynamics, and Generalization in the Mean-Field Regime",
      "authors": [
        "Diyuan Wu",
        "Marco Mondelli"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "nc1",
        "loss",
        "landscape",
        "unconstrained",
        "gradient",
        "mean",
        "neural",
        "collapse",
        "layer",
        "occurrence"
      ],
      "summary": "Neural Collapse is a phenomenon where the last-layer representations of a well-trained neural network converge to a highly structured geometry. In this paper, we focus on its first (and most basic) property, known as NC1: the within-class variability vanishes. While prior theoretical studies establish the occurrence of NC1 via the data-agnostic unconstrained features model, our work adopts a data-specific perspective, analyzing NC1 in a three-layer neural network, with the first two layers operating in the mean-field regime and followed by a linear layer. In particular, we establish a fundamental connection between NC1 and the loss landscape: we prove that points with small empirical loss and gradient norm (thus, close to being stationary) approximately satisfy NC1, and the closeness to NC1 is controlled by the residual loss and gradient norm. We then show that (i) gradient flow on the mean squared error converges to NC1 solutions with small empirical loss, and (ii) for well-separated data distributions, both NC1 and vanishing test loss are achieved simultaneously. This aligns with the empirical observation that NC1 emerges during training while models attain near-zero test error. Overall, our results demonstrate that NC1 arises from gradient training due to the properties of the loss landscape, and they show the co-occurrence of NC1 and small test error for certain data distributions.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=ZrhGq664om"
        ],
        "venue": [
          "/venue/ZrhGq664om@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=ZrhGq664om"
        ],
        "detail": [
          "https://openreview.net/forum?id=ZrhGq664om"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Neural Collapse Beyond the Unconstrained Features Model: Landscape, Dynamics, and Generalization in the Mean-Field Regime [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Diyuan Wu , Marco Mondelli Neural Collapse is a phenomenon where the last-layer representations of a well-trained neural network converge to a highly structured geometry. In this paper, we focus on its first (and most basic) property, known as NC1: the within-class variability vanishes. While prior theoretical studies establish the occurrence of NC1 via the data-agnostic unconstrained features model, our work adopts a data-specific perspective, analyzing NC1 in a three-layer neural network, with the first two layers operating in the mean-field regime and followed by a linear layer. In particular, we establish a fundamental connection between NC1 and the loss landscape: we prove that points with small empirical loss and gradient norm (thus, close to being stationary) approximately satisfy NC1, and the closeness to NC1 is controlled by the residual loss and gradient norm. We then show that (i) gradient flow on the mean squared error converges to NC1 solutions with small empirical loss, and (ii) for well-separated data distributions, both NC1 and vanishing test loss are achieved simultaneously. This aligns with the empirical observation that NC1 emerges during training while models attain near-zero test error. Overall, our results demonstrate that NC1 arises from gradient training due to the properties of the loss landscape, and they show the co-occurrence of NC1 and small test error for certain data distributions. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "a6Cagkpmgz@OpenReview",
      "index": 125,
      "title": "Stochastic Smoothed Primal-Dual Algorithms for Nonconvex Optimization with Linear Inequality Constraints",
      "authors": [
        "Ruichuan Huang",
        "Jiawei Zhang",
        "Ahmet Alacaoglu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "moreau",
        "stochastic",
        "algorithms",
        "primal",
        "dual",
        "constraints",
        "envelope",
        "smoothed",
        "nonconvex",
        "inequality"
      ],
      "summary": "We propose smoothed primal-dual algorithms for solving stochastic nonconvex optimization problems with linear \\emph{inequality} constraints. Our algorithms are single-loop and only require a single (or two) samples of stochastic gradients at each iteration. A defining feature of our algorithm is that it is based on an inexact gradient descent framework for the Moreau envelope, where the gradient of the Moreau envelope is estimated using one step of a stochastic primal-dual (linearized) augmented Lagrangian algorithm. To handle inequality constraints and stochasticity, we combine the recently established global error bounds in constrained optimization with a Moreau envelope-based analysis of stochastic proximal algorithms. We establish the optimal (in their respective cases) O ( ε − 4 ) O ( ε − 4 ) and O ( ε − 3 ) O ( ε − 3 ) sample complexity guarantees for our algorithms and provide extensions to stochastic linear constraints. Unlike existing methods, iterations of our algorithms are free of subproblems, large batch sizes or increasing penalty parameters in their iterations and they use dual variable updates to ensure feasibility.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=a6Cagkpmgz"
        ],
        "venue": [
          "/venue/a6Cagkpmgz@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=a6Cagkpmgz"
        ],
        "detail": [
          "https://openreview.net/forum?id=a6Cagkpmgz"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "Stochastic Smoothed Primal-Dual Algorithms for Nonconvex Optimization with Linear Inequality Constraints [PDF 3 ] [Copy] [Kimi 1 ] [REL] Authors : Ruichuan Huang , Jiawei Zhang , Ahmet Alacaoglu We propose smoothed primal-dual algorithms for solving stochastic nonconvex optimization problems with linear \\emph{inequality} constraints. Our algorithms are single-loop and only require a single (or two) samples of stochastic gradients at each iteration. A defining feature of our algorithm is that it is based on an inexact gradient descent framework for the Moreau envelope, where the gradient of the Moreau envelope is estimated using one step of a stochastic primal-dual (linearized) augmented Lagrangian algorithm. To handle inequality constraints and stochasticity, we combine the recently established global error bounds in constrained optimization with a Moreau envelope-based analysis of stochastic proximal algorithms. We establish the optimal (in their respective cases) O ( ε − 4 ) O ( ε − 4 ) and O ( ε − 3 ) O ( ε − 3 ) sample complexity guarantees for our algorithms and provide extensions to stochastic linear constraints. Unlike existing methods, iterations of our algorithms are free of subproblems, large batch sizes or increasing penalty parameters in their iterations and they use dual variable updates to ensure feasibility. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "a7UM5c1CEa@OpenReview",
      "index": 126,
      "title": "Provable Benefits of Unsupervised Pre-training and Transfer Learning via Single-Index Models",
      "authors": [
        "Taj Jones-McCormick",
        "Aukosh Jagannath",
        "Subhabrata Sen"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "training",
        "pre",
        "transfer",
        "unsupervised",
        "sample",
        "complexity",
        "learning",
        "provable",
        "settings",
        "grants"
      ],
      "summary": "Unsupervised pre-training and transfer learning are commonly used techniques to initialize training algorithms for neural networks, particularly in settings with limited labeled data. In this paper, we study the effects of unsupervised pre-training and transfer learning on the sample complexity of high-dimensional supervised learning. Specifically, we consider the problem of training a single-layer neural network via online stochastic gradient descent. We establish that pre-training and transfer learning (under concept shift) reduce sample complexity by polynomial factors (in the dimension) under very general assumptions. We also uncover some surprising settings where pre-training grants exponential improvement over random initialization in terms of sample complexity.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=a7UM5c1CEa"
        ],
        "venue": [
          "/venue/a7UM5c1CEa@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=a7UM5c1CEa"
        ],
        "detail": [
          "https://openreview.net/forum?id=a7UM5c1CEa"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 2
      },
      "raw_excerpt": "Provable Benefits of Unsupervised Pre-training and Transfer Learning via Single-Index Models [PDF 1 ] [Copy] [Kimi 2 ] [REL] Authors : Taj Jones-McCormick , Aukosh Jagannath , Subhabrata Sen Unsupervised pre-training and transfer learning are commonly used techniques to initialize training algorithms for neural networks, particularly in settings with limited labeled data. In this paper, we study the effects of unsupervised pre-training and transfer learning on the sample complexity of high-dimensional supervised learning. Specifically, we consider the problem of training a single-layer neural network via online stochastic gradient descent. We establish that pre-training and transfer learning (under concept shift) reduce sample complexity by polynomial factors (in the dimension) under very general assumptions. We also uncover some surprising settings where pre-training grants exponential improvement over random initialization in terms of sample complexity. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "aFNq67ilos@OpenReview",
      "index": 127,
      "title": "Training Dynamics of In-Context Learning in Linear Attention",
      "authors": [
        "Yedi Zhang",
        "Aaditya Singh",
        "Peter Latham",
        "Andrew Saxe"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "training",
        "attention",
        "context",
        "descent",
        "dynamics",
        "linear",
        "icl",
        "merged",
        "query",
        "parametrization"
      ],
      "summary": "While attention-based models have demonstrated the remarkable ability of in-context learning (ICL), the theoretical understanding of how these models acquired this ability through gradient descent training is still preliminary. Towards answering this question, we study the gradient descent dynamics of multi-head linear self-attention trained for in-context linear regression. We examine two parametrizations of linear self-attention: one with the key and query weights merged as a single matrix (common in theoretical studies), and one with separate key and query matrices (closer to practical settings). For the merged parametrization, we show that the training dynamics has two fixed points and the loss trajectory exhibits a single, abrupt drop. We derive an analytical time-course solution for a certain class of datasets and initialization. For the separate parametrization, we show that the training dynamics has exponentially many fixed points and the loss exhibits saddle-to-saddle dynamics, which we reduce to scalar ordinary differential equations. During training, the model implements principal component regression in context with the number of principal components increasing over training time. Overall, we provide a theoretical description of how ICL abilities evolve during gradient descent training of linear attention, revealing abrupt acquisition or progressive improvements depending on how the key and query are parametrized.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=aFNq67ilos"
        ],
        "venue": [
          "/venue/aFNq67ilos@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=aFNq67ilos"
        ],
        "detail": [
          "https://openreview.net/forum?id=aFNq67ilos"
        ]
      },
      "scores": {
        "pdf": 6,
        "kimi": 3
      },
      "raw_excerpt": "Training Dynamics of In-Context Learning in Linear Attention [PDF 6 ] [Copy] [Kimi 3 ] [REL] Authors : Yedi Zhang , Aaditya Singh , Peter Latham , Andrew Saxe While attention-based models have demonstrated the remarkable ability of in-context learning (ICL), the theoretical understanding of how these models acquired this ability through gradient descent training is still preliminary. Towards answering this question, we study the gradient descent dynamics of multi-head linear self-attention trained for in-context linear regression. We examine two parametrizations of linear self-attention: one with the key and query weights merged as a single matrix (common in theoretical studies), and one with separate key and query matrices (closer to practical settings). For the merged parametrization, we show that the training dynamics has two fixed points and the loss trajectory exhibits a single, abrupt drop. We derive an analytical time-course solution for a certain class of datasets and initialization. For the separate parametrization, we show that the training dynamics has exponentially many fixed points and the loss exhibits saddle-to-saddle dynamics, which we reduce to scalar ordinary differential equations. During training, the model implements principal component regression in context with the number of principal components increasing over training time. Overall, we provide a theoretical description of how ICL abilities evolve during gradient descent training of linear attention, revealing abrupt acquisition or progressive improvements depending on how the key and query are parametrized. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "aJeLhLcsh0@OpenReview",
      "index": 128,
      "title": "Multi-Turn Code Generation Through Single-Step Rewards",
      "authors": [
        "Arnav Kumar Jain",
        "Gonzalo Gonzalez-Pumariega",
        "Wayne Chen",
        "Alexander Rush",
        "Wenting Zhao",
        "Sanjiban Choudhury"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "code",
        "turn",
        "rewards",
        "feedback",
        "generation",
        "execution",
        "multi",
        "step",
        "single",
        "recoverable"
      ],
      "summary": "We address the problem of code generation from multi-turn execution feedback. Existing methods either generate code without feedback or use complex, hierarchical reinforcement learning to optimize multi-turn rewards.We propose a simple yet scalable approach, μ μ CODE, that solves multi-turn code generation using only single-step rewards.Our key insight is that code generation is a one-step recoverable MDP, where the correct code can be recovered from any intermediate code state in a single turn. μ μ CODE iteratively trains both a generator to provide code solutions conditioned on multi-turn execution feedback and a verifier to score the newly generated code.Experimental evaluations show that our approach achieves significant improvements over state-of-the-art baselines. We provide analysis of the design choices of the reward models and policy, and show the efficacy of μ μ CODE at utilizing the execution feedback.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=aJeLhLcsh0"
        ],
        "venue": [
          "/venue/aJeLhLcsh0@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=aJeLhLcsh0"
        ],
        "detail": [
          "https://openreview.net/forum?id=aJeLhLcsh0"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 5
      },
      "raw_excerpt": "Multi-Turn Code Generation Through Single-Step Rewards [PDF 3 ] [Copy] [Kimi 5 ] [REL] Authors : Arnav Kumar Jain , Gonzalo Gonzalez-Pumariega , Wayne Chen , Alexander Rush , Wenting Zhao , Sanjiban Choudhury We address the problem of code generation from multi-turn execution feedback. Existing methods either generate code without feedback or use complex, hierarchical reinforcement learning to optimize multi-turn rewards.We propose a simple yet scalable approach, μ μ CODE, that solves multi-turn code generation using only single-step rewards.Our key insight is that code generation is a one-step recoverable MDP, where the correct code can be recovered from any intermediate code state in a single turn. μ μ CODE iteratively trains both a generator to provide code solutions conditioned on multi-turn execution feedback and a verifier to score the newly generated code.Experimental evaluations show that our approach achieves significant improvements over state-of-the-art baselines. We provide analysis of the design choices of the reward models and policy, and show the efficacy of μ μ CODE at utilizing the execution feedback. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "aQUUUAcAw1@OpenReview",
      "index": 129,
      "title": "Sparse-pivot: Dynamic correlation clustering for node insertions",
      "authors": [
        "Mina Dalirrooyfard",
        "Konstantin Makarychev",
        "Slobodan Mitrovic"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "addad",
        "cohen",
        "algorithm",
        "clustering",
        "maggiori",
        "node",
        "pivot",
        "insertions",
        "added",
        "lattanzi"
      ],
      "summary": "We present a new Correlation Clustering algorithm for a dynamic setting where nodes are added one at a time. In this model, proposed by Cohen-Addad, Lattanzi, Maggiori, and Parotsidis (ICML 2024), the algorithm uses database queries to access the input graph and updates the clustering as each new node is added.Our algorithm has the amortized update time of log O ( 1 ) ( n ) log O ( 1 ) ⁡ ( n ) . Its approximation factor is 20 + ε 20 + ε , which is a substantial improvement over the approximation factor of the algorithm by Cohen-Addad et al. We complement our theoretical findings by empirically evaluating the approximation guarantee of our algorithm. The results show that it outperforms the algorithm by Cohen-Addad et al.~in practice.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=aQUUUAcAw1"
        ],
        "venue": [
          "/venue/aQUUUAcAw1@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=aQUUUAcAw1"
        ],
        "detail": [
          "https://openreview.net/forum?id=aQUUUAcAw1"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Sparse-pivot: Dynamic correlation clustering for node insertions [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Mina Dalirrooyfard , Konstantin Makarychev , Slobodan Mitrovic We present a new Correlation Clustering algorithm for a dynamic setting where nodes are added one at a time. In this model, proposed by Cohen-Addad, Lattanzi, Maggiori, and Parotsidis (ICML 2024), the algorithm uses database queries to access the input graph and updates the clustering as each new node is added.Our algorithm has the amortized update time of log O ( 1 ) ( n ) log O ( 1 ) ⁡ ( n ) . Its approximation factor is 20 + ε 20 + ε , which is a substantial improvement over the approximation factor of the algorithm by Cohen-Addad et al. We complement our theoretical findings by empirically evaluating the approximation guarantee of our algorithm. The results show that it outperforms the algorithm by Cohen-Addad et al.~in practice. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "afpc1MFMYU@OpenReview",
      "index": 130,
      "title": "Non-stationary Diffusion For Probabilistic Time Series Forecasting",
      "authors": [
        "Weiwei Ye",
        "Zhuopeng Xu",
        "Ning Gui"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "nsdiff",
        "lsnm",
        "diffusion",
        "uncertainty",
        "anm",
        "stationary",
        "probabilistic",
        "noise",
        "forecasting",
        "denoising"
      ],
      "summary": "Due to the dynamics of underlying physics and external influences, the uncertainty of time series often varies over time. However, existing Denoising Diffusion Probabilistic Models (DDPMs) often fail to capture this non-stationary nature, constrained by their constant variance assumption from the additive noise model (ANM). In this paper, we innovatively utilize the Location-Scale Noise Model (LSNM) to relax the fixed uncertainty assumption of ANM. A diffusion-based probabilistic forecasting framework, termed Non-stationary Diffusion (NsDiff), is designed based on LSNM that is capable of modeling the changing pattern of uncertainty. Specifically, NsDiff combines a denoising diffusion-based conditional generative model with a pre-trained conditional mean and variance estimator, enabling adaptive endpoint distribution modeling. Furthermore, we propose an uncertainty-aware noise schedule, which dynamically adjusts the noise levels to accurately reflect the data uncertainty at each step and integrates the time-varying variances into the diffusion process. Extensive experiments conducted on nine real-world and synthetic datasets demonstrate the superior performance of NsDiff compared to existing approaches. Code is available at https://github.com/wwy155/NsDiff.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=afpc1MFMYU"
        ],
        "venue": [
          "/venue/afpc1MFMYU@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=afpc1MFMYU"
        ],
        "detail": [
          "https://openreview.net/forum?id=afpc1MFMYU"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 2
      },
      "raw_excerpt": "Non-stationary Diffusion For Probabilistic Time Series Forecasting [PDF 5 ] [Copy] [Kimi 2 ] [REL] Authors : Weiwei Ye , Zhuopeng Xu , Ning Gui Due to the dynamics of underlying physics and external influences, the uncertainty of time series often varies over time. However, existing Denoising Diffusion Probabilistic Models (DDPMs) often fail to capture this non-stationary nature, constrained by their constant variance assumption from the additive noise model (ANM). In this paper, we innovatively utilize the Location-Scale Noise Model (LSNM) to relax the fixed uncertainty assumption of ANM. A diffusion-based probabilistic forecasting framework, termed Non-stationary Diffusion (NsDiff), is designed based on LSNM that is capable of modeling the changing pattern of uncertainty. Specifically, NsDiff combines a denoising diffusion-based conditional generative model with a pre-trained conditional mean and variance estimator, enabling adaptive endpoint distribution modeling. Furthermore, we propose an uncertainty-aware noise schedule, which dynamically adjusts the noise levels to accurately reflect the data uncertainty at each step and integrates the time-varying variances into the diffusion process. Extensive experiments conducted on nine real-world and synthetic datasets demonstrate the superior performance of NsDiff compared to existing approaches. Code is available at https://github.com/wwy155/NsDiff. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "bLcXkIasck@OpenReview",
      "index": 131,
      "title": "Language Models May Verbatim Complete Text They Were Not Explicitly Trained On",
      "authors": [
        "Ken Ziyu Liu",
        "Christopher A. Choquette Choo",
        "Matthew Jagielski",
        "Peter Kairouz",
        "Sanmi Koyejo",
        "Percy Liang",
        "Nicolas Papernot"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "membership",
        "text",
        "gram",
        "duplicates",
        "verbatim",
        "completed",
        "llm",
        "completion",
        "gamed",
        "definitions"
      ],
      "summary": "An important question today is whether a given text was used to train a large language model (LLM). A completion test is often employed: check if the LLM completes a sufficiently complex text. This, however, requires a ground-truth definition of membership; most commonly, it is defined as a member based on the n-gram overlap between the target text and any text in the dataset. In this work, we demonstrate that this n-gram based membership definition can be effectively gamed. We study scenarios where sequences are non-members for a given n and we find that completion tests still succeed. We find many natural cases of this phenomenon by retraining LLMs from scratch after removing all training samples that were completed; these cases include exact duplicates, near-duplicates, and even short overlaps. They showcase that it is difficult to find a single viable choice of n for membership definitions. Using these insights, we design adversarial datasets that can cause a given target sequence to be completed without containing it, for any reasonable choice of n. Our findings highlight the inadequacy of n-gram membership, suggesting membership definitions fail to account for auxiliary information available to the training algorithm.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=bLcXkIasck"
        ],
        "venue": [
          "/venue/bLcXkIasck@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=bLcXkIasck"
        ],
        "detail": [
          "https://openreview.net/forum?id=bLcXkIasck"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Language Models May Verbatim Complete Text They Were Not Explicitly Trained On [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Ken Ziyu Liu , Christopher A. Choquette Choo , Matthew Jagielski , Peter Kairouz , Sanmi Koyejo , Percy Liang , Nicolas Papernot An important question today is whether a given text was used to train a large language model (LLM). A completion test is often employed: check if the LLM completes a sufficiently complex text. This, however, requires a ground-truth definition of membership; most commonly, it is defined as a member based on the n-gram overlap between the target text and any text in the dataset. In this work, we demonstrate that this n-gram based membership definition can be effectively gamed. We study scenarios where sequences are non-members for a given n and we find that completion tests still succeed. We find many natural cases of this phenomenon by retraining LLMs from scratch after removing all training samples that were completed; these cases include exact duplicates, near-duplicates, and even short overlaps. They showcase that it is difficult to find a single viable choice of n for membership definitions. Using these insights, we design adversarial datasets that can cause a given target sequence to be completed without containing it, for any reasonable choice of n. Our findings highlight the inadequacy of n-gram membership, suggesting membership definitions fail to account for auxiliary information available to the training algorithm. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "beeNgQEfe2@OpenReview",
      "index": 132,
      "title": "Scaling Test-Time Compute Without Verification or RL is Suboptimal",
      "authors": [
        "Amrith Setlur",
        "Nived Rajaraman",
        "Sergey Levine",
        "Aviral Kumar"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "traces",
        "test",
        "compute",
        "scaling",
        "verifier",
        "verification",
        "distilling",
        "search",
        "rewards",
        "budget"
      ],
      "summary": "Despite substantial advances in scaling test-time compute, an ongoing debate in the community is how it should be scaled up to enable continued and efficient improvements with scaling. There are largely two approaches: (i) distilling successful search or thinking traces; and (ii), using verification (e.g., 0/1 outcome rewards, or verifiers) to guide reinforcement learning (RL) and search algorithms. In this paper, we prove that finetuning LLMs with verifier-based (VB) methods based on RL or search is far superior to verifier-free (VF) approaches based on distilling or cloning search traces, given a fixed amount of compute/data budget. Further, we show that as we scale test-time compute (measured as the output token length) and training data, suboptimality of VF methods scales poorly compared to VB when the base pre-trained LLM presents a heterogeneous distribution over correct solution traces (e.g., different lengths, styles, etc.) and admits a non-sharp distribution over rewards on traces sampled from it. We formalize this condition using anti-concentration [Erdős 1945], implying a stronger result that VB methods scale better asymptotically, with the performance gap between VB and VF widening as test-time budget grows.We corroborate our theory empirically on didactic and math reasoning problems with 3/8/32B-sized pre-trained LLMs, where we find verification is crucial for scaling test-time compute.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=beeNgQEfe2"
        ],
        "venue": [
          "/venue/beeNgQEfe2@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=beeNgQEfe2"
        ],
        "detail": [
          "https://openreview.net/forum?id=beeNgQEfe2"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 4
      },
      "raw_excerpt": "Scaling Test-Time Compute Without Verification or RL is Suboptimal [PDF 4 ] [Copy] [Kimi 4 ] [REL] Authors : Amrith Setlur , Nived Rajaraman , Sergey Levine , Aviral Kumar Despite substantial advances in scaling test-time compute, an ongoing debate in the community is how it should be scaled up to enable continued and efficient improvements with scaling. There are largely two approaches: (i) distilling successful search or thinking traces; and (ii), using verification (e.g., 0/1 outcome rewards, or verifiers) to guide reinforcement learning (RL) and search algorithms. In this paper, we prove that finetuning LLMs with verifier-based (VB) methods based on RL or search is far superior to verifier-free (VF) approaches based on distilling or cloning search traces, given a fixed amount of compute/data budget. Further, we show that as we scale test-time compute (measured as the output token length) and training data, suboptimality of VF methods scales poorly compared to VB when the base pre-trained LLM presents a heterogeneous distribution over correct solution traces (e.g., different lengths, styles, etc.) and admits a non-sharp distribution over rewards on traces sampled from it. We formalize this condition using anti-concentration [Erdős 1945], implying a stronger result that VB methods scale better asymptotically, with the performance gap between VB and VF widening as test-time budget grows.We corroborate our theory empirically on didactic and math reasoning problems with 3/8/32B-sized pre-trained LLMs, where we find verification is crucial for scaling test-time compute. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "bkauyuzBN4@OpenReview",
      "index": 133,
      "title": "Privacy Amplification by Structured Subsampling for Deep Differentially Private Time Series Forecasting",
      "authors": [
        "Jan Schuchardt",
        "Mina Dalirrooyfard",
        "Jed Guzelkabaagac",
        "Anderson Schneider",
        "Yuriy Nevmyvaka",
        "Stephan Günnemann"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "privacy",
        "forecasting",
        "subsampling",
        "amplification",
        "structured",
        "private",
        "series",
        "differentially",
        "hospital",
        "batches"
      ],
      "summary": "Many forms of sensitive data, such as web traffic, mobility data, or hospital occupancy, are inherently sequential. The standard method for training machine learning models while ensuring privacy for units of sensitive information, such as individual hospital visits, is differentially private stochastic gradient descent (DP-SGD). However, we observe in this work that the formal guarantees of DP-SGD are incompatible with time series specific tasks like forecasting, since they rely on the *privacy amplification* attained by training on small, unstructured batches sampled from an unstructured dataset. In contrast, batches for forecasting are generated by (1) sampling sequentially structured time series from a dataset, (2) sampling contiguous subsequences from these series, and (3) partitioning them into context and ground-truth forecast windows. We theoretically analyze the privacy amplification attained by this *structured subsampling* to enable the training of forecasting models with sound and tight event- and user-level privacy guarantees. Towards more private models, we additionally prove how data augmentation amplifies privacy in self-supervised training of sequence models. Our empirical evaluation demonstrates that amplification by structured subsampling enables the training of forecasting models with strong formal privacy guarantees.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=bkauyuzBN4"
        ],
        "venue": [
          "/venue/bkauyuzBN4@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=bkauyuzBN4"
        ],
        "detail": [
          "https://openreview.net/forum?id=bkauyuzBN4"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "Privacy Amplification by Structured Subsampling for Deep Differentially Private Time Series Forecasting [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : Jan Schuchardt , Mina Dalirrooyfard , Jed Guzelkabaagac , Anderson Schneider , Yuriy Nevmyvaka , Stephan Günnemann Many forms of sensitive data, such as web traffic, mobility data, or hospital occupancy, are inherently sequential. The standard method for training machine learning models while ensuring privacy for units of sensitive information, such as individual hospital visits, is differentially private stochastic gradient descent (DP-SGD). However, we observe in this work that the formal guarantees of DP-SGD are incompatible with time series specific tasks like forecasting, since they rely on the *privacy amplification* attained by training on small, unstructured batches sampled from an unstructured dataset. In contrast, batches for forecasting are generated by (1) sampling sequentially structured time series from a dataset, (2) sampling contiguous subsequences from these series, and (3) partitioning them into context and ground-truth forecast windows. We theoretically analyze the privacy amplification attained by this *structured subsampling* to enable the training of forecasting models with sound and tight event- and user-level privacy guarantees. Towards more private models, we additionally prove how data augmentation amplifies privacy in self-supervised training of sequence models. Our empirical evaluation demonstrates that amplification by structured subsampling enables the training of forecasting models with strong formal privacy guarantees. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "c0dhw1du33@OpenReview",
      "index": 134,
      "title": "Video Prediction Policy: A Generalist Robot Policy with Predictive Visual Representations",
      "authors": [
        "Yucheng Hu",
        "Yanjiang Guo",
        "Pengchao Wang",
        "Xiaoyu Chen",
        "Yen-Jen Wang",
        "Jianke Zhang",
        "Koushil Sreenath",
        "Chaochao Lu",
        "Jianyu Chen"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "vdms",
        "video",
        "policy",
        "generalist",
        "vpp",
        "representations",
        "robot",
        "future",
        "prediction",
        "visual"
      ],
      "summary": "Visual representations play a crucial role in developing generalist robotic policies. Previous vision encoders, typically pre-trained with single-image reconstruction or two-image contrastive learning, tend to capture static information, often neglecting the dynamic aspects vital for embodied tasks. Recently, video diffusion models (VDMs) demonstrate the ability to predict future frames and showcase a strong understanding of physical world. We hypothesize that VDMs inherently produce visual representations that encompass both current static information and predicted future dynamics, thereby providing valuable guidance for robot action learning. Based on this hypothesis, we propose the Video Prediction Policy (VPP), which learns implicit inverse dynamics model conditioned on predicted future representations inside VDMs. To predict more precise future, we fine-tune pre-trained video foundation model on robot datasets along with internet human manipulation data.In experiments, VPP achieves a 18.6\\% relative improvement on the Calvin ABC-D generalization benchmark compared to the previous state-of-the-art, and demonstrates a 31.6\\% increase in success rates for complex real-world dexterous manipulation tasks. For your convenience, videos can be found at https://video-prediction-policy.github.io/",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=c0dhw1du33"
        ],
        "venue": [
          "/venue/c0dhw1du33@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=c0dhw1du33"
        ],
        "detail": [
          "https://openreview.net/forum?id=c0dhw1du33"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 3
      },
      "raw_excerpt": "Video Prediction Policy: A Generalist Robot Policy with Predictive Visual Representations [PDF 4 ] [Copy] [Kimi 3 ] [REL] Authors : Yucheng Hu , Yanjiang Guo , Pengchao Wang , Xiaoyu Chen , Yen-Jen Wang , Jianke Zhang , Koushil Sreenath , Chaochao Lu , Jianyu Chen Visual representations play a crucial role in developing generalist robotic policies. Previous vision encoders, typically pre-trained with single-image reconstruction or two-image contrastive learning, tend to capture static information, often neglecting the dynamic aspects vital for embodied tasks. Recently, video diffusion models (VDMs) demonstrate the ability to predict future frames and showcase a strong understanding of physical world. We hypothesize that VDMs inherently produce visual representations that encompass both current static information and predicted future dynamics, thereby providing valuable guidance for robot action learning. Based on this hypothesis, we propose the Video Prediction Policy (VPP), which learns implicit inverse dynamics model conditioned on predicted future representations inside VDMs. To predict more precise future, we fine-tune pre-trained video foundation model on robot datasets along with internet human manipulation data.In experiments, VPP achieves a 18.6\\% relative improvement on the Calvin ABC-D generalization benchmark compared to the previous state-of-the-art, and demonstrates a 31.6\\% increase in success rates for complex real-world dexterous manipulation tasks. For your convenience, videos can be found at https://video-prediction-policy.github.io/ Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "cKaUC1PeJA@OpenReview",
      "index": 135,
      "title": "Efficient and Separate Authentication Image Steganography Network",
      "authors": [
        "Junchao Zhou",
        "Yao Lu",
        "Jie Wen",
        "Guangming Lu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "authentication",
        "steganography",
        "hiding",
        "image",
        "secret",
        "recipients",
        "separate",
        "images",
        "multiple",
        "cover"
      ],
      "summary": "Image steganography hides multiple images for multiple recipients into a single cover image. All secret images are usually revealed without authentication, which reduces security among multiple recipients. It is elegant to design an authentication mechanism for isolated reception. We explore such mechanism through sufficient experiments, and uncover that additional authentication information will affect the distribution of hidden information and occupy more hiding space of the cover image. This severely decreases effectiveness and efficiency in large-capacity hiding. To overcome such a challenge, we first prove the authentication feasibility within image steganography. Then, this paper proposes an image steganography network collaborating with separate authentication and efficient scheme. Specifically, multiple pairs of lock-key are generated during hiding and revealing. Unlike traditional methods, our method has two stages to make appropriate distribution adaptation between locks and secret images, simultaneously extracting more reasonable primary information from secret images, which can release hiding space of the cover image to some extent. Furthermore, due to separate authentication, fused information can be hidden in parallel with a single network rather than traditional serial hiding with multiple networks, which can largely decrease the model size. Extensive experiments demonstrate that the proposed method achieves more secure, effective, and efficient image steganography. Code is available at https://github.com/Revive624/Authentication-Image-Steganography.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=cKaUC1PeJA"
        ],
        "venue": [
          "/venue/cKaUC1PeJA@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=cKaUC1PeJA"
        ],
        "detail": [
          "https://openreview.net/forum?id=cKaUC1PeJA"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 2
      },
      "raw_excerpt": "Efficient and Separate Authentication Image Steganography Network [PDF 4 ] [Copy] [Kimi 2 ] [REL] Authors : Junchao Zhou , Yao Lu , Jie Wen , Guangming Lu Image steganography hides multiple images for multiple recipients into a single cover image. All secret images are usually revealed without authentication, which reduces security among multiple recipients. It is elegant to design an authentication mechanism for isolated reception. We explore such mechanism through sufficient experiments, and uncover that additional authentication information will affect the distribution of hidden information and occupy more hiding space of the cover image. This severely decreases effectiveness and efficiency in large-capacity hiding. To overcome such a challenge, we first prove the authentication feasibility within image steganography. Then, this paper proposes an image steganography network collaborating with separate authentication and efficient scheme. Specifically, multiple pairs of lock-key are generated during hiding and revealing. Unlike traditional methods, our method has two stages to make appropriate distribution adaptation between locks and secret images, simultaneously extracting more reasonable primary information from secret images, which can release hiding space of the cover image to some extent. Furthermore, due to separate authentication, fused information can be hidden in parallel with a single network rather than traditional serial hiding with multiple networks, which can largely decrease the model size. Extensive experiments demonstrate that the proposed method achieves more secure, effective, and efficient image steganography. Code is available at https://github.com/Revive624/Authentication-Image-Steganography. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "clJIQ4TKR0@OpenReview",
      "index": 136,
      "title": "Investigating Non-Transitivity in LLM-as-a-Judge",
      "authors": [
        "Yi Xu",
        "Laura Ruis",
        "Tim Rocktäschel",
        "Robert Kirk"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "tournaments",
        "rankings",
        "robin",
        "llm",
        "transitivity",
        "round",
        "transitive",
        "judge",
        "preferences",
        "rightarrow"
      ],
      "summary": "Automatic evaluation methods based on large language models (LLMs) are emerging as the standard tool for assessing the instruction-following abilities of LLM-based agents. The most common method in this paradigm, pairwise comparisons with a baseline model, critically depends on the assumption of transitive preferences. However, the validity of this assumption remains largely unexplored. In this study, we investigate the presence of non-transitivity within the AlpacaEval framework and analyze its effects on model rankings. We find that LLM judges exhibit non-transitive preferences, leading to rankings that are sensitive to the choice of the baseline model. To mitigate this issue, we show that round-robin tournaments combined with Bradley-Terry models of preference can produce more reliable rankings. Notably, our method increases both the Spearman correlation and the Kendall correlation with Chatbot Arena (95.0\\% → → 96.4\\% and 82.1\\% → → 86.3\\% respectively). To address the computational cost of round-robin tournaments, we propose Swiss-Wise Iterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to capture the benefits of round-robin tournaments while maintaining computational efficiency.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=clJIQ4TKR0"
        ],
        "venue": [
          "/venue/clJIQ4TKR0@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=clJIQ4TKR0"
        ],
        "detail": [
          "https://openreview.net/forum?id=clJIQ4TKR0"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Investigating Non-Transitivity in LLM-as-a-Judge [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Yi Xu , Laura Ruis , Tim Rocktäschel , Robert Kirk Automatic evaluation methods based on large language models (LLMs) are emerging as the standard tool for assessing the instruction-following abilities of LLM-based agents. The most common method in this paradigm, pairwise comparisons with a baseline model, critically depends on the assumption of transitive preferences. However, the validity of this assumption remains largely unexplored. In this study, we investigate the presence of non-transitivity within the AlpacaEval framework and analyze its effects on model rankings. We find that LLM judges exhibit non-transitive preferences, leading to rankings that are sensitive to the choice of the baseline model. To mitigate this issue, we show that round-robin tournaments combined with Bradley-Terry models of preference can produce more reliable rankings. Notably, our method increases both the Spearman correlation and the Kendall correlation with Chatbot Arena (95.0\\% → → 96.4\\% and 82.1\\% → → 86.3\\% respectively). To address the computational cost of round-robin tournaments, we propose Swiss-Wise Iterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to capture the benefits of round-robin tournaments while maintaining computational efficiency. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "dhRXGWJ027@OpenReview",
      "index": 137,
      "title": "Discovering Symbolic Cognitive Models from Human and Animal Behavior",
      "authors": [
        "Pablo Samuel Castro",
        "Nenad Tomasev",
        "Ankit Anand",
        "Navodita Sharma",
        "Rishika Mohanta",
        "Aparna Dev",
        "Kuba Perlin",
        "Siddhant Jain",
        "Kyle Levin",
        "Noemi Elteto",
        "Will Dabney",
        "Alexander Novikov",
        "Glenn Turner",
        "Maria Eckstein",
        "Nathaniel Daw",
        "Kevin Miller",
        "Kimberly Stachenfeld"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "cognitive",
        "animal",
        "symbolic",
        "human",
        "hypotheses",
        "romera",
        "funsearch",
        "cognition",
        "paredes",
        "effort"
      ],
      "summary": "Symbolic models play a key role in cognitive science, expressing computationally precise hypotheses about how the brain implements a cognitive process. Identifying an appropriate model typically requires a great deal of effort and ingenuity on the part of a human scientist.Here, we adapt FunSearch (Romera-Paredes et al. 2024), a recently developed tool that uses Large Language Models (LLMs) in an evolutionary algorithm, to automatically discover symbolic cognitive models that accurately capture human and animal behavior.We consider datasets from three species performing a classic reward-learning task that has been the focus of substantial modeling effort, and find that the discovered programs outperform state-of-the-art cognitive models for each.The discovered programs can readily be interpreted as hypotheses about human and animal cognition, instantiating interpretable symbolic learning and decision-making algorithms. Broadly, these results demonstrate the viability of using LLM-powered program synthesis to propose novel scientific hypotheses regarding mechanisms of human and animal cognition.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=dhRXGWJ027"
        ],
        "venue": [
          "/venue/dhRXGWJ027@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=dhRXGWJ027"
        ],
        "detail": [
          "https://openreview.net/forum?id=dhRXGWJ027"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "Discovering Symbolic Cognitive Models from Human and Animal Behavior [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : Pablo Samuel Castro , Nenad Tomasev , Ankit Anand , Navodita Sharma , Rishika Mohanta , Aparna Dev , Kuba Perlin , Siddhant Jain , Kyle Levin , Noemi Elteto , Will Dabney , Alexander Novikov , Glenn Turner , Maria Eckstein , Nathaniel Daw , Kevin Miller , Kimberly Stachenfeld Symbolic models play a key role in cognitive science, expressing computationally precise hypotheses about how the brain implements a cognitive process. Identifying an appropriate model typically requires a great deal of effort and ingenuity on the part of a human scientist.Here, we adapt FunSearch (Romera-Paredes et al. 2024), a recently developed tool that uses Large Language Models (LLMs) in an evolutionary algorithm, to automatically discover symbolic cognitive models that accurately capture human and animal behavior.We consider datasets from three species performing a classic reward-learning task that has been the focus of substantial modeling effort, and find that the discovered programs outperform state-of-the-art cognitive models for each.The discovered programs can readily be interpreted as hypotheses about human and animal cognition, instantiating interpretable symbolic learning and decision-making algorithms. Broadly, these results demonstrate the viability of using LLM-powered program synthesis to propose novel scientific hypotheses regarding mechanisms of human and animal cognition. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "e46xNZhwl8@OpenReview",
      "index": 138,
      "title": "Learning with Exact Invariances in Polynomial Time",
      "authors": [
        "Ashkan Soleymani",
        "Behrooz Tahmasebi",
        "Stefanie Jegelka",
        "Patrick Jaillet"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "invariances",
        "exact",
        "kernel",
        "polynomial",
        "averaging",
        "regression",
        "diaz",
        "canonicalization",
        "2025",
        "time"
      ],
      "summary": "We study the statistical-computational trade-offs for learning with exact invariances (or symmetries) using kernel regression. Traditional methods, such as data augmentation, group averaging, canonicalization, and frame-averaging, either fail to provide a polynomial-time solution or are not applicable in the kernel setting. However, with oracle access to the geometric properties of the input space, we propose a polynomial-time algorithm that learns a classifier with \\emph{exact} invariances. Moreover, our approach achieves the same excess population risk (or generalization error) as the original kernel regression problem. To the best of our knowledge, this is the first polynomial-time algorithm to achieve exact (as opposed to approximate) invariances in this setting, partially addressing a question posed by Diaz (2025) regarding the avoidance of prohibitively large and computationally intensive group averaging methods in kernel regression with exact invariances. Our proof leverages tools from differential geometry, spectral theory, and optimization. A key result in our development is a new reformulation of the problem of learning under invariances as optimizing an infinite number of linearly constrained convex quadratic programs, which may be of independent interest.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=e46xNZhwl8"
        ],
        "venue": [
          "/venue/e46xNZhwl8@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=e46xNZhwl8"
        ],
        "detail": [
          "https://openreview.net/forum?id=e46xNZhwl8"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Learning with Exact Invariances in Polynomial Time [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Ashkan Soleymani , Behrooz Tahmasebi , Stefanie Jegelka , Patrick Jaillet We study the statistical-computational trade-offs for learning with exact invariances (or symmetries) using kernel regression. Traditional methods, such as data augmentation, group averaging, canonicalization, and frame-averaging, either fail to provide a polynomial-time solution or are not applicable in the kernel setting. However, with oracle access to the geometric properties of the input space, we propose a polynomial-time algorithm that learns a classifier with \\emph{exact} invariances. Moreover, our approach achieves the same excess population risk (or generalization error) as the original kernel regression problem. To the best of our knowledge, this is the first polynomial-time algorithm to achieve exact (as opposed to approximate) invariances in this setting, partially addressing a question posed by Diaz (2025) regarding the avoidance of prohibitively large and computationally intensive group averaging methods in kernel regression with exact invariances. Our proof leverages tools from differential geometry, spectral theory, and optimization. A key result in our development is a new reformulation of the problem of learning under invariances as optimizing an infinite number of linearly constrained convex quadratic programs, which may be of independent interest. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "evb9dNxCN5@OpenReview",
      "index": 139,
      "title": "Where is the Truth? The Risk of Getting Confounded in a Continual World",
      "authors": [
        "Florian Peter Busch",
        "Roshni Ramanna Kamath",
        "Rupert Mitchell",
        "Wolfgang Stammer",
        "Kristian Kersting",
        "Martin Mundt"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "continual",
        "confounders",
        "confounded",
        "dataset",
        "confounding",
        "spurious",
        "concon",
        "getting",
        "easily",
        "clevr"
      ],
      "summary": "A dataset is confounded if it is most easily solved via a spurious correlation which fails to generalize to new data. In this work, we show that, in a continual learning setting where confounders may vary in time across tasks, the challenge of mitigating the effect of confounders far exceeds the standard forgetting problem normally considered. In particular, we provide a formal description of such continual confounders and identify that, in general, spurious correlations are easily ignored when training for all tasks jointly, but it is harder to avoid confounding when they are considered sequentially. These descriptions serve as a basis for constructing a novel CLEVR-based continually confounded dataset, which we term the ConCon dataset. Our evaluations demonstrate that standard continual learning methods fail to ignore the dataset's confounders. Overall, our work highlights the challenges of confounding factors, particularly in continual learning settings, and demonstrates the need for developing continual learning methods to robustly tackle these.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=evb9dNxCN5"
        ],
        "venue": [
          "/venue/evb9dNxCN5@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=evb9dNxCN5"
        ],
        "detail": [
          "https://openreview.net/forum?id=evb9dNxCN5"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 2
      },
      "raw_excerpt": "Where is the Truth? The Risk of Getting Confounded in a Continual World [PDF 1 ] [Copy] [Kimi 2 ] [REL] Authors : Florian Peter Busch , Roshni Ramanna Kamath , Rupert Mitchell , Wolfgang Stammer , Kristian Kersting , Martin Mundt A dataset is confounded if it is most easily solved via a spurious correlation which fails to generalize to new data. In this work, we show that, in a continual learning setting where confounders may vary in time across tasks, the challenge of mitigating the effect of confounders far exceeds the standard forgetting problem normally considered. In particular, we provide a formal description of such continual confounders and identify that, in general, spurious correlations are easily ignored when training for all tasks jointly, but it is harder to avoid confounding when they are considered sequentially. These descriptions serve as a basis for constructing a novel CLEVR-based continually confounded dataset, which we term the ConCon dataset. Our evaluations demonstrate that standard continual learning methods fail to ignore the dataset's confounders. Overall, our work highlights the challenges of confounding factors, particularly in continual learning settings, and demonstrates the need for developing continual learning methods to robustly tackle these. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "fPOkujQBVb@OpenReview",
      "index": 140,
      "title": "Sharp Generalization for Nonparametric Regression by Over-Parameterized Neural Networks: A Distribution-Free Analysis in Spherical Covariate",
      "authors": [
        "Yingzhen Yang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "ntk",
        "covariate",
        "regression",
        "nonparametric",
        "neural",
        "spherical",
        "parameterized",
        "network",
        "distributional",
        "trained"
      ],
      "summary": "Sharp generalization bound for neural networks trained by gradient descent (GD) is of central interest in statistical learning theory and deep learning. In this paper, we consider nonparametric regressionby an over-parameterized two-layer NN trained by GD. We show that, if the neural network is trained by GD with early stopping, then the trained network renders a sharp rate of the nonparametric regression risk of O ( ϵ 2 n ) O ( ϵ n 2 ) , which is the same rate as that for the classical kernel regression trained by GD with early stopping, where ϵ n ϵ n is the critical population rate of the Neural Tangent Kernel (NTK) associated with the network and n n is the size of the training data. It is remarked that our result does not require distributional assumptions on the covariate as long as the covariate lies on the unit sphere, in a strong contrast with many existing results which rely on specific distributions such as the spherical uniform data distribution or distributions satisfying certain restrictive conditions.As a special case of our general result, when the eigenvalues of the associated NTKdecay at a rate of λ j ≍ j − d d − 1 λ j ≍ j − d d − 1 for j ≥ 1 j ≥ 1 which happens under certain distributional assumption such as the training features follow the spherical uniform distribution, we immediately obtain the minimax optimal rate of O ( n − d 2 d − 1 ) O ( n − d 2 d − 1 ) , which is the major results of several existing works in this direction. The neural network width in our general result is lower bounded by a function of only d d and ϵ n ϵ n , and such width does not depend on the minimum eigenvalue of the empirical NTK matrix whose lower bound usually requires additional assumptions on the training data.Our results are built upon two significant technical results which are of independent interest. First, uniform convergence to the NTK is established during the training process by GD, so that we can have a nice decomposition of the neural network function at any step of the GD into a function in the ReproducingKernel Hilbert Space associated with the NTK and an error function with a small L ∞ L ∞ -norm. Second, local Rademacher complexity is employedto tightly bound the Rademacher complexity of the function class comprising all the possible neural network functions obtained by GD. Our resultformally fills the gap between training a classical kernel regression model and training an over-parameterized but finite-width neural network by GD for nonparametric regression without distributional assumptions about the spherical covariate.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=fPOkujQBVb"
        ],
        "venue": [
          "/venue/fPOkujQBVb@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=fPOkujQBVb"
        ],
        "detail": [
          "https://openreview.net/forum?id=fPOkujQBVb"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "Sharp Generalization for Nonparametric Regression by Over-Parameterized Neural Networks: A Distribution-Free Analysis in Spherical Covariate [PDF 3 ] [Copy] [Kimi 1 ] [REL] Author : Yingzhen Yang Sharp generalization bound for neural networks trained by gradient descent (GD) is of central interest in statistical learning theory and deep learning. In this paper, we consider nonparametric regressionby an over-parameterized two-layer NN trained by GD. We show that, if the neural network is trained by GD with early stopping, then the trained network renders a sharp rate of the nonparametric regression risk of O ( ϵ 2 n ) O ( ϵ n 2 ) , which is the same rate as that for the classical kernel regression trained by GD with early stopping, where ϵ n ϵ n is the critical population rate of the Neural Tangent Kernel (NTK) associated with the network and n n is the size of the training data. It is remarked that our result does not require distributional assumptions on the covariate as long as the covariate lies on the unit sphere, in a strong contrast with many existing results which rely on specific distributions such as the spherical uniform data distribution or distributions satisfying certain restrictive conditions.As a special case of our general result, when the eigenvalues of the associated NTKdecay at a rate of λ j ≍ j − d d − 1 λ j ≍ j − d d − 1 for j ≥ 1 j ≥ 1 which happens under certain distributional assumption such as the training features follow the spherical uniform distribution, we immediately obtain the minimax optimal rate of O ( n − d 2 d − 1 ) O ( n − d 2 d − 1 ) , which is the major results of several existing works in this direction. The neural network width in our general result is lower bounded by a function of only d d and ϵ n ϵ n , and such width does not depend on the minimum eigenvalue of the empirical NTK matrix whose lower bound usually requires additional assumptions on the training data.Our results are built upon two significant technical results which are of independent interest. First, uniform convergence to the NTK is established during the training process by GD, so that we can have a nice decomposition of the neural network function at any step of the GD into a function in the ReproducingKernel Hilbert Space associated with the NTK and an error function with a small L ∞ L ∞ -norm. Second, local Rademacher complexity is employedto tightly bound the Rademacher complexity of the function class comprising all the possible neural network functions obtained by GD. Our resultformally fills the gap between training a classical kernel regression model and training an over-parameterized but finite-width neural network by GD for nonparametric regression without distributional assumptions about the spherical covariate. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "gcgzQSKR7y@OpenReview",
      "index": 141,
      "title": "Stronger Neyman Regret Guarantees for Adaptive Experimental Design",
      "authors": [
        "Georgy Noarov",
        "Riccardo Fogliato",
        "Martin A Bertran",
        "Aaron Roth"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "neyman",
        "regret",
        "adaptive",
        "designs",
        "widetilde",
        "clipogd",
        "multigroup",
        "design",
        "guarantees",
        "anytime"
      ],
      "summary": "We study the design of adaptive, sequential experiments for unbiased average treatment effect (ATE) estimation in the design-based potential outcomes setting. Our goal is to develop adaptive designs offering *sublinear Neyman regret*, meaning their efficiency must approach that of the hindsight-optimal nonadaptive design.Recent work [Dai et al, 2023] introduced ClipOGD, the first method achieving O ˜ ( T − − √ ) O ~ ( T ) expected Neyman regret under mild conditions. In this work, we propose adaptive designs with substantially stronger Neyman regret guarantees. In particular, we modify ClipOGD to obtain anytime O ˜ ( log T ) O ~ ( log ⁡ T ) Neyman regret under natural boundedness assumptions. Further, in the setting where experimental units have pre-treatment covariates, we introduce and study a class of contextual ``multigroup'' Neyman regret guarantees: Given a set of possibly overlapping groups based on the covariates, the adaptive design outperforms each group's best non-adaptive designs. In particular, we develop a contextual adaptive design with O ˜ ( T − − √ ) O ~ ( T ) anytime multigroup Neyman regret. We empirically validate the proposed designs through an array of experiments.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=gcgzQSKR7y"
        ],
        "venue": [
          "/venue/gcgzQSKR7y@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=gcgzQSKR7y"
        ],
        "detail": [
          "https://openreview.net/forum?id=gcgzQSKR7y"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Stronger Neyman Regret Guarantees for Adaptive Experimental Design [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Georgy Noarov , Riccardo Fogliato , Martin A Bertran , Aaron Roth We study the design of adaptive, sequential experiments for unbiased average treatment effect (ATE) estimation in the design-based potential outcomes setting. Our goal is to develop adaptive designs offering *sublinear Neyman regret*, meaning their efficiency must approach that of the hindsight-optimal nonadaptive design.Recent work [Dai et al, 2023] introduced ClipOGD, the first method achieving O ˜ ( T − − √ ) O ~ ( T ) expected Neyman regret under mild conditions. In this work, we propose adaptive designs with substantially stronger Neyman regret guarantees. In particular, we modify ClipOGD to obtain anytime O ˜ ( log T ) O ~ ( log ⁡ T ) Neyman regret under natural boundedness assumptions. Further, in the setting where experimental units have pre-treatment covariates, we introduce and study a class of contextual ``multigroup'' Neyman regret guarantees: Given a set of possibly overlapping groups based on the covariates, the adaptive design outperforms each group's best non-adaptive designs. In particular, we develop a contextual adaptive design with O ˜ ( T − − √ ) O ~ ( T ) anytime multigroup Neyman regret. We empirically validate the proposed designs through an array of experiments. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "glLqTK9En3@OpenReview",
      "index": 142,
      "title": "Functional Alignment Can Mislead: Examining Model Stitching",
      "authors": [
        "Damian Smith",
        "Harvey Mannering",
        "Antonia Marcu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "stitching",
        "stitched",
        "functionally",
        "mislead",
        "aligned",
        "different",
        "functional",
        "capture",
        "similarity",
        "examining"
      ],
      "summary": "A common belief in the representational comparison literature is that if two representations can be functionally aligned, they must capture similar information. In this paper we focus on model stitching and show that models can be functionally aligned, but represent very different information. Firstly, we show that discriminative models with very different biases can be stitched together. We then show that models trained to solve entirely different tasks on different data modalities, and even clustered random noise, can be successfully stitched into MNIST or ImageNet-trained models. We end with a discussion of the wider impact of our results on the community's current beliefs. Overall, our paper draws attention to the need to correctly interpret the results of such functional similarity measures and highlights the need for approaches that capture informational similarity.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=glLqTK9En3"
        ],
        "venue": [
          "/venue/glLqTK9En3@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=glLqTK9En3"
        ],
        "detail": [
          "https://openreview.net/forum?id=glLqTK9En3"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "Functional Alignment Can Mislead: Examining Model Stitching [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : Damian Smith , Harvey Mannering , Antonia Marcu A common belief in the representational comparison literature is that if two representations can be functionally aligned, they must capture similar information. In this paper we focus on model stitching and show that models can be functionally aligned, but represent very different information. Firstly, we show that discriminative models with very different biases can be stitched together. We then show that models trained to solve entirely different tasks on different data modalities, and even clustered random noise, can be successfully stitched into MNIST or ImageNet-trained models. We end with a discussion of the wider impact of our results on the community's current beliefs. Overall, our paper draws attention to the need to correctly interpret the results of such functional similarity measures and highlights the need for approaches that capture informational similarity. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "h2oNQOzbc5@OpenReview",
      "index": 143,
      "title": "ActionPiece: Contextually Tokenizing Action Sequences for Generative Recommendation",
      "authors": [
        "Yupeng Hou",
        "Jianmo Ni",
        "Zhankui He",
        "Noveen Sachdeva",
        "Wang-Cheng Kang",
        "Ed Chi",
        "Julian McAuley",
        "Derek Cheng"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "actionpiece",
        "action",
        "tokenizing",
        "sequences",
        "recommendation",
        "contextually",
        "generative",
        "tokens",
        "context",
        "sets"
      ],
      "summary": "Generative recommendation (GR) is an emerging paradigm where user actions are tokenized into discrete token patterns and autoregressively generated as predictions. However, existing GR models tokenize each action independently, assigning the same fixed tokens to identical actions across all sequences without considering contextual relationships. This lack of context-awareness can lead to suboptimal performance, as the same action may hold different meanings depending on its surrounding context. To address this issue, we propose ActionPiece to explicitly incorporate context when tokenizing action sequences. In ActionPiece, each action is represented as a *set* of item features. Given the action sequence corpora, we construct the vocabulary by merging feature patterns as new tokens, based on their co-occurrence frequency both within individual sets and across adjacent sets. Considering the unordered nature of feature sets, we further introduce set permutation regularization, which produces multiple segmentations of action sequences with the same semantics. Our code is available at: https://github.com/google-deepmind/action_piece.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=h2oNQOzbc5"
        ],
        "venue": [
          "/venue/h2oNQOzbc5@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=h2oNQOzbc5"
        ],
        "detail": [
          "https://openreview.net/forum?id=h2oNQOzbc5"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "ActionPiece: Contextually Tokenizing Action Sequences for Generative Recommendation [PDF 3 ] [Copy] [Kimi 1 ] [REL] Authors : Yupeng Hou , Jianmo Ni , Zhankui He , Noveen Sachdeva , Wang-Cheng Kang , Ed Chi , Julian McAuley , Derek Cheng Generative recommendation (GR) is an emerging paradigm where user actions are tokenized into discrete token patterns and autoregressively generated as predictions. However, existing GR models tokenize each action independently, assigning the same fixed tokens to identical actions across all sequences without considering contextual relationships. This lack of context-awareness can lead to suboptimal performance, as the same action may hold different meanings depending on its surrounding context. To address this issue, we propose ActionPiece to explicitly incorporate context when tokenizing action sequences. In ActionPiece, each action is represented as a *set* of item features. Given the action sequence corpora, we construct the vocabulary by merging feature patterns as new tokens, based on their co-occurrence frequency both within individual sets and across adjacent sets. Considering the unordered nature of feature sets, we further introduce set permutation regularization, which produces multiple segmentations of action sequences with the same semantics. Our code is available at: https://github.com/google-deepmind/action_piece. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "hRQyqtcjVv@OpenReview",
      "index": 144,
      "title": "The Jailbreak Tax: How Useful are Your Jailbreak Outputs?",
      "authors": [
        "Kristina Nikolić",
        "Luze Sun",
        "Jie Zhang",
        "Florian Tramer"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "jailbreak",
        "jailbreaks",
        "tax",
        "outputs",
        "instructions",
        "guardrails",
        "bomb",
        "utility",
        "refuse",
        "bypass"
      ],
      "summary": "Jailbreak attacks bypass the guardrails of large language models to produce harmful outputs.In this paper, we ask whether the model outputs produced by existing jailbreaks are actually *useful*. For example, when jailbreaking a model to give instructions for building a bomb, does the jailbreak yield good instructions?Since the utility of most unsafe answers (e.g., bomb instructions) is hard to evaluate rigorously, we build new jailbreak evaluation sets with known ground truth answers, by aligning models to refuse questions related to benign and easy-to-evaluate topics (e.g., biology or math).Our evaluation of eight representative jailbreaks across five utility benchmarks reveals a consistent drop in model utility in jailbroken responses, which we term the *jailbreak tax*. For example, while all jailbreaks we tested bypass guardrails in models aligned to refuse to answer math, this comes at the expense of a drop of up to 92% in accuracy.Overall, our work proposes jailbreak utility as a new important metric in AI safety, and introduces benchmarks to evaluate existing and future jailbreaks. We make the benchmark available at https://github.com/ethz-spylab/jailbreak-tax",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=hRQyqtcjVv"
        ],
        "venue": [
          "/venue/hRQyqtcjVv@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=hRQyqtcjVv"
        ],
        "detail": [
          "https://openreview.net/forum?id=hRQyqtcjVv"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 3
      },
      "raw_excerpt": "The Jailbreak Tax: How Useful are Your Jailbreak Outputs? [PDF 4 ] [Copy] [Kimi 3 ] [REL] Authors : Kristina Nikolić , Luze Sun , Jie Zhang , Florian Tramer Jailbreak attacks bypass the guardrails of large language models to produce harmful outputs.In this paper, we ask whether the model outputs produced by existing jailbreaks are actually *useful*. For example, when jailbreaking a model to give instructions for building a bomb, does the jailbreak yield good instructions?Since the utility of most unsafe answers (e.g., bomb instructions) is hard to evaluate rigorously, we build new jailbreak evaluation sets with known ground truth answers, by aligning models to refuse questions related to benign and easy-to-evaluate topics (e.g., biology or math).Our evaluation of eight representative jailbreaks across five utility benchmarks reveals a consistent drop in model utility in jailbroken responses, which we term the *jailbreak tax*. For example, while all jailbreaks we tested bypass guardrails in models aligned to refuse to answer math, this comes at the expense of a drop of up to 92% in accuracy.Overall, our work proposes jailbreak utility as a new important metric in AI safety, and introduces benchmarks to evaluate existing and future jailbreaks. We make the benchmark available at https://github.com/ethz-spylab/jailbreak-tax Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "hS2Ed5XYRq@OpenReview",
      "index": 145,
      "title": "MapEval: A Map-Based Evaluation of Geo-Spatial Reasoning in Foundation Models",
      "authors": [
        "Mahir Labib Dihan",
        "Tanvir Hassan",
        "Md Tanvir Parvez",
        "Hasebul Hasan",
        "Almash Alam",
        "Muhammad Aamir Cheema",
        "Mohammed Eunus Ali",
        "Md Rizwan Parvez"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "mapeval",
        "foundation",
        "reasoning",
        "models",
        "map",
        "geospatial",
        "evaluation",
        "spatial",
        "api",
        "geo"
      ],
      "summary": "Recent advancements in foundation models have improved autonomous tool usage and reasoning, but their capabilities in map-based reasoning remain underexplored. To address this, we introduce MapEval, a benchmark designed to assess foundation models across three distinct tasks—textual, API-based, and visual reasoning—through 700 multiple-choice questions spanning 180 cities and 54 countries, covering spatial relationships, navigation, travel planning, and real-world map interactions. Unlike prior benchmarks that focus on simple location queries, MapEval requires models to handle long-context reasoning, API interactions and visual map analysis, making it the most comprehensive evaluation framework for geospatial AI. On evaluation of 30 foundation models, including Claude-3.5-Sonnet, GPT-4o, Gemini-1.5-Pro, none surpasses 67% accuracy, with open-source models performing significantly worse and all models lagging over 20% behind human performance. These results expose critical gaps in spatial inference, as models struggle with distances, directions, route planning, and place-specific reasoning, highlighting the need for better geospatial AI to bridge the gap between foundation models and real-world navigation.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=hS2Ed5XYRq"
        ],
        "venue": [
          "/venue/hS2Ed5XYRq@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=hS2Ed5XYRq"
        ],
        "detail": [
          "https://openreview.net/forum?id=hS2Ed5XYRq"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "MapEval: A Map-Based Evaluation of Geo-Spatial Reasoning in Foundation Models [PDF 3 ] [Copy] [Kimi 1 ] [REL] Authors : Mahir Labib Dihan , Tanvir Hassan , Md Tanvir Parvez , Hasebul Hasan , Almash Alam , Muhammad Aamir Cheema , Mohammed Eunus Ali , Md Rizwan Parvez Recent advancements in foundation models have improved autonomous tool usage and reasoning, but their capabilities in map-based reasoning remain underexplored. To address this, we introduce MapEval, a benchmark designed to assess foundation models across three distinct tasks—textual, API-based, and visual reasoning—through 700 multiple-choice questions spanning 180 cities and 54 countries, covering spatial relationships, navigation, travel planning, and real-world map interactions. Unlike prior benchmarks that focus on simple location queries, MapEval requires models to handle long-context reasoning, API interactions and visual map analysis, making it the most comprehensive evaluation framework for geospatial AI. On evaluation of 30 foundation models, including Claude-3.5-Sonnet, GPT-4o, Gemini-1.5-Pro, none surpasses 67% accuracy, with open-source models performing significantly worse and all models lagging over 20% behind human performance. These results expose critical gaps in spatial inference, as models struggle with distances, directions, route planning, and place-specific reasoning, highlighting the need for better geospatial AI to bridge the gap between foundation models and real-world navigation. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "hrdLhNDAzp@OpenReview",
      "index": 146,
      "title": "MCU: An Evaluation Framework for Open-Ended Game Agents",
      "authors": [
        "Xinyue Zheng",
        "Haowei Lin",
        "Kaichen He",
        "Zihao Wang",
        "Qiang Fu",
        "Haobo Fu",
        "Zilong Zheng",
        "Yitao Liang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "mcu",
        "ended",
        "open",
        "agents",
        "minecraft",
        "evaluation",
        "tasks",
        "craftjarvis",
        "game",
        "framework"
      ],
      "summary": "Developing AI agents capable of interacting with open-world environments to solve diverse tasks is a compelling challenge. However, evaluating such open-ended agents remains difficult, with current benchmarks facing scalability limitations. To address this, we introduce \\textit{Minecraft Universe} (MCU), a comprehensive evaluation framework set within the open-world video game Minecraft. MCU incorporates three key components: (1) an expanding collection of 3,452 composable atomic tasks that encompasses 11 major categories and 41 subcategories of challenges; (2) a task composition mechanism capable of generating infinite diverse tasks with varying difficulty; and (3) a general evaluation framework that achieves 91.5\\% alignment with human ratings for open-ended task assessment. Empirical results reveal that even state-of-the-art foundation agents struggle with the increasing diversity and complexity of tasks. These findings highlight the necessity of MCU as a robust benchmark to drive progress in AI agent development within open-ended environments. Our evaluation code and scripts are available at https://github.com/CraftJarvis/MCU.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=hrdLhNDAzp"
        ],
        "venue": [
          "/venue/hrdLhNDAzp@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=hrdLhNDAzp"
        ],
        "detail": [
          "https://openreview.net/forum?id=hrdLhNDAzp"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 2
      },
      "raw_excerpt": "MCU: An Evaluation Framework for Open-Ended Game Agents [PDF 1 ] [Copy] [Kimi 2 ] [REL] Authors : Xinyue Zheng , Haowei Lin , Kaichen He , Zihao Wang , Qiang Fu , Haobo Fu , Zilong Zheng , Yitao Liang Developing AI agents capable of interacting with open-world environments to solve diverse tasks is a compelling challenge. However, evaluating such open-ended agents remains difficult, with current benchmarks facing scalability limitations. To address this, we introduce \\textit{Minecraft Universe} (MCU), a comprehensive evaluation framework set within the open-world video game Minecraft. MCU incorporates three key components: (1) an expanding collection of 3,452 composable atomic tasks that encompasses 11 major categories and 41 subcategories of challenges; (2) a task composition mechanism capable of generating infinite diverse tasks with varying difficulty; and (3) a general evaluation framework that achieves 91.5\\% alignment with human ratings for open-ended task assessment. Empirical results reveal that even state-of-the-art foundation agents struggle with the increasing diversity and complexity of tasks. These findings highlight the necessity of MCU as a robust benchmark to drive progress in AI agent development within open-ended environments. Our evaluation code and scripts are available at https://github.com/CraftJarvis/MCU. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "hwTKGdM4TK@OpenReview",
      "index": 147,
      "title": "Instance Correlation Graph-based Naive Bayes",
      "authors": [
        "Chengyuan Li",
        "Liangxiao Jiang",
        "Wenjun Zhang",
        "Liangjun Yu",
        "Huan Zhang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "naive",
        "bayes",
        "attributes",
        "icgnb",
        "gnb",
        "icg",
        "graph",
        "instance",
        "correlation",
        "vgae"
      ],
      "summary": "Due to its simplicity, effectiveness and robustness, naive Bayes (NB) has continued to be one of the top 10 data mining algorithms. To improve its performance, a large number of improved algorithms have been proposed in the last few decades. However, in addition to Gaussian naive Bayes (GNB), there is little work on numerical attributes. At the same time, none of them takes into account the correlations among instances. To fill this gap, we propose a novel algorithm called instance correlation graph-based naive Bayes (ICGNB). Specifically, it first uses original attributes to construct an instance correlation graph (ICG) to represent the correlations among instances. Then, it employs a variational graph auto-encoder (VGAE) to generate new attributes from the constructed ICG and uses them to augment original attributes.Finally, it weights each augmented attribute to alleviate the attribute redundancy and builds GNB on the weighted attributes. The experimental results on tens of datasets show that ICGNB significantly outperforms its deserved competitors.Our codes and datasets are available at https://github.com/jiangliangxiao/ICGNB.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=hwTKGdM4TK"
        ],
        "venue": [
          "/venue/hwTKGdM4TK@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=hwTKGdM4TK"
        ],
        "detail": [
          "https://openreview.net/forum?id=hwTKGdM4TK"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Instance Correlation Graph-based Naive Bayes [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Chengyuan Li , Liangxiao Jiang , Wenjun Zhang , Liangjun Yu , Huan Zhang Due to its simplicity, effectiveness and robustness, naive Bayes (NB) has continued to be one of the top 10 data mining algorithms. To improve its performance, a large number of improved algorithms have been proposed in the last few decades. However, in addition to Gaussian naive Bayes (GNB), there is little work on numerical attributes. At the same time, none of them takes into account the correlations among instances. To fill this gap, we propose a novel algorithm called instance correlation graph-based naive Bayes (ICGNB). Specifically, it first uses original attributes to construct an instance correlation graph (ICG) to represent the correlations among instances. Then, it employs a variational graph auto-encoder (VGAE) to generate new attributes from the constructed ICG and uses them to augment original attributes.Finally, it weights each augmented attribute to alleviate the attribute redundancy and builds GNB on the weighted attributes. The experimental results on tens of datasets show that ICGNB significantly outperforms its deserved competitors.Our codes and datasets are available at https://github.com/jiangliangxiao/ICGNB. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "iBpkzB5LEr@OpenReview",
      "index": 148,
      "title": "Primal-Dual Neural Algorithmic Reasoning",
      "authors": [
        "Yu He",
        "Ellen Vitercik"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "primal",
        "nar",
        "reasoning",
        "algorithms",
        "dual",
        "algorithmic",
        "neural",
        "classical",
        "approximation",
        "simulates"
      ],
      "summary": "Neural Algorithmic Reasoning (NAR) trains neural networks to simulate classical algorithms, enabling structured and interpretable reasoning over complex data. While prior research has predominantly focused on learning exact algorithms for polynomial-time-solvable problems, extending NAR to harder problems remains an open challenge. In this work, we introduce a general NAR framework grounded in the primal-dual paradigm, a classical method for designing efficient approximation algorithms. By leveraging a bipartite representation between primal and dual variables, we establish an alignment between primal-dual algorithms and Graph Neural Networks. Furthermore, we incorporate optimal solutions from small instances to greatly enhance the model’s reasoning capabilities. Our empirical results demonstrate that our model not only simulates but also outperforms approximation algorithms for multiple tasks, exhibiting robust generalization to larger and out-of-distribution graphs. Moreover, we highlight the framework’s practical utility by integrating it with commercial solvers and applying it to real-world datasets.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=iBpkzB5LEr"
        ],
        "venue": [
          "/venue/iBpkzB5LEr@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=iBpkzB5LEr"
        ],
        "detail": [
          "https://openreview.net/forum?id=iBpkzB5LEr"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Primal-Dual Neural Algorithmic Reasoning [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Yu He , Ellen Vitercik Neural Algorithmic Reasoning (NAR) trains neural networks to simulate classical algorithms, enabling structured and interpretable reasoning over complex data. While prior research has predominantly focused on learning exact algorithms for polynomial-time-solvable problems, extending NAR to harder problems remains an open challenge. In this work, we introduce a general NAR framework grounded in the primal-dual paradigm, a classical method for designing efficient approximation algorithms. By leveraging a bipartite representation between primal and dual variables, we establish an alignment between primal-dual algorithms and Graph Neural Networks. Furthermore, we incorporate optimal solutions from small instances to greatly enhance the model’s reasoning capabilities. Our empirical results demonstrate that our model not only simulates but also outperforms approximation algorithms for multiple tasks, exhibiting robust generalization to larger and out-of-distribution graphs. Moreover, we highlight the framework’s practical utility by integrating it with commercial solvers and applying it to real-world datasets. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "iFOXz5H2gB@OpenReview",
      "index": 149,
      "title": "Automatically Identify and Rectify: Robust Deep Contrastive Multi-view Clustering in Noisy Scenarios",
      "authors": [
        "xihong yang",
        "Siwei Wang",
        "Fangdi Wang",
        "Jiaqi Jin",
        "Suyuan Liu",
        "Yue Liu",
        "En Zhu",
        "Xinwang Liu",
        "Yueming Jin"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "airmvc",
        "noisy",
        "identification",
        "clustering",
        "rectification",
        "contrastive",
        "view",
        "scenarios",
        "xihongyang1999",
        "multi"
      ],
      "summary": "Leveraging the powerful representation learning capabilities, deep multi-view clustering methods have demonstrated reliable performance by effectively integrating multi-source information from diverse views in recent years. Most existing methods rely on the assumption of clean views. However, noise is pervasive in real-world scenarios, leading to a significant degradation in performance. To tackle this problem, we propose a novel multi-view clustering framework for the automatic identification and rectification of noisy data, termed AIRMVC. Specifically, we reformulate noisy identification as an anomaly identification problem using GMM. We then design a hybrid rectification strategy to mitigate the adverse effects of noisy data based on the identification results. Furthermore, we introduce a noise-robust contrastive mechanism to generate reliable representations. Additionally, we provide a theoretical proof demonstrating that these representations can discard noisy information, thereby improving the performance of downstream tasks. Extensive experiments on six benchmark datasets demonstrate that AIRMVC outperforms state-of-the-art algorithms in terms of robustness in noisy scenarios. The code of AIRMVC are available at https://github.com/xihongyang1999/AIRMVC on Github.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=iFOXz5H2gB"
        ],
        "venue": [
          "/venue/iFOXz5H2gB@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=iFOXz5H2gB"
        ],
        "detail": [
          "https://openreview.net/forum?id=iFOXz5H2gB"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Automatically Identify and Rectify: Robust Deep Contrastive Multi-view Clustering in Noisy Scenarios [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : xihong yang , Siwei Wang , Fangdi Wang , Jiaqi Jin , Suyuan Liu , Yue Liu , En Zhu , Xinwang Liu , Yueming Jin Leveraging the powerful representation learning capabilities, deep multi-view clustering methods have demonstrated reliable performance by effectively integrating multi-source information from diverse views in recent years. Most existing methods rely on the assumption of clean views. However, noise is pervasive in real-world scenarios, leading to a significant degradation in performance. To tackle this problem, we propose a novel multi-view clustering framework for the automatic identification and rectification of noisy data, termed AIRMVC. Specifically, we reformulate noisy identification as an anomaly identification problem using GMM. We then design a hybrid rectification strategy to mitigate the adverse effects of noisy data based on the identification results. Furthermore, we introduce a noise-robust contrastive mechanism to generate reliable representations. Additionally, we provide a theoretical proof demonstrating that these representations can discard noisy information, thereby improving the performance of downstream tasks. Extensive experiments on six benchmark datasets demonstrate that AIRMVC outperforms state-of-the-art algorithms in terms of robustness in noisy scenarios. The code of AIRMVC are available at https://github.com/xihongyang1999/AIRMVC on Github. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "jEcQP3lGlq@OpenReview",
      "index": 150,
      "title": "Elucidating the Design Space of Multimodal Protein Language Models",
      "authors": [
        "Cheng-Yen Hsieh",
        "Xinyou Wang",
        "Daiheng Zhang",
        "Dongyu Xue",
        "Fei YE",
        "Shujian Huang",
        "Zaixiang Zheng",
        "Quanquan Gu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "plms",
        "multimodal",
        "dplm",
        "protein",
        "token",
        "design",
        "folding",
        "650m",
        "elucidating",
        "structural"
      ],
      "summary": "Multimodal protein language models (PLMs) integrate sequence and token-based structural information, serving as a powerful foundation for protein modeling, generation, and design. However, the reliance on tokenizing 3D structures into discrete tokens causes substantial loss of fidelity about fine-grained structural details and correlations. In this paper, we systematically elucidate the design space of multimodal PLMs to overcome their limitations. We identify tokenization loss and inaccurate structure token predictions by the PLMs as major bottlenecks.To address these, our proposed design space covers improved generative modeling, structure-aware architectures and representation learning, and data exploration. Our advancements approach finer-grained supervision, demonstrating that token-based multimodal PLMs can achieve robust structural modeling.The effective design methods dramatically improve the structure generation diversity, and notably, folding abilities of our 650M model by reducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B baselines and on par with the specialized folding models.Project page and code: https://bytedance.github.io/dplm/dplm-2.1.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=jEcQP3lGlq"
        ],
        "venue": [
          "/venue/jEcQP3lGlq@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=jEcQP3lGlq"
        ],
        "detail": [
          "https://openreview.net/forum?id=jEcQP3lGlq"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 2
      },
      "raw_excerpt": "Elucidating the Design Space of Multimodal Protein Language Models [PDF 5 ] [Copy] [Kimi 2 ] [REL] Authors : Cheng-Yen Hsieh , Xinyou Wang , Daiheng Zhang , Dongyu Xue , Fei YE , Shujian Huang , Zaixiang Zheng , Quanquan Gu Multimodal protein language models (PLMs) integrate sequence and token-based structural information, serving as a powerful foundation for protein modeling, generation, and design. However, the reliance on tokenizing 3D structures into discrete tokens causes substantial loss of fidelity about fine-grained structural details and correlations. In this paper, we systematically elucidate the design space of multimodal PLMs to overcome their limitations. We identify tokenization loss and inaccurate structure token predictions by the PLMs as major bottlenecks.To address these, our proposed design space covers improved generative modeling, structure-aware architectures and representation learning, and data exploration. Our advancements approach finer-grained supervision, demonstrating that token-based multimodal PLMs can achieve robust structural modeling.The effective design methods dramatically improve the structure generation diversity, and notably, folding abilities of our 650M model by reducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B baselines and on par with the specialized folding models.Project page and code: https://bytedance.github.io/dplm/dplm-2.1. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "jJRkkPr474@OpenReview",
      "index": 151,
      "title": "Geometric Hyena Networks for Large-scale Equivariant Learning",
      "authors": [
        "Artem Moskalev",
        "Mangal Prakash",
        "Junjie Xu",
        "Tianyu Cui",
        "Rui Liao",
        "Tommaso Mansi"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "hyena",
        "equivariant",
        "geometric",
        "equivariance",
        "context",
        "global",
        "quadratic",
        "convolutional",
        "30k",
        "sacrifice"
      ],
      "summary": "Processing global geometric context while preserving equivariance is crucial when modeling biological, chemical, and physical systems. Yet, this is challenging due to the computational demands of equivariance and global context at scale. Standard methods such as equivariant self-attention suffer from quadratic complexity, while local methods such as distance-based message passing sacrifice global information. Inspired by the recent success of state-space and long-convolutional models, we introduce Geometric Hyena, the first equivariant long-convolutional model for geometric systems. Geometric Hyena captures global geometric context at sub-quadratic complexity while maintaining equivariance to rotations and translations. Evaluated on all-atom property prediction of large RNA molecules and full protein molecular dynamics, Geometric Hyena outperforms existing equivariant models while requiring significantly less memory and compute that equivariant self-attention. Notably, our model processes the geometric context of 30 k 30 k tokens 20 × 20 × faster than the equivariant transformer and allows 72 × 72 × longer context within the same budget.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=jJRkkPr474"
        ],
        "venue": [
          "/venue/jJRkkPr474@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=jJRkkPr474"
        ],
        "detail": [
          "https://openreview.net/forum?id=jJRkkPr474"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Geometric Hyena Networks for Large-scale Equivariant Learning [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Artem Moskalev , Mangal Prakash , Junjie Xu , Tianyu Cui , Rui Liao , Tommaso Mansi Processing global geometric context while preserving equivariance is crucial when modeling biological, chemical, and physical systems. Yet, this is challenging due to the computational demands of equivariance and global context at scale. Standard methods such as equivariant self-attention suffer from quadratic complexity, while local methods such as distance-based message passing sacrifice global information. Inspired by the recent success of state-space and long-convolutional models, we introduce Geometric Hyena, the first equivariant long-convolutional model for geometric systems. Geometric Hyena captures global geometric context at sub-quadratic complexity while maintaining equivariance to rotations and translations. Evaluated on all-atom property prediction of large RNA molecules and full protein molecular dynamics, Geometric Hyena outperforms existing equivariant models while requiring significantly less memory and compute that equivariant self-attention. Notably, our model processes the geometric context of 30 k 30 k tokens 20 × 20 × faster than the equivariant transformer and allows 72 × 72 × longer context within the same budget. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "jnPHZqcUdn@OpenReview",
      "index": 152,
      "title": "scSSL-Bench: Benchmarking Self-Supervised Learning for Single-Cell Data",
      "authors": [
        "Olga Ovcharenko",
        "Florian Barkmann",
        "Philip Toma",
        "Imant Daunhawer",
        "Julia Vogt",
        "Sebastian Schelter",
        "Valentina Boeva"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "cell",
        "ssl",
        "scssl",
        "bench",
        "single",
        "scgpt",
        "modal",
        "scvi",
        "data",
        "batch"
      ],
      "summary": "Self-supervised learning (SSL) has proven to be a powerful approach for extracting biologically meaningful representations from single-cell data. To advance our understanding of SSL methods applied to single-cell data, we present scSSL-Bench, a comprehensive benchmark that evaluates nineteen SSL methods. Our evaluation spans nine datasets and focuses on three common downstream tasks: batch correction, cell type annotation, and missing modality prediction. Furthermore, we systematically assess various data augmentation strategies. Our analysis reveals task-specific trade-offs: the specialized single-cell frameworks, scVI, CLAIRE, and the finetuned scGPT excel at uni-modal batch correction, while generic SSL methods, such as VICReg and SimCLR, demonstrate superior performance in cell typing and multi-modal data integration. Random masking emerges as the most effective augmentation technique across all tasks, surpassing domain-specific augmentations. Notably, our results indicate the need for a specialized single-cell multi-modal data integration framework. scSSL-Bench provides a standardized evaluation platform and concrete recommendations for applying SSL to single-cell analysis, advancing the convergence of deep learning and single-cell genomics.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=jnPHZqcUdn"
        ],
        "venue": [
          "/venue/jnPHZqcUdn@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=jnPHZqcUdn"
        ],
        "detail": [
          "https://openreview.net/forum?id=jnPHZqcUdn"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 4
      },
      "raw_excerpt": "scSSL-Bench: Benchmarking Self-Supervised Learning for Single-Cell Data [PDF 3 ] [Copy] [Kimi 4 ] [REL] Authors : Olga Ovcharenko , Florian Barkmann , Philip Toma , Imant Daunhawer , Julia Vogt , Sebastian Schelter , Valentina Boeva Self-supervised learning (SSL) has proven to be a powerful approach for extracting biologically meaningful representations from single-cell data. To advance our understanding of SSL methods applied to single-cell data, we present scSSL-Bench, a comprehensive benchmark that evaluates nineteen SSL methods. Our evaluation spans nine datasets and focuses on three common downstream tasks: batch correction, cell type annotation, and missing modality prediction. Furthermore, we systematically assess various data augmentation strategies. Our analysis reveals task-specific trade-offs: the specialized single-cell frameworks, scVI, CLAIRE, and the finetuned scGPT excel at uni-modal batch correction, while generic SSL methods, such as VICReg and SimCLR, demonstrate superior performance in cell typing and multi-modal data integration. Random masking emerges as the most effective augmentation technique across all tasks, surpassing domain-specific augmentations. Notably, our results indicate the need for a specialized single-cell multi-modal data integration framework. scSSL-Bench provides a standardized evaluation platform and concrete recommendations for applying SSL to single-cell analysis, advancing the convergence of deep learning and single-cell genomics. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "js3gePctLu@OpenReview",
      "index": 153,
      "title": "Procurement Auctions via Approximately Optimal Submodular Optimization",
      "authors": [
        "Yuan Deng",
        "Amin Karbasi",
        "Vahab Mirrokni",
        "Renato Leme",
        "Grigoris Velegkas",
        "Song Zuo"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "sellers",
        "auctioneer",
        "submodular",
        "auctions",
        "descending",
        "procurement",
        "optimization",
        "services",
        "frameworks",
        "nas"
      ],
      "summary": "We study the problem of procurement auctions, in which an auctioneer seeks to acquire services from a group of strategic sellers with private costs. The quality of the services is measured through some submodular function that is known to the auctioneer. Our goal is to design computationally efficient procurement auctions that (approximately) maximize the difference between the quality of the acquired services and the total cost of the sellers, in a way that is incentive compatible (IC) and individual rational (IR) for the sellers, and generates non-negative surplus (NAS) for the auctioneer. {Our contribution is twofold: \\textbf{i)} we provide an improved analysis of existing algorithms for non-positive submodular function maximization and \\textbf{ii)} we design computationally efficient frameworks that transform submodular function optimization algorithms to mechanisms that are IC and IR for the sellers, NAS for the auctioneer, and approximation-preserving.} Our frameworks are general and work both in the offline setting where the auctioneer can observe the bids and the services of all the sellers simultaneously, and in the online setting where the sellers arrive in an adversarial order and the auctioneer has to make an irrevocable decision whether to purchase their service or not. We further investigate whether it is possible to convert state-of-art submodular optimization algorithms into descending auctions. We focus on the adversarial setting, meaning that the schedule of the descending prices is determined by an adversary. We show that a submodular optimization algorithm satisfying bi-criteria ( 1 / 2 , 1 ) ( 1 / 2 , 1 ) -approximation in welfare can be effectively converted to a descending auction in this setting. We further establish a connection between descending auctions and online submodular optimization. Finally, we demonstrate the practical applications of our frameworks by instantiating them with different state-of-the-art submodular optimization algorithms and comparing their welfare performance through empirical experiments on publicly available datasets that consist of thousands of sellers.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=js3gePctLu"
        ],
        "venue": [
          "/venue/js3gePctLu@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=js3gePctLu"
        ],
        "detail": [
          "https://openreview.net/forum?id=js3gePctLu"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Procurement Auctions via Approximately Optimal Submodular Optimization [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Yuan Deng , Amin Karbasi , Vahab Mirrokni , Renato Leme , Grigoris Velegkas , Song Zuo We study the problem of procurement auctions, in which an auctioneer seeks to acquire services from a group of strategic sellers with private costs. The quality of the services is measured through some submodular function that is known to the auctioneer. Our goal is to design computationally efficient procurement auctions that (approximately) maximize the difference between the quality of the acquired services and the total cost of the sellers, in a way that is incentive compatible (IC) and individual rational (IR) for the sellers, and generates non-negative surplus (NAS) for the auctioneer. {Our contribution is twofold: \\textbf{i)} we provide an improved analysis of existing algorithms for non-positive submodular function maximization and \\textbf{ii)} we design computationally efficient frameworks that transform submodular function optimization algorithms to mechanisms that are IC and IR for the sellers, NAS for the auctioneer, and approximation-preserving.} Our frameworks are general and work both in the offline setting where the auctioneer can observe the bids and the services of all the sellers simultaneously, and in the online setting where the sellers arrive in an adversarial order and the auctioneer has to make an irrevocable decision whether to purchase their service or not. We further investigate whether it is possible to convert state-of-art submodular optimization algorithms into descending auctions. We focus on the adversarial setting, meaning that the schedule of the descending prices is determined by an adversary. We show that a submodular optimization algorithm satisfying bi-criteria ( 1 / 2 , 1 ) ( 1 / 2 , 1 ) -approximation in welfare can be effectively converted to a descending auction in this setting. We further establish a connection between descending auctions and online submodular optimization. Finally, we demonstrate the practical applications of our frameworks by instantiating them with different state-of-the-art submodular optimization algorithms and comparing their welfare performance through empirical experiments on publicly available datasets that consist of thousands of sellers. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "jvP1wbD0xh@OpenReview",
      "index": 154,
      "title": "Better to Teach than to Give: Domain Generalized Semantic Segmentation via Agent Queries with Diffusion Model Guidance",
      "authors": [
        "Fan Li",
        "Xuan Wang",
        "Min Qi",
        "Zhaoxiang Zhang",
        "yuelei xu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "dgss",
        "agent",
        "queries",
        "scene",
        "segmentation",
        "semantic",
        "querydiff",
        "domain",
        "guidance",
        "diffusion"
      ],
      "summary": "Domain Generalized Semantic Segmentation (DGSS) trains a model on a labeled source domain to generalize to unseen target domains with consistent contextual distribution and varying visual appearance.Most existing methods rely on domain randomization or data generation but struggle to capture the underlying scene distribution, resulting in the loss of useful semantic information. Inspired by the diffusion model's capability to generate diverse variations within a given scene context, we consider harnessing its rich prior knowledge of scene distribution to tackle the challenging DGSS task.In this paper, we propose a novel agent \\textbf{Query}-driven learning framework based on \\textbf{Diff}usion model guidance for DGSS, named QueryDiff. Our recipe comprises three key ingredients: (1) generating agent queries from segmentation features to aggregate semantic information about instances within the scene; (2) learning the inherent semantic distribution of the scene through agent queries guided by diffusion features; (3) refining segmentation features using optimized agent queries for robust mask predictions.Extensive experiments across various settings demonstrate that our method significantly outperforms previous state-of-the-art methods. Notably, it enhances the model's ability to generalize effectively to extreme domains, such as cubist art styles. Code is available at https://github.com/FanLiHub/QueryDiff.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=jvP1wbD0xh"
        ],
        "venue": [
          "/venue/jvP1wbD0xh@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=jvP1wbD0xh"
        ],
        "detail": [
          "https://openreview.net/forum?id=jvP1wbD0xh"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "Better to Teach than to Give: Domain Generalized Semantic Segmentation via Agent Queries with Diffusion Model Guidance [PDF 3 ] [Copy] [Kimi 1 ] [REL] Authors : Fan Li , Xuan Wang , Min Qi , Zhaoxiang Zhang , yuelei xu Domain Generalized Semantic Segmentation (DGSS) trains a model on a labeled source domain to generalize to unseen target domains with consistent contextual distribution and varying visual appearance.Most existing methods rely on domain randomization or data generation but struggle to capture the underlying scene distribution, resulting in the loss of useful semantic information. Inspired by the diffusion model's capability to generate diverse variations within a given scene context, we consider harnessing its rich prior knowledge of scene distribution to tackle the challenging DGSS task.In this paper, we propose a novel agent \\textbf{Query}-driven learning framework based on \\textbf{Diff}usion model guidance for DGSS, named QueryDiff. Our recipe comprises three key ingredients: (1) generating agent queries from segmentation features to aggregate semantic information about instances within the scene; (2) learning the inherent semantic distribution of the scene through agent queries guided by diffusion features; (3) refining segmentation features using optimized agent queries for robust mask predictions.Extensive experiments across various settings demonstrate that our method significantly outperforms previous state-of-the-art methods. Notably, it enhances the model's ability to generalize effectively to extreme domains, such as cubist art styles. Code is available at https://github.com/FanLiHub/QueryDiff. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "kfYxyvCYQ4@OpenReview",
      "index": 155,
      "title": "Hyperspherical Normalization for Scalable Deep Reinforcement Learning",
      "authors": [
        "Hojoon Lee",
        "Youngdo Lee",
        "Takuma Seno",
        "Donghu Kim",
        "Peter Stone",
        "Jaegul Choo"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "hyperspherical",
        "simbav2",
        "normalization",
        "reinforcement",
        "reward",
        "lesson",
        "scaling",
        "optimization",
        "scalable",
        "learning"
      ],
      "summary": "Scaling up the model size and computation has brought consistent performance improvements in supervised learning. However, this lesson often fails to apply to reinforcement learning (RL) because training the model on non-stationary data easily leads to overfitting and unstable optimization.In response, we introduce SimbaV2, a novel RL architecture designed to stabilize optimization by (i) constraining the growth of weight and feature norm by hyperspherical normalization; and (ii) using a distributional value estimation with reward scaling to maintain stable gradients under varying reward magnitudes. Using the soft actor-critic as a base algorithm, SimbaV2 scales up effectively with larger models and greater compute, achieving state-of-the-art performance on 57 continuous control tasks across 4 domains.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=kfYxyvCYQ4"
        ],
        "venue": [
          "/venue/kfYxyvCYQ4@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=kfYxyvCYQ4"
        ],
        "detail": [
          "https://openreview.net/forum?id=kfYxyvCYQ4"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 4
      },
      "raw_excerpt": "Hyperspherical Normalization for Scalable Deep Reinforcement Learning [PDF 5 ] [Copy] [Kimi 4 ] [REL] Authors : Hojoon Lee , Youngdo Lee , Takuma Seno , Donghu Kim , Peter Stone , Jaegul Choo Scaling up the model size and computation has brought consistent performance improvements in supervised learning. However, this lesson often fails to apply to reinforcement learning (RL) because training the model on non-stationary data easily leads to overfitting and unstable optimization.In response, we introduce SimbaV2, a novel RL architecture designed to stabilize optimization by (i) constraining the growth of weight and feature norm by hyperspherical normalization; and (ii) using a distributional value estimation with reward scaling to maintain stable gradients under varying reward magnitudes. Using the soft actor-critic as a base algorithm, SimbaV2 scales up effectively with larger models and greater compute, achieving state-of-the-art performance on 57 continuous control tasks across 4 domains. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "kmg7hweySi@OpenReview",
      "index": 156,
      "title": "Feature learning from non-Gaussian inputs: the case of Independent Component Analysis in high dimensions",
      "authors": [
        "Fabiola Ricci",
        "Lorenzo Bardone",
        "Sebastian Goldt"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "fastica",
        "ica",
        "inputs",
        "gaussian",
        "feature",
        "learnt",
        "sgd",
        "gtrsim",
        "non",
        "independent"
      ],
      "summary": "Deep neural networks learn structured features from complex, non-Gaussian inputs, but the mechanisms behind this process remain poorly understood. Our work is motivated by the observation that the first-layer filters learnt by deep convolutional neural networks from natural images resemble those learnt by independent component analysis (ICA), a simple unsupervised method that seeks the most non-Gaussian projections of its inputs. This similarity suggests that ICA provides a simple, yet principled model for studying feature learning. Here, we leverage this connection to investigate the interplay between data structure and optimisation in feature learning for the most popular ICA algorithm, FastICA, and stochastic gradient descent (SGD), which is used to train deep networks. We rigorously establish that FastICA requires at least n ≳ d 4 n ≳ d 4 samples to recover a single non-Gaussian direction from d d -dimensional inputs on a simple synthetic data model. We show that vanilla online SGD outperforms FastICA, and prove that the optimal sample complexity n ≳ d 2 n ≳ d 2 can be reached by smoothing the loss, albeit in a data-dependent way. We finally demonstrate the existence of a search phase for FastICA on ImageNet, and discuss how the strong non-Gaussianity of said images compensates for the poor sample complexity of FastICA.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=kmg7hweySi"
        ],
        "venue": [
          "/venue/kmg7hweySi@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=kmg7hweySi"
        ],
        "detail": [
          "https://openreview.net/forum?id=kmg7hweySi"
        ]
      },
      "scores": {
        "pdf": null,
        "kimi": null
      },
      "raw_excerpt": "Feature learning from non-Gaussian inputs: the case of Independent Component Analysis in high dimensions [PDF ] [Copy] [Kimi ] [REL] Authors : Fabiola Ricci , Lorenzo Bardone , Sebastian Goldt Deep neural networks learn structured features from complex, non-Gaussian inputs, but the mechanisms behind this process remain poorly understood. Our work is motivated by the observation that the first-layer filters learnt by deep convolutional neural networks from natural images resemble those learnt by independent component analysis (ICA), a simple unsupervised method that seeks the most non-Gaussian projections of its inputs. This similarity suggests that ICA provides a simple, yet principled model for studying feature learning. Here, we leverage this connection to investigate the interplay between data structure and optimisation in feature learning for the most popular ICA algorithm, FastICA, and stochastic gradient descent (SGD), which is used to train deep networks. We rigorously establish that FastICA requires at least n ≳ d 4 n ≳ d 4 samples to recover a single non-Gaussian direction from d d -dimensional inputs on a simple synthetic data model. We show that vanilla online SGD outperforms FastICA, and prove that the optimal sample complexity n ≳ d 2 n ≳ d 2 can be reached by smoothing the loss, albeit in a data-dependent way. We finally demonstrate the existence of a search phase for FastICA on ImageNet, and discuss how the strong non-Gaussianity of said images compensates for the poor sample complexity of FastICA. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "mEV0nvHcK3@OpenReview",
      "index": 157,
      "title": "Towards Practical Defect-Focused Automated Code Review",
      "authors": [
        "Junyi Lu",
        "Lili Jiang",
        "Xiaojia Li",
        "Jianbing Fang",
        "Fengjun Zhang",
        "Li Yang",
        "Chun Zuo"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "kbi",
        "code",
        "defect",
        "merge",
        "review",
        "context",
        "oversimplify",
        "codebases",
        "snippet",
        "text"
      ],
      "summary": "The complexity of code reviews has driven efforts to automate review comments, but prior approaches oversimplify this task by treating it as snippet-level code-to-text generation and relying on text similarity metrics like BLEU for evaluation. These methods overlook repository context, real-world merge request evaluation, and defect detection, limiting their practicality. To address these issues, we explore the full automation pipeline within the online recommendation service of a company with nearly 400 million daily active users, analyzing industry-grade C++ codebases comprising hundreds of thousands of lines of code. We identify four key challenges: 1) capturing relevant context, 2) improving key bug inclusion (KBI), 3) reducing false alarm rates (FAR), and 4) integrating human workflows. To tackle these, we propose 1) code slicing algorithms for context extraction, 2) a multi-role LLM framework for KBI, 3) a filtering mechanism for FAR reduction, and 4) a novel prompt design for better human interaction. Our approach, validated on real-world merge requests from historical fault reports, achieves a 2× improvement over standard LLMs and a 10× gain over previous baselines. While the presented results focus on C++, the underlying framework design leverages language-agnostic principles (e.g., AST-based analysis), suggesting potential for broader applicability.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=mEV0nvHcK3"
        ],
        "venue": [
          "/venue/mEV0nvHcK3@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=mEV0nvHcK3"
        ],
        "detail": [
          "https://openreview.net/forum?id=mEV0nvHcK3"
        ]
      },
      "scores": {
        "pdf": null,
        "kimi": 1
      },
      "raw_excerpt": "Towards Practical Defect-Focused Automated Code Review [PDF ] [Copy] [Kimi 1 ] [REL] Authors : Junyi Lu , Lili Jiang , Xiaojia Li , Jianbing Fang , Fengjun Zhang , Li Yang , Chun Zuo The complexity of code reviews has driven efforts to automate review comments, but prior approaches oversimplify this task by treating it as snippet-level code-to-text generation and relying on text similarity metrics like BLEU for evaluation. These methods overlook repository context, real-world merge request evaluation, and defect detection, limiting their practicality. To address these issues, we explore the full automation pipeline within the online recommendation service of a company with nearly 400 million daily active users, analyzing industry-grade C++ codebases comprising hundreds of thousands of lines of code. We identify four key challenges: 1) capturing relevant context, 2) improving key bug inclusion (KBI), 3) reducing false alarm rates (FAR), and 4) integrating human workflows. To tackle these, we propose 1) code slicing algorithms for context extraction, 2) a multi-role LLM framework for KBI, 3) a filtering mechanism for FAR reduction, and 4) a novel prompt design for better human interaction. Our approach, validated on real-world merge requests from historical fault reports, achieves a 2× improvement over standard LLMs and a 10× gain over previous baselines. While the presented results focus on C++, the underlying framework design leverages language-agnostic principles (e.g., AST-based analysis), suggesting potential for broader applicability. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "mruyFvKDKq@OpenReview",
      "index": 158,
      "title": "Invariant Deep Uplift Modeling for Incentive Assignment in Online Marketing via Probability of Necessity and Sufficiency",
      "authors": [
        "Zexu Sun",
        "Qiyu Han",
        "Hao Yang",
        "Anpeng Wu",
        "Minqin Zhu",
        "Dugang Liu",
        "Chen Ma",
        "Yunpeng Weng",
        "Xing Tang",
        "xiuqiang He"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "uplift",
        "idum",
        "textbf",
        "marketing",
        "online",
        "distribution",
        "modeling",
        "invariant",
        "odeling",
        "sufficiency"
      ],
      "summary": "In online platforms, incentives (\\textit{e.g}., discounts, coupons) are used to boost user engagement and revenue. Uplift modeling methods are developed to estimate user responses from observational data, often incorporating distribution balancing to address selection bias. However, these methods are limited by in-distribution testing data, which mirrors the training data distribution. In reality, user features change continuously due to time, geography, and other factors, especially on complex online marketing platforms. Thus, effective uplift modeling method for out-of-distribution data is crucial. To address this, we propose a novel uplift modeling method \\textbf{I}nvariant \\textbf{D}eep \\textbf{U}plift \\textbf{M}odeling, namely \\textbf{IDUM}, which uses invariant learning to enhance out-of-distribution generalization by identifying causal factors that remain consistent across domains. IDUM further refines these features into necessary and sufficient factors and employs a masking component to reduce computational costs by selecting the most informative invariant features. A balancing discrepancy component is also introduced to mitigate selection bias in observational data. We conduct extensive experiments on public and real-world datasets to demonstrate IDUM's effectiveness in both in-distribution and out-of-distribution scenarios in online marketing. Furthermore, we also provide theoretical analysis and related proofs to support our IDUM's generalizability.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=mruyFvKDKq"
        ],
        "venue": [
          "/venue/mruyFvKDKq@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=mruyFvKDKq"
        ],
        "detail": [
          "https://openreview.net/forum?id=mruyFvKDKq"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Invariant Deep Uplift Modeling for Incentive Assignment in Online Marketing via Probability of Necessity and Sufficiency [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Zexu Sun , Qiyu Han , Hao Yang , Anpeng Wu , Minqin Zhu , Dugang Liu , Chen Ma , Yunpeng Weng , Xing Tang , xiuqiang He In online platforms, incentives (\\textit{e.g}., discounts, coupons) are used to boost user engagement and revenue. Uplift modeling methods are developed to estimate user responses from observational data, often incorporating distribution balancing to address selection bias. However, these methods are limited by in-distribution testing data, which mirrors the training data distribution. In reality, user features change continuously due to time, geography, and other factors, especially on complex online marketing platforms. Thus, effective uplift modeling method for out-of-distribution data is crucial. To address this, we propose a novel uplift modeling method \\textbf{I}nvariant \\textbf{D}eep \\textbf{U}plift \\textbf{M}odeling, namely \\textbf{IDUM}, which uses invariant learning to enhance out-of-distribution generalization by identifying causal factors that remain consistent across domains. IDUM further refines these features into necessary and sufficient factors and employs a masking component to reduce computational costs by selecting the most informative invariant features. A balancing discrepancy component is also introduced to mitigate selection bias in observational data. We conduct extensive experiments on public and real-world datasets to demonstrate IDUM's effectiveness in both in-distribution and out-of-distribution scenarios in online marketing. Furthermore, we also provide theoretical analysis and related proofs to support our IDUM's generalizability. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "mwSBIlNLdQ@OpenReview",
      "index": 159,
      "title": "Learning Dynamics under Environmental Constraints via Measurement-Induced Bundle Structures",
      "authors": [
        "Dongzhe Zheng",
        "Wenjie Mei"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "constraints",
        "geometric",
        "dynamics",
        "learning",
        "environmental",
        "bundle",
        "constraint",
        "sensing",
        "measurement",
        "satisfaction"
      ],
      "summary": "Learning unknown dynamics under environmental (or external) constraints is fundamental to many fields (e.g., modern robotics), particularly challenging when constraint information is only locally available and uncertain. Existing approaches requiring global constraints or using probabilistic filtering fail to fully exploit the geometric structure inherent in local measurements (by using, e.g., sensors) and constraints. This paper presents a geometric framework unifying measurements, constraints, and dynamics learning through a fiber bundle structure over the state space. This naturally induced geometric structure enables measurement-aware Control Barrier Functions that adapt to local sensing (or measurement) conditions. By integrating Neural ODEs, our framework learns continuous-time dynamics while preserving geometric constraints, with theoretical guarantees of learning convergence and constraint satisfaction dependent on sensing quality. The geometric framework not only enables efficient dynamics learning but also suggests promising directions for integration with reinforcement learning approaches. Extensive simulations demonstrate significant improvements in both learning efficiency and constraint satisfaction over traditional methods, especially under limited and uncertain sensing conditions.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=mwSBIlNLdQ"
        ],
        "venue": [
          "/venue/mwSBIlNLdQ@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=mwSBIlNLdQ"
        ],
        "detail": [
          "https://openreview.net/forum?id=mwSBIlNLdQ"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 3
      },
      "raw_excerpt": "Learning Dynamics under Environmental Constraints via Measurement-Induced Bundle Structures [PDF 2 ] [Copy] [Kimi 3 ] [REL] Authors : Dongzhe Zheng , Wenjie Mei Learning unknown dynamics under environmental (or external) constraints is fundamental to many fields (e.g., modern robotics), particularly challenging when constraint information is only locally available and uncertain. Existing approaches requiring global constraints or using probabilistic filtering fail to fully exploit the geometric structure inherent in local measurements (by using, e.g., sensors) and constraints. This paper presents a geometric framework unifying measurements, constraints, and dynamics learning through a fiber bundle structure over the state space. This naturally induced geometric structure enables measurement-aware Control Barrier Functions that adapt to local sensing (or measurement) conditions. By integrating Neural ODEs, our framework learns continuous-time dynamics while preserving geometric constraints, with theoretical guarantees of learning convergence and constraint satisfaction dependent on sensing quality. The geometric framework not only enables efficient dynamics learning but also suggests promising directions for integration with reinforcement learning approaches. Extensive simulations demonstrate significant improvements in both learning efficiency and constraint satisfaction over traditional methods, especially under limited and uncertain sensing conditions. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "mzSwYvwYdC@OpenReview",
      "index": 160,
      "title": "Independence Tests for Language Models",
      "authors": [
        "Sally Zhu",
        "Ahmed Ahmed",
        "Rohith Kuditipudi",
        "Percy Liang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "models",
        "independent",
        "initializations",
        "test",
        "values",
        "llama",
        "assumptions",
        "unconstrained",
        "copies",
        "tests"
      ],
      "summary": "Motivated by liability and intellectual property concerns over open-weight models we consider the following problem: given the weights of two models, can we test whether they were trained independently---i.e., from independent random initializations? We consider two settings: *constrained* and *unconstrained*. In the constrained setting, we make assumptions about model architecture and training and propose statistical tests that yield exact p-values with respect to the null hypothesis that the models are trained from independent random initializations. We compute the p-values by simulating exchangeable copies of each model under our assumptions and comparing various similarity measures between the original two models versus these copies. We report p-values on pairs of 21 open-weight models (210 total pairs) and find we correctly identify all pairs of non-independent models. In the unconstrained setting we make none of the prior assumptions and allow for adversarial evasion attacks that do not change model output. We thus propose a new test which matches hidden activations between two models, which is robust to these transformations and to changes in model architecture and can also identify specific non-independent components of models. Though we no longer obtain exact p-values from this test, empirically we find it reliably distinguishes non-independent models like a p-value. Notably, we can use the test to identify specific parts of one model that are derived from another (e.g., how Llama 3.1-8B was pruned to initialize Llama 3.2-3B, or shared layers between Mistral-7B and StripedHyena-7B), and it is even robust to retraining individual layers of either model from scratch.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=mzSwYvwYdC"
        ],
        "venue": [
          "/venue/mzSwYvwYdC@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=mzSwYvwYdC"
        ],
        "detail": [
          "https://openreview.net/forum?id=mzSwYvwYdC"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 3
      },
      "raw_excerpt": "Independence Tests for Language Models [PDF 4 ] [Copy] [Kimi 3 ] [REL] Authors : Sally Zhu , Ahmed Ahmed , Rohith Kuditipudi , Percy Liang Motivated by liability and intellectual property concerns over open-weight models we consider the following problem: given the weights of two models, can we test whether they were trained independently---i.e., from independent random initializations? We consider two settings: *constrained* and *unconstrained*. In the constrained setting, we make assumptions about model architecture and training and propose statistical tests that yield exact p-values with respect to the null hypothesis that the models are trained from independent random initializations. We compute the p-values by simulating exchangeable copies of each model under our assumptions and comparing various similarity measures between the original two models versus these copies. We report p-values on pairs of 21 open-weight models (210 total pairs) and find we correctly identify all pairs of non-independent models. In the unconstrained setting we make none of the prior assumptions and allow for adversarial evasion attacks that do not change model output. We thus propose a new test which matches hidden activations between two models, which is robust to these transformations and to changes in model architecture and can also identify specific non-independent components of models. Though we no longer obtain exact p-values from this test, empirically we find it reliably distinguishes non-independent models like a p-value. Notably, we can use the test to identify specific parts of one model that are derived from another (e.g., how Llama 3.1-8B was pruned to initialize Llama 3.2-3B, or shared layers between Mistral-7B and StripedHyena-7B), and it is even robust to retraining individual layers of either model from scratch. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "nVD7KoU09V@OpenReview",
      "index": 161,
      "title": "Rethink GraphODE Generalization within Coupled Dynamical System",
      "authors": [
        "Guancheng Wan",
        "Zijie Huang",
        "Wanjia Zhao",
        "Xiao Luo",
        "Yizhou Sun",
        "Wei Wang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "graphode",
        "static",
        "causal",
        "generalization",
        "coupled",
        "dynamical",
        "initialization",
        "cmcd",
        "rethink",
        "dynamic"
      ],
      "summary": "Coupled dynamical systems govern essential phenomena across physics, biology, and engineering, where components interact through complex dependencies. While Graph Ordinary Differential Equations (GraphODE) offer a powerful framework to model these systems, their **generalization** capabilities degrade severely under limited observational training data due to two fundamental flaws: (i) the entanglement of static attributes and dynamic states in the initialization process, and (ii) the reliance on context-specific coupling patterns during training, which hinders performance in unseen scenarios. In this paper, we propose a Generalizable GraphODE with disentanglement and regularization (GREAT) to address these challenges. Through systematic analysis via the Structural Causal Model, we identify backdoor paths that undermine generalization and design two key modules to mitigate their effects. The *Dynamic-Static Equilibrium Decoupler (DyStaED)* disentangles static and dynamic states via orthogonal subspace projections, ensuring robust initialization. Furthermore, the *Causal Mediation for Coupled Dynamics (CMCD)* employs variational inference to estimate latent causal factors, reducing spurious correlations and enhancing universal coupling dynamics. Extensive experiments across diverse dynamical systems demonstrate that ours outperforms state-of-the-art methods within both in-distribution and out-of-distribution.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=nVD7KoU09V"
        ],
        "venue": [
          "/venue/nVD7KoU09V@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=nVD7KoU09V"
        ],
        "detail": [
          "https://openreview.net/forum?id=nVD7KoU09V"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "Rethink GraphODE Generalization within Coupled Dynamical System [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Guancheng Wan , Zijie Huang , Wanjia Zhao , Xiao Luo , Yizhou Sun , Wei Wang Coupled dynamical systems govern essential phenomena across physics, biology, and engineering, where components interact through complex dependencies. While Graph Ordinary Differential Equations (GraphODE) offer a powerful framework to model these systems, their **generalization** capabilities degrade severely under limited observational training data due to two fundamental flaws: (i) the entanglement of static attributes and dynamic states in the initialization process, and (ii) the reliance on context-specific coupling patterns during training, which hinders performance in unseen scenarios. In this paper, we propose a Generalizable GraphODE with disentanglement and regularization (GREAT) to address these challenges. Through systematic analysis via the Structural Causal Model, we identify backdoor paths that undermine generalization and design two key modules to mitigate their effects. The *Dynamic-Static Equilibrium Decoupler (DyStaED)* disentangles static and dynamic states via orthogonal subspace projections, ensuring robust initialization. Furthermore, the *Causal Mediation for Coupled Dynamics (CMCD)* employs variational inference to estimate latent causal factors, reducing spurious correlations and enhancing universal coupling dynamics. Extensive experiments across diverse dynamical systems demonstrate that ours outperforms state-of-the-art methods within both in-distribution and out-of-distribution. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "oYyaVSqEFu@OpenReview",
      "index": 162,
      "title": "When Every Millisecond Counts: Real-Time Anomaly Detection via the Multimodal Asynchronous Hybrid Network",
      "authors": [
        "Dong Xiao",
        "Guangyao Chen",
        "Peixi Peng",
        "Yangru Huang",
        "Yifan Zhao",
        "Yongxing Dai",
        "Yonghong Tian"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "asynchronous",
        "anomaly",
        "driving",
        "cameras",
        "millisecond",
        "detection",
        "time",
        "multimodal",
        "event",
        "network"
      ],
      "summary": "Anomaly detection is essential for the safety and reliability of autonomous driving systems. Current methods often focus on detection accuracy but neglect response time, which is critical in time-sensitive driving scenarios. In this paper, we introduce real-time anomaly detection for autonomous driving, prioritizing both minimal response time and high accuracy. We propose a novel multimodal asynchronous hybrid network that combines event streams from event cameras with image data from RGB cameras. Our network utilizes the high temporal resolution of event cameras through an asynchronous Graph Neural Network and integrates it with spatial features extracted by a CNN from RGB images. This combination effectively captures both the temporal dynamics and spatial details of the driving environment, enabling swift and precise anomaly detection. Extensive experiments on benchmark datasets show that our approach outperforms existing methods in both accuracy and response time, achieving millisecond-level real-time performance.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=oYyaVSqEFu"
        ],
        "venue": [
          "/venue/oYyaVSqEFu@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=oYyaVSqEFu"
        ],
        "detail": [
          "https://openreview.net/forum?id=oYyaVSqEFu"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 3
      },
      "raw_excerpt": "When Every Millisecond Counts: Real-Time Anomaly Detection via the Multimodal Asynchronous Hybrid Network [PDF 3 ] [Copy] [Kimi 3 ] [REL] Authors : Dong Xiao , Guangyao Chen , Peixi Peng , Yangru Huang , Yifan Zhao , Yongxing Dai , Yonghong Tian Anomaly detection is essential for the safety and reliability of autonomous driving systems. Current methods often focus on detection accuracy but neglect response time, which is critical in time-sensitive driving scenarios. In this paper, we introduce real-time anomaly detection for autonomous driving, prioritizing both minimal response time and high accuracy. We propose a novel multimodal asynchronous hybrid network that combines event streams from event cameras with image data from RGB cameras. Our network utilizes the high temporal resolution of event cameras through an asynchronous Graph Neural Network and integrates it with spatial features extracted by a CNN from RGB images. This combination effectively captures both the temporal dynamics and spatial details of the driving environment, enabling swift and precise anomaly detection. Extensive experiments on benchmark datasets show that our approach outperforms existing methods in both accuracy and response time, achieving millisecond-level real-time performance. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "oa7MYAO6h6@OpenReview",
      "index": 163,
      "title": "ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference",
      "authors": [
        "Hanshi Sun",
        "Li-Wen Chang",
        "Wenlei Bao",
        "Size Zheng",
        "Ningxin Zheng",
        "Xin Liu",
        "Harry Dong",
        "Yuejie Chi",
        "Beidi Chen"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "shadowkv",
        "cache",
        "throughput",
        "context",
        "inference",
        "decoding",
        "gpu",
        "batch",
        "memory",
        "llm"
      ],
      "summary": "With the widespread deployment of long-context large language models (LLMs), there has been a growing demand for efficient support of high-throughput inference. However, as the key-value (KV) cache expands with the sequence length, the increasing memory footprint and the need to access it for decoding both result in low throughput when serving long-context LLMs. While various dynamic sparse attention methods have been proposed to accelerate inference while maintaining generation quality, they either fail to sufficiently reduce GPU memory usage or introduce significant decoding latency by offloading the KV cache to the CPU. We present ShadowKV, a high-throughput long-context LLM inference system that stores the low-rank key cache and offloads the value cache to reduce the memory footprint for larger batch sizes and longer sequences. To minimize decoding latency, ShadowKV employs an accurate KV selection strategy that reconstructs minimal sparse KV pairs on-the-fly. By evaluating ShadowKV on benchmarks like RULER, LongBench, and models such as Llama-3.1-8B and GLM-4-9B-1M, we demonstrate that it achieves up to 6 × × larger batch sizes and 3.04 × × higher throughput on an A100 GPU without sacrificing accuracy, even surpassing the performance achievable with infinite batch size under the assumption of infinite GPU memory.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=oa7MYAO6h6"
        ],
        "venue": [
          "/venue/oa7MYAO6h6@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=oa7MYAO6h6"
        ],
        "detail": [
          "https://openreview.net/forum?id=oa7MYAO6h6"
        ]
      },
      "scores": {
        "pdf": 12,
        "kimi": 7
      },
      "raw_excerpt": "ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference [PDF 12 ] [Copy] [Kimi 7 ] [REL] Authors : Hanshi Sun , Li-Wen Chang , Wenlei Bao , Size Zheng , Ningxin Zheng , Xin Liu , Harry Dong , Yuejie Chi , Beidi Chen With the widespread deployment of long-context large language models (LLMs), there has been a growing demand for efficient support of high-throughput inference. However, as the key-value (KV) cache expands with the sequence length, the increasing memory footprint and the need to access it for decoding both result in low throughput when serving long-context LLMs. While various dynamic sparse attention methods have been proposed to accelerate inference while maintaining generation quality, they either fail to sufficiently reduce GPU memory usage or introduce significant decoding latency by offloading the KV cache to the CPU. We present ShadowKV, a high-throughput long-context LLM inference system that stores the low-rank key cache and offloads the value cache to reduce the memory footprint for larger batch sizes and longer sequences. To minimize decoding latency, ShadowKV employs an accurate KV selection strategy that reconstructs minimal sparse KV pairs on-the-fly. By evaluating ShadowKV on benchmarks like RULER, LongBench, and models such as Llama-3.1-8B and GLM-4-9B-1M, we demonstrate that it achieves up to 6 × × larger batch sizes and 3.04 × × higher throughput on an A100 GPU without sacrificing accuracy, even surpassing the performance achievable with infinite batch size under the assumption of infinite GPU memory. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "otNB7BzsiR@OpenReview",
      "index": 164,
      "title": "Determining Layer-wise Sparsity for Large Language Models Through a Theoretical Perspective",
      "authors": [
        "Weizhong Huang",
        "Yuxin Zhang",
        "Xiawu Zheng",
        "Fei Chao",
        "Rongrong Ji"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "sparsity",
        "wise",
        "layer",
        "theoretical",
        "determining",
        "sparsification",
        "llms",
        "reconstruction",
        "layers",
        "perspective"
      ],
      "summary": "In this paper, we address the challenge of determining the layer-wise sparsity rates of large language models (LLMs) through a theoretical perspective. Specifically, we identify a critical issue of **\"reconstruction error explosion\"** in existing LLMs sparsification methods. This refers to the cumulative effect of reconstruction errors throughout the sparsification process, where errors from earlier layers propagate and amplify in subsequent layers. As a result, the overall reconstruction error increases significantly, leading to a substantial degradation in model performance. Through theoretical analysis, we derive a simple yet effective approach to layer-wise sparsity allocation that mitigates this issue. Our method uses a monotonically increasing arithmetic progression, reducing the process of determining sparsity rates for multiple layers to the determination of a single common difference hyperparameter. Remarkably, this allows for the optimal layer-wise sparsity rates to be identified with just a few trials. Both our theoretical analysis and experimental results demonstrate that this sparsity allocation scheme is near optimal. Extensive experiments show that our method significantly improves the performance of sparse LLMs across various architectures, outperforming existing layer-wise sparsity methods. Furthermore, it enhances the performance of various compression techniques and is applicable to vision and multimodal models. Notably, our method achieves a reduction of 52.10 in perplexity for the 70% sparse LLaMA2-7B model obtained via Wanda, improves average zero-shot accuracy by 10.50%, and delivers speedups of 2.63 × × and 2.23 × × on CPU and GPU, respectively. Code is available at https://github.com/wzhuang-xmu/ATP.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=otNB7BzsiR"
        ],
        "venue": [
          "/venue/otNB7BzsiR@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=otNB7BzsiR"
        ],
        "detail": [
          "https://openreview.net/forum?id=otNB7BzsiR"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 6
      },
      "raw_excerpt": "Determining Layer-wise Sparsity for Large Language Models Through a Theoretical Perspective [PDF 3 ] [Copy] [Kimi 6 ] [REL] Authors : Weizhong Huang , Yuxin Zhang , Xiawu Zheng , Fei Chao , Rongrong Ji In this paper, we address the challenge of determining the layer-wise sparsity rates of large language models (LLMs) through a theoretical perspective. Specifically, we identify a critical issue of **\"reconstruction error explosion\"** in existing LLMs sparsification methods. This refers to the cumulative effect of reconstruction errors throughout the sparsification process, where errors from earlier layers propagate and amplify in subsequent layers. As a result, the overall reconstruction error increases significantly, leading to a substantial degradation in model performance. Through theoretical analysis, we derive a simple yet effective approach to layer-wise sparsity allocation that mitigates this issue. Our method uses a monotonically increasing arithmetic progression, reducing the process of determining sparsity rates for multiple layers to the determination of a single common difference hyperparameter. Remarkably, this allows for the optimal layer-wise sparsity rates to be identified with just a few trials. Both our theoretical analysis and experimental results demonstrate that this sparsity allocation scheme is near optimal. Extensive experiments show that our method significantly improves the performance of sparse LLMs across various architectures, outperforming existing layer-wise sparsity methods. Furthermore, it enhances the performance of various compression techniques and is applicable to vision and multimodal models. Notably, our method achieves a reduction of 52.10 in perplexity for the 70% sparse LLaMA2-7B model obtained via Wanda, improves average zero-shot accuracy by 10.50%, and delivers speedups of 2.63 × × and 2.23 × × on CPU and GPU, respectively. Code is available at https://github.com/wzhuang-xmu/ATP. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "pKaNgFzJBy@OpenReview",
      "index": 165,
      "title": "On the Guidance of Flow Matching",
      "authors": [
        "Ruiqi Feng",
        "Chenglei Yu",
        "Wenhao Deng",
        "Peiyan Hu",
        "Tailin Wu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "guidance",
        "matching",
        "flow",
        "westlakeu",
        "ai4science",
        "general",
        "methods",
        "abbreviated",
        "different",
        "predecessor"
      ],
      "summary": "Flow matching has shown state-of-the-art performance in various generative tasks, ranging from image generation to decision-making, where generation under energy guidance (abbreviated as guidance in the following) is pivotal. However, the guidance of flow matching is more general than and thus substantially different from that of its predecessor, diffusion models. Therefore, the challenge in guidance for general flow matching remains largely underexplored. In this paper, we propose the first framework of general guidance for flow matching. From this framework, we derive a family of guidance techniques that can be applied to general flow matching. These include a new training-free asymptotically exact guidance, novel training losses for training-based guidance, and two classes of approximate guidance that cover classical gradient guidance methods as special cases. We theoretically investigate these different methods to give a practical guideline for choosing suitable methods in different scenarios. Experiments on synthetic datasets, image inverse problems, and offline reinforcement learning demonstrate the effectiveness of our proposed guidance methods and verify the correctness of our flow matching guidance framework. Code to reproduce the experiments can be found at https://github.com/AI4Science-WestlakeU/flow_guidance.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=pKaNgFzJBy"
        ],
        "venue": [
          "/venue/pKaNgFzJBy@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=pKaNgFzJBy"
        ],
        "detail": [
          "https://openreview.net/forum?id=pKaNgFzJBy"
        ]
      },
      "scores": {
        "pdf": 7,
        "kimi": 7
      },
      "raw_excerpt": "On the Guidance of Flow Matching [PDF 7 ] [Copy] [Kimi 7 ] [REL] Authors : Ruiqi Feng , Chenglei Yu , Wenhao Deng , Peiyan Hu , Tailin Wu Flow matching has shown state-of-the-art performance in various generative tasks, ranging from image generation to decision-making, where generation under energy guidance (abbreviated as guidance in the following) is pivotal. However, the guidance of flow matching is more general than and thus substantially different from that of its predecessor, diffusion models. Therefore, the challenge in guidance for general flow matching remains largely underexplored. In this paper, we propose the first framework of general guidance for flow matching. From this framework, we derive a family of guidance techniques that can be applied to general flow matching. These include a new training-free asymptotically exact guidance, novel training losses for training-based guidance, and two classes of approximate guidance that cover classical gradient guidance methods as special cases. We theoretically investigate these different methods to give a practical guideline for choosing suitable methods in different scenarios. Experiments on synthetic datasets, image inverse problems, and offline reinforcement learning demonstrate the effectiveness of our proposed guidance methods and verify the correctness of our flow matching guidance framework. Code to reproduce the experiments can be found at https://github.com/AI4Science-WestlakeU/flow_guidance. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "pWs925fKyK@OpenReview",
      "index": 166,
      "title": "Bridging Layout and RTL: Knowledge Distillation based Timing Prediction",
      "authors": [
        "Mingjun Wang",
        "Yihan Wen",
        "Bin Sun",
        "Jianan Mu",
        "Juan Li",
        "Xiaoyi Wang",
        "Jing Ye",
        "Bei Yu",
        "Huawei Li"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "rtl",
        "timing",
        "rtldistil",
        "eda",
        "prediction",
        "distillation",
        "layout",
        "teacher",
        "gnn",
        "level"
      ],
      "summary": "Accurate and efficient timing prediction at the register-transfer level (RTL) remains a fundamental challenge in electronic design automation (EDA), particularly in striking a balance between accuracy and computational efficiency. While static timing analysis (STA) provides high-fidelity results through comprehensive physical parameters, its computational overhead makes it impractical for rapid design iterations. Conversely, existing RTL-level approaches sacrifice accuracy due to the limited physical information available. We propose RTLDistil, a novel cross-stage knowledge distillation framework that bridges this gap by transferring precise physical characteristics from a layout-aware teacher model (Teacher GNN) to an efficient RTL-level student model (Student GNN), both implemented as graph neural networks (GNNs). RTLDistil efficiently predicts key timing metrics, such as arrival time (AT), and employs a multi-granularity distillation strategy that captures timing-critical features at node, subgraph, and global levels. Experimental results demonstrate that RTLDistil achieves significant improvement in RTL-level timing prediction error reduction, compared to state-of-the-art prediction models. This framework enables accurate early-stage timing prediction, advancing EDA's ``left-shift'' paradigm while maintaining computational efficiency. Our code and dataset will be publicly available at https://github.com/sklp-eda-lab/RTLDistil.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=pWs925fKyK"
        ],
        "venue": [
          "/venue/pWs925fKyK@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=pWs925fKyK"
        ],
        "detail": [
          "https://openreview.net/forum?id=pWs925fKyK"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 1
      },
      "raw_excerpt": "Bridging Layout and RTL: Knowledge Distillation based Timing Prediction [PDF 5 ] [Copy] [Kimi 1 ] [REL] Authors : Mingjun Wang , Yihan Wen , Bin Sun , Jianan Mu , Juan Li , Xiaoyi Wang , Jing Ye , Bei Yu , Huawei Li Accurate and efficient timing prediction at the register-transfer level (RTL) remains a fundamental challenge in electronic design automation (EDA), particularly in striking a balance between accuracy and computational efficiency. While static timing analysis (STA) provides high-fidelity results through comprehensive physical parameters, its computational overhead makes it impractical for rapid design iterations. Conversely, existing RTL-level approaches sacrifice accuracy due to the limited physical information available. We propose RTLDistil, a novel cross-stage knowledge distillation framework that bridges this gap by transferring precise physical characteristics from a layout-aware teacher model (Teacher GNN) to an efficient RTL-level student model (Student GNN), both implemented as graph neural networks (GNNs). RTLDistil efficiently predicts key timing metrics, such as arrival time (AT), and employs a multi-granularity distillation strategy that captures timing-critical features at node, subgraph, and global levels. Experimental results demonstrate that RTLDistil achieves significant improvement in RTL-level timing prediction error reduction, compared to state-of-the-art prediction models. This framework enables accurate early-stage timing prediction, advancing EDA's ``left-shift'' paradigm while maintaining computational efficiency. Our code and dataset will be publicly available at https://github.com/sklp-eda-lab/RTLDistil. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "tNGdLEL4R0@OpenReview",
      "index": 167,
      "title": "Scaling Trends in Language Model Robustness",
      "authors": [
        "Nikolaus Howe",
        "Ian McKenzie",
        "Oskar Hollinsworth",
        "Michał Zając",
        "Tom Tseng",
        "Aaron Tucker",
        "Pierre-Luc Bacon",
        "Adam Gleave"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "robustness",
        "scaling",
        "defense",
        "attack",
        "models",
        "adversarially",
        "adversarial",
        "attacks",
        "alignmentresearch",
        "language"
      ],
      "summary": "Increasing model size has unlocked a dazzling array of capabilities in language models.At the same time, even frontier models remain vulnerable to jailbreaks and prompt injections, despite concerted efforts to make them robust.As both attackers and defenders gain access to more compute, and as models become larger, what will be the effect on robustness?We argue that to answer this question requires a *scaling lens*, which we adopt in an extensive study of language model robustness across several classification tasks, model families, and adversarial attacks.We find that in the absence of explicit safety training, larger models are not consistently more robust; however, scale improves sample efficiency in adversarial training, though it worsens compute efficiency.Further, we find that increasing attack compute smoothly improves attack success rate against both undefended and adversarially trained models.Finally, after exploring robustness transfer across attacks and threat models, we combine attack and defense scaling rates to study the offense-defense balance.We find that while attack scaling outpaces adversarial training across all models studied, larger adversarially trained models might give defense the advantage in the long run.These results underscore the utility of the scaling lens, and provide a paradigm for evaluating future attacks and defenses on frontier models.Code for this project is available at https://github.com/AlignmentResearch/scaling-llm-robustness-paper.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=tNGdLEL4R0"
        ],
        "venue": [
          "/venue/tNGdLEL4R0@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=tNGdLEL4R0"
        ],
        "detail": [
          "https://openreview.net/forum?id=tNGdLEL4R0"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 3
      },
      "raw_excerpt": "Scaling Trends in Language Model Robustness [PDF 2 ] [Copy] [Kimi 3 ] [REL] Authors : Nikolaus Howe , Ian McKenzie , Oskar Hollinsworth , Michał Zając , Tom Tseng , Aaron Tucker , Pierre-Luc Bacon , Adam Gleave Increasing model size has unlocked a dazzling array of capabilities in language models.At the same time, even frontier models remain vulnerable to jailbreaks and prompt injections, despite concerted efforts to make them robust.As both attackers and defenders gain access to more compute, and as models become larger, what will be the effect on robustness?We argue that to answer this question requires a *scaling lens*, which we adopt in an extensive study of language model robustness across several classification tasks, model families, and adversarial attacks.We find that in the absence of explicit safety training, larger models are not consistently more robust; however, scale improves sample efficiency in adversarial training, though it worsens compute efficiency.Further, we find that increasing attack compute smoothly improves attack success rate against both undefended and adversarially trained models.Finally, after exploring robustness transfer across attacks and threat models, we combine attack and defense scaling rates to study the offense-defense balance.We find that while attack scaling outpaces adversarial training across all models studied, larger adversarially trained models might give defense the advantage in the long run.These results underscore the utility of the scaling lens, and provide a paradigm for evaluating future attacks and defenses on frontier models.Code for this project is available at https://github.com/AlignmentResearch/scaling-llm-robustness-paper. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "ps3aO9MHJv@OpenReview",
      "index": 168,
      "title": "Prediction models that learn to avoid missing values",
      "authors": [
        "Lena Stempfle",
        "Anton Matsson",
        "Newton Mwai",
        "Fredrik Johansson"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "missing",
        "missingness",
        "values",
        "interpretability",
        "reliance",
        "test",
        "models",
        "tree",
        "unregularized",
        "imputed"
      ],
      "summary": "Handling missing values at test time is challenging for machine learning models, especially when aiming for both high accuracy and interpretability. Established approaches often add bias through imputation or excessive model complexity via missingness indicators. Moreover, either method can obscure interpretability, making it harder to understand how the model utilizes the observed variables in predictions. We propose *missingness-avoiding* (MA) machine learning, a general framework for training models to rarely require the values of missing (or imputed) features at test time. We create tailored MA learning algorithms for decision trees, tree ensembles, and sparse linear models by incorporating classifier-specific regularization terms in their learning objectives. The tree-based models leverage contextual missingness by reducing reliance on missing values based on the observed context. Experiments on real-world datasets demonstrate that **MA-DT, MA-LASSO, MA-RF**, and **MA-GBT** effectively reduce the reliance on features with missing values while maintaining predictive performance competitive with their unregularized counterparts. This shows that our framework gives practitioners a powerful tool to maintain interpretability in predictions with test-time missing values.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=ps3aO9MHJv"
        ],
        "venue": [
          "/venue/ps3aO9MHJv@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=ps3aO9MHJv"
        ],
        "detail": [
          "https://openreview.net/forum?id=ps3aO9MHJv"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Prediction models that learn to avoid missing values [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Lena Stempfle , Anton Matsson , Newton Mwai , Fredrik Johansson Handling missing values at test time is challenging for machine learning models, especially when aiming for both high accuracy and interpretability. Established approaches often add bias through imputation or excessive model complexity via missingness indicators. Moreover, either method can obscure interpretability, making it harder to understand how the model utilizes the observed variables in predictions. We propose *missingness-avoiding* (MA) machine learning, a general framework for training models to rarely require the values of missing (or imputed) features at test time. We create tailored MA learning algorithms for decision trees, tree ensembles, and sparse linear models by incorporating classifier-specific regularization terms in their learning objectives. The tree-based models leverage contextual missingness by reducing reliance on missing values based on the observed context. Experiments on real-world datasets demonstrate that **MA-DT, MA-LASSO, MA-RF**, and **MA-GBT** effectively reduce the reliance on features with missing values while maintaining predictive performance competitive with their unregularized counterparts. This shows that our framework gives practitioners a powerful tool to maintain interpretability in predictions with test-time missing values. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "pyIXyl4qFx@OpenReview",
      "index": 169,
      "title": "G-Adaptivity: optimised graph-based mesh relocation for finite element methods",
      "authors": [
        "James Rowbottom",
        "Georg Maierhofer",
        "Teo Deveney",
        "Eike Müller",
        "Alberto Paganini",
        "Katharina Schratz",
        "Pietro Lió",
        "Carola-Bibiane Schönlieb",
        "Chris Budd"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "mesh",
        "adaptivity",
        "relocation",
        "meshing",
        "classical",
        "fems",
        "gnn",
        "solution",
        "methods",
        "element"
      ],
      "summary": "We present a novel, and effective, approach to achieve optimal mesh relocation in finite element methods (FEMs). The cost and accuracy of FEMs is critically dependent on the choice of mesh points. Mesh relocation (r-adaptivity) seeks to optimise the mesh geometry to obtain the best solution accuracy at given computational budget. Classical r-adaptivity relies on the solution of a separate nonlinear ``meshing'' PDE to determine mesh point locations. This incurs significant cost at remeshing, and relies on estimates that relate interpolation- and FEM-error. Recent machine learning approaches have focused on the construction of fast surrogates for such classical methods. Instead, our new approach trains a graph neural network (GNN) to determine mesh point locations by directly minimising the FE solution error from the PDE system Firedrake to achieve higher solution accuracy. Our GNN architecture closely aligns the mesh solution space to that of classical meshing methodologies, thus replacing classical estimates for optimality with a learnable strategy. This allows for rapid and robust training and results in an extremely efficient and effective GNN approach to online r-adaptivity. Our method outperforms both classical, and prior ML, approaches to r-adaptive meshing. In particular, it achieves lower FE solution error, whilst retaining the significant speed-up over classical methods observed in prior ML work.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=pyIXyl4qFx"
        ],
        "venue": [
          "/venue/pyIXyl4qFx@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=pyIXyl4qFx"
        ],
        "detail": [
          "https://openreview.net/forum?id=pyIXyl4qFx"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "G-Adaptivity: optimised graph-based mesh relocation for finite element methods [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : James Rowbottom , Georg Maierhofer , Teo Deveney , Eike Müller , Alberto Paganini , Katharina Schratz , Pietro Lió , Carola-Bibiane Schönlieb , Chris Budd We present a novel, and effective, approach to achieve optimal mesh relocation in finite element methods (FEMs). The cost and accuracy of FEMs is critically dependent on the choice of mesh points. Mesh relocation (r-adaptivity) seeks to optimise the mesh geometry to obtain the best solution accuracy at given computational budget. Classical r-adaptivity relies on the solution of a separate nonlinear ``meshing'' PDE to determine mesh point locations. This incurs significant cost at remeshing, and relies on estimates that relate interpolation- and FEM-error. Recent machine learning approaches have focused on the construction of fast surrogates for such classical methods. Instead, our new approach trains a graph neural network (GNN) to determine mesh point locations by directly minimising the FE solution error from the PDE system Firedrake to achieve higher solution accuracy. Our GNN architecture closely aligns the mesh solution space to that of classical meshing methodologies, thus replacing classical estimates for optimality with a learnable strategy. This allows for rapid and robust training and results in an extremely efficient and effective GNN approach to online r-adaptivity. Our method outperforms both classical, and prior ML, approaches to r-adaptive meshing. In particular, it achieves lower FE solution error, whilst retaining the significant speed-up over classical methods observed in prior ML work. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "qOgKMqv9T7@OpenReview",
      "index": 170,
      "title": "TIMING: Temporality-Aware Integrated Gradients for Time Series Explanation",
      "authors": [
        "Hyeongwon Jang",
        "Changhun Kim",
        "Eunho Yang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "timing",
        "xai",
        "series",
        "temporality",
        "gradients",
        "metrics",
        "attribution",
        "suboptimal",
        "integrated",
        "points"
      ],
      "summary": "Recent explainable artificial intelligence (XAI) methods for time series primarily estimate point-wise attribution magnitudes, while overlooking the directional impact on predictions, leading to suboptimal identification of significant points. Our analysis shows that conventional Integrated Gradients (IG) effectively capture critical points with both positive and negative impacts on predictions. However, current evaluation metrics fail to assess this capability, as they inadvertently cancel out opposing feature contributions. To address this limitation, we propose novel evaluation metrics—Cumulative Prediction Difference (CPD) and Cumulative Prediction Preservation(CPP)—to systematically assess whether attribution methods accurately identify significant positive and negative points in time series XAI. Under these metrics, conventional IG outperforms recent counterparts. However, directly applying IG to time series data may lead to suboptimal outcomes, as generated paths ignore temporal relationships and introduce out-of-distribution samples. To overcome these challenges, we introduce TIMING, which enhances IG by incorporating temporal awareness while maintaining its theoretical properties. Extensive experiments on synthetic and real-world time series benchmarks demonstrate that TIMING outperforms existing timeseries XAI baselines. Our code is available at https://github.com/drumpt/TIMING.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=qOgKMqv9T7"
        ],
        "venue": [
          "/venue/qOgKMqv9T7@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=qOgKMqv9T7"
        ],
        "detail": [
          "https://openreview.net/forum?id=qOgKMqv9T7"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "TIMING: Temporality-Aware Integrated Gradients for Time Series Explanation [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : Hyeongwon Jang , Changhun Kim , Eunho Yang Recent explainable artificial intelligence (XAI) methods for time series primarily estimate point-wise attribution magnitudes, while overlooking the directional impact on predictions, leading to suboptimal identification of significant points. Our analysis shows that conventional Integrated Gradients (IG) effectively capture critical points with both positive and negative impacts on predictions. However, current evaluation metrics fail to assess this capability, as they inadvertently cancel out opposing feature contributions. To address this limitation, we propose novel evaluation metrics—Cumulative Prediction Difference (CPD) and Cumulative Prediction Preservation(CPP)—to systematically assess whether attribution methods accurately identify significant positive and negative points in time series XAI. Under these metrics, conventional IG outperforms recent counterparts. However, directly applying IG to time series data may lead to suboptimal outcomes, as generated paths ignore temporal relationships and introduce out-of-distribution samples. To overcome these challenges, we introduce TIMING, which enhances IG by incorporating temporal awareness while maintaining its theoretical properties. Extensive experiments on synthetic and real-world time series benchmarks demonstrate that TIMING outperforms existing timeseries XAI baselines. Our code is available at https://github.com/drumpt/TIMING. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "qtuxDy2qEB@OpenReview",
      "index": 171,
      "title": "Parallel Simulation for Log-concave Sampling and Score-based Diffusion Models",
      "authors": [
        "Huanjian Zhou",
        "Masashi Sugiyama"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "log",
        "sampling",
        "parallel",
        "concave",
        "widetilde",
        "simulation",
        "reducing",
        "mathcal",
        "adaptive",
        "complexity"
      ],
      "summary": "Sampling from high-dimensional probability distributions is fundamental in machine learning and statistics. As datasets grow larger, computational efficiency becomes increasingly important, particularly in reducing *adaptive complexity*, namely the number of sequential rounds required for sampling algorithms. While recent works have introduced several parallelizable techniques, they often exhibit suboptimal convergence rates and remain significantly weaker than the latest lower bounds for log-concave sampling.To address this, we propose a novel parallel sampling method that improves adaptive complexity dependence on dimension d d reducing it from O ˜ ( log 2 d ) O ~ ( log 2 ⁡ d ) to O ˜ ( log d ) O ~ ( log ⁡ d ) . Our approach builds on parallel simulation techniques from scientific computing.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=qtuxDy2qEB"
        ],
        "venue": [
          "/venue/qtuxDy2qEB@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=qtuxDy2qEB"
        ],
        "detail": [
          "https://openreview.net/forum?id=qtuxDy2qEB"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Parallel Simulation for Log-concave Sampling and Score-based Diffusion Models [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Huanjian Zhou , Masashi Sugiyama Sampling from high-dimensional probability distributions is fundamental in machine learning and statistics. As datasets grow larger, computational efficiency becomes increasingly important, particularly in reducing *adaptive complexity*, namely the number of sequential rounds required for sampling algorithms. While recent works have introduced several parallelizable techniques, they often exhibit suboptimal convergence rates and remain significantly weaker than the latest lower bounds for log-concave sampling.To address this, we propose a novel parallel sampling method that improves adaptive complexity dependence on dimension d d reducing it from O ˜ ( log 2 d ) O ~ ( log 2 ⁡ d ) to O ˜ ( log d ) O ~ ( log ⁡ d ) . Our approach builds on parallel simulation techniques from scientific computing. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "r9HlTuCQfr@OpenReview",
      "index": 172,
      "title": "Decision Making under the Exponential Family: Distributionally Robust Optimisation with Bayesian Ambiguity Sets",
      "authors": [
        "Charita Dellaporta",
        "Patrick O&#x27;Hara",
        "Theodoros Damoulas"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "dro",
        "bas",
        "ambiguity",
        "posterior",
        "bayesian",
        "distributionally",
        "dgp",
        "optimisation",
        "uncertainty",
        "sets"
      ],
      "summary": "Decision making under uncertainty is challenging as the data-generating process (DGP) is often unknown. Bayesian inference proceeds by estimating the DGP through posterior beliefs on the model’s parameters. However, minimising the expected risk under these beliefs can lead to suboptimal decisions due to model uncertainty or limited, noisy observations. To address this, we introduce Distributionally Robust Optimisation with Bayesian Ambiguity Sets (DRO-BAS) which hedges against model uncertainty by optimising the worst-case risk over a posterior-informed ambiguity set. We provide two such sets, based on the posterior expectation (DRO-BAS(PE)) or the posterior predictive (DRO-BAS(PP)) and prove that both admit, under conditions, strong dual formulations leading to efficient single-stage stochastic programs which are solved with a sample average approximation. For DRO-BAS(PE), this covers all conjugate exponential family members while for DRO-BAS(PP) this is shown under conditions on the predictive's moment generating function. Our DRO-BAS formulations outperform existing Bayesian DRO on the Newsvendor problem and achieve faster solve times with comparable robustness on the Portfolio problem.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=r9HlTuCQfr"
        ],
        "venue": [
          "/venue/r9HlTuCQfr@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=r9HlTuCQfr"
        ],
        "detail": [
          "https://openreview.net/forum?id=r9HlTuCQfr"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Decision Making under the Exponential Family: Distributionally Robust Optimisation with Bayesian Ambiguity Sets [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Charita Dellaporta , Patrick O&#x27;Hara , Theodoros Damoulas Decision making under uncertainty is challenging as the data-generating process (DGP) is often unknown. Bayesian inference proceeds by estimating the DGP through posterior beliefs on the model’s parameters. However, minimising the expected risk under these beliefs can lead to suboptimal decisions due to model uncertainty or limited, noisy observations. To address this, we introduce Distributionally Robust Optimisation with Bayesian Ambiguity Sets (DRO-BAS) which hedges against model uncertainty by optimising the worst-case risk over a posterior-informed ambiguity set. We provide two such sets, based on the posterior expectation (DRO-BAS(PE)) or the posterior predictive (DRO-BAS(PP)) and prove that both admit, under conditions, strong dual formulations leading to efficient single-stage stochastic programs which are solved with a sample average approximation. For DRO-BAS(PE), this covers all conjugate exponential family members while for DRO-BAS(PP) this is shown under conditions on the predictive's moment generating function. Our DRO-BAS formulations outperform existing Bayesian DRO on the Newsvendor problem and achieve faster solve times with comparable robustness on the Portfolio problem. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "sDK6bSmHgM@OpenReview",
      "index": 173,
      "title": "FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields",
      "authors": [
        "Gwanhyeong Koo",
        "Sunjae Yoon",
        "Younghwan Lee",
        "Ji Woo Hong",
        "Chang Yoo"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "drag",
        "flowdrag",
        "editing",
        "mesh",
        "vfd",
        "edits",
        "dragbench",
        "deformation",
        "user",
        "truth"
      ],
      "summary": "Drag-based editing allows precise object manipulation through point-based control, offering user convenience. However, current methods often suffer from a geometric inconsistency problem by focusing exclusively on matching user-defined points, neglecting the broader geometry and leading to artifacts or unstable edits. We propose FlowDrag, which leverages geometric information for more accurate and coherent transformations. Our approach constructs a 3D mesh from the image, using an energy function to guide mesh deformation based on user-defined drag points. The resulting mesh displacements are projected into 2D and incorporated into a UNet denoising process, enabling precise handle-to-target point alignment while preserving structural integrity. Additionally, existing drag-editing benchmarks provide no ground truth, making it difficult to assess how accurately the edits match the intended transformations. To address this, we present VFD (VidFrameDrag) benchmark dataset, which provides ground-truth frames using consecutive shots in a video dataset. FlowDrag outperforms existing drag-based editing methods on both VFD Bench and DragBench.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=sDK6bSmHgM"
        ],
        "venue": [
          "/venue/sDK6bSmHgM@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=sDK6bSmHgM"
        ],
        "detail": [
          "https://openreview.net/forum?id=sDK6bSmHgM"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Gwanhyeong Koo , Sunjae Yoon , Younghwan Lee , Ji Woo Hong , Chang Yoo Drag-based editing allows precise object manipulation through point-based control, offering user convenience. However, current methods often suffer from a geometric inconsistency problem by focusing exclusively on matching user-defined points, neglecting the broader geometry and leading to artifacts or unstable edits. We propose FlowDrag, which leverages geometric information for more accurate and coherent transformations. Our approach constructs a 3D mesh from the image, using an energy function to guide mesh deformation based on user-defined drag points. The resulting mesh displacements are projected into 2D and incorporated into a UNet denoising process, enabling precise handle-to-target point alignment while preserving structural integrity. Additionally, existing drag-editing benchmarks provide no ground truth, making it difficult to assess how accurately the edits match the intended transformations. To address this, we present VFD (VidFrameDrag) benchmark dataset, which provides ground-truth frames using consecutive shots in a video dataset. FlowDrag outperforms existing drag-based editing methods on both VFD Bench and DragBench. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "sEBfiF8JBu@OpenReview",
      "index": 174,
      "title": "PANDAS: Improving Many-shot Jailbreaking via Positive Affirmation, Negative Demonstration, and Adaptive Sampling",
      "authors": [
        "Avery Ma",
        "Yangchen Pan",
        "Amir-massoud Farahmand"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "pandas",
        "jailbreaking",
        "shot",
        "affirmation",
        "fabricated",
        "exchanges",
        "harmful",
        "many",
        "affirmations",
        "prompt"
      ],
      "summary": "Many-shot jailbreaking circumvents the safety alignment of LLMs by exploiting their ability to process long input sequences. To achieve this, the malicious target prompt is prefixed with hundreds of fabricated conversational exchanges between the user and the model. These exchanges are randomly sampled from a pool of unsafe question-answer pairs, making it appear as though the model has already complied with harmful instructions. In this paper, we present PANDAS: a hybrid technique that improves many-shot jailbreaking by modifying these fabricated dialogues with Positive Affirmations, Negative Demonstrations, and an optimized Adaptive Sampling method tailored to the target prompt's topic. We also introduce ManyHarm, a dataset of harmful question–answer pairs, and demonstrate through extensive experiments that PANDAS significantly outperforms baseline methods in long-context scenarios. Through attention analysis, we provide insights into how long-context vulnerabilities are exploited and show how PANDAS further improves upon many-shot jailbreaking.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=sEBfiF8JBu"
        ],
        "venue": [
          "/venue/sEBfiF8JBu@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=sEBfiF8JBu"
        ],
        "detail": [
          "https://openreview.net/forum?id=sEBfiF8JBu"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 3
      },
      "raw_excerpt": "PANDAS: Improving Many-shot Jailbreaking via Positive Affirmation, Negative Demonstration, and Adaptive Sampling [PDF 1 ] [Copy] [Kimi 3 ] [REL] Authors : Avery Ma , Yangchen Pan , Amir-massoud Farahmand Many-shot jailbreaking circumvents the safety alignment of LLMs by exploiting their ability to process long input sequences. To achieve this, the malicious target prompt is prefixed with hundreds of fabricated conversational exchanges between the user and the model. These exchanges are randomly sampled from a pool of unsafe question-answer pairs, making it appear as though the model has already complied with harmful instructions. In this paper, we present PANDAS: a hybrid technique that improves many-shot jailbreaking by modifying these fabricated dialogues with Positive Affirmations, Negative Demonstrations, and an optimized Adaptive Sampling method tailored to the target prompt's topic. We also introduce ManyHarm, a dataset of harmful question–answer pairs, and demonstrate through extensive experiments that PANDAS significantly outperforms baseline methods in long-context scenarios. Through attention analysis, we provide insights into how long-context vulnerabilities are exploited and show how PANDAS further improves upon many-shot jailbreaking. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "sQS0roNQZR@OpenReview",
      "index": 175,
      "title": "From Language Models over Tokens to Language Models over Characters",
      "authors": [
        "Tim Vieira",
        "Benjamin LeBrun",
        "Mario Giulianelli",
        "Juan Luis Gastaldi",
        "Brian DuSell",
        "John Terilla",
        "Timothy O&#x27;Donnell",
        "Ryan Cotterell"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "language",
        "character",
        "token",
        "prompt",
        "models",
        "strings",
        "level",
        "tokenized",
        "approximate",
        "tokens"
      ],
      "summary": "Modern language models are internally—and mathematically—distributions over *token* strings rather than *character* strings, posing numerous challenges for programmers building user applications on top of them. For example, if a prompt is specified as a character string, it must be tokenized before passing it to the token-level language model. Thus, the tokenizer and consequent processing are very sensitive to the specification of the prompt (e.g., whether the prompt ends with a space or not). This paper presents algorithms for converting token-level language models to character-level ones. We present both exact and approximate algorithms. In the empirical portion of the paper, we benchmark the practical runtime and approximation quality. Across four publicly available language models, we find that—even with a small computation budget—our method is able to accurately approximate the character-level distribution at reasonably fast speeds, and that a significant improvement in the language model's compression rate (bits/byte) is achieved.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=sQS0roNQZR"
        ],
        "venue": [
          "/venue/sQS0roNQZR@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=sQS0roNQZR"
        ],
        "detail": [
          "https://openreview.net/forum?id=sQS0roNQZR"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "From Language Models over Tokens to Language Models over Characters [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : Tim Vieira , Benjamin LeBrun , Mario Giulianelli , Juan Luis Gastaldi , Brian DuSell , John Terilla , Timothy O&#x27;Donnell , Ryan Cotterell Modern language models are internally—and mathematically—distributions over *token* strings rather than *character* strings, posing numerous challenges for programmers building user applications on top of them. For example, if a prompt is specified as a character string, it must be tokenized before passing it to the token-level language model. Thus, the tokenizer and consequent processing are very sensitive to the specification of the prompt (e.g., whether the prompt ends with a space or not). This paper presents algorithms for converting token-level language models to character-level ones. We present both exact and approximate algorithms. In the empirical portion of the paper, we benchmark the practical runtime and approximation quality. Across four publicly available language models, we find that—even with a small computation budget—our method is able to accurately approximate the character-level distribution at reasonably fast speeds, and that a significant improvement in the language model's compression rate (bits/byte) is achieved. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "teUg2pMrF0@OpenReview",
      "index": 176,
      "title": "Large Language Model-driven Large Neighborhood Search for Large-Scale MILP Problems",
      "authors": [
        "Huigen Ye",
        "Hua Xu",
        "An Yan",
        "Yaoyang Cheng"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "lns",
        "milp",
        "neighborhood",
        "llm",
        "large",
        "scale",
        "strategies",
        "layer",
        "milpopt",
        "search"
      ],
      "summary": "Large Neighborhood Search (LNS) is a widely used method for solving large-scale Mixed Integer Linear Programming (MILP) problems. The effectiveness of LNS crucially depends on the choice of the search neighborhood. However, existing strategies either rely on expert knowledge or computationally expensive Machine Learning (ML) approaches, both of which struggle to scale effectively for large problems. To address this, we propose LLM-LNS, a novel Large Language Model (LLM)-driven LNS framework for large-scale MILP problems. Our approach introduces a dual-layer self-evolutionary LLM agent to automate neighborhood selection, discovering effective strategies with scant small-scale training data that generalize well to large-scale MILPs. The inner layer evolves heuristic strategies to ensure convergence, while the outer layer evolves evolutionary prompt strategies to maintain diversity. Experimental results demonstrate that the proposed dual-layer agent outperforms state-of-the-art agents such as FunSearch and EOH. Furthermore, the full LLM-LNS framework surpasses manually designed LNS algorithms like ACP, ML-based LNS methods like CL-LNS, and large-scale solvers such as Gurobi and SCIP. It also achieves superior performance compared to advanced ML-based MILP optimization frameworks like GNN&GBDT and Light-MILPopt, further validating the effectiveness of our approach.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=teUg2pMrF0"
        ],
        "venue": [
          "/venue/teUg2pMrF0@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=teUg2pMrF0"
        ],
        "detail": [
          "https://openreview.net/forum?id=teUg2pMrF0"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Large Language Model-driven Large Neighborhood Search for Large-Scale MILP Problems [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Huigen Ye , Hua Xu , An Yan , Yaoyang Cheng Large Neighborhood Search (LNS) is a widely used method for solving large-scale Mixed Integer Linear Programming (MILP) problems. The effectiveness of LNS crucially depends on the choice of the search neighborhood. However, existing strategies either rely on expert knowledge or computationally expensive Machine Learning (ML) approaches, both of which struggle to scale effectively for large problems. To address this, we propose LLM-LNS, a novel Large Language Model (LLM)-driven LNS framework for large-scale MILP problems. Our approach introduces a dual-layer self-evolutionary LLM agent to automate neighborhood selection, discovering effective strategies with scant small-scale training data that generalize well to large-scale MILPs. The inner layer evolves heuristic strategies to ensure convergence, while the outer layer evolves evolutionary prompt strategies to maintain diversity. Experimental results demonstrate that the proposed dual-layer agent outperforms state-of-the-art agents such as FunSearch and EOH. Furthermore, the full LLM-LNS framework surpasses manually designed LNS algorithms like ACP, ML-based LNS methods like CL-LNS, and large-scale solvers such as Gurobi and SCIP. It also achieves superior performance compared to advanced ML-based MILP optimization frameworks like GNN&GBDT and Light-MILPopt, further validating the effectiveness of our approach. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "tnyxtaSve5@OpenReview",
      "index": 177,
      "title": "Visual and Domain Knowledge for Professional-level Graph-of-Thought Medical Reasoning",
      "authors": [
        "Rina Bao",
        "Shilong Dong",
        "Zhenfang Chen",
        "Sheng He",
        "Patricia Ellen Grant",
        "Yangming Ou"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "medical",
        "clinical",
        "mvqa",
        "neurocognitive",
        "lvlms",
        "professional",
        "reasoning",
        "benchmark",
        "questions",
        "visual"
      ],
      "summary": "Medical Visual Question Answering (MVQA) requires AI models to answer questions related to medical images, offering significant potential to assist medical professionals in evaluating and diagnosing diseases, thereby improving early interventions. However, existing MVQA datasets primarily focus on basic questions regarding visual perception and pattern recognition, without addressing the more complex questions that are critical in clinical diagnosis and decision-making. This paper introduces a new benchmark designed for professional-level medical reasoning, simulating the decision-making process. We achieve this by collecting MRI and clinical data related to Hypoxic-Ischemic Encephalopathy, enriched with expert annotations and insights. Building on this data, we generate clinical question-answer pairs and MRI interpretations to enable comprehensive diagnosis, interpretation, and prediction of neurocognitive outcomes. Our evaluation of current large vision-language models (LVLMs) shows limited performance on this benchmark, highlighting both the challenges of the task and the importance of this benchmark for advancing medical AI. Furthermore, we propose a novel ``Clinical Graph of Thoughts\" model, which integrates domain-specific medical knowledge and clinical reasoning processes with the interpretive abilities of LVLMs. The model demonstrates promising results, achieving around 15\\% absolute gain on the most important neurocognitive outcome task, while the benchmark still reveals substantial opportunities for further research innovation.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=tnyxtaSve5"
        ],
        "venue": [
          "/venue/tnyxtaSve5@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=tnyxtaSve5"
        ],
        "detail": [
          "https://openreview.net/forum?id=tnyxtaSve5"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 1
      },
      "raw_excerpt": "Visual and Domain Knowledge for Professional-level Graph-of-Thought Medical Reasoning [PDF 4 ] [Copy] [Kimi 1 ] [REL] Authors : Rina Bao , Shilong Dong , Zhenfang Chen , Sheng He , Patricia Ellen Grant , Yangming Ou Medical Visual Question Answering (MVQA) requires AI models to answer questions related to medical images, offering significant potential to assist medical professionals in evaluating and diagnosing diseases, thereby improving early interventions. However, existing MVQA datasets primarily focus on basic questions regarding visual perception and pattern recognition, without addressing the more complex questions that are critical in clinical diagnosis and decision-making. This paper introduces a new benchmark designed for professional-level medical reasoning, simulating the decision-making process. We achieve this by collecting MRI and clinical data related to Hypoxic-Ischemic Encephalopathy, enriched with expert annotations and insights. Building on this data, we generate clinical question-answer pairs and MRI interpretations to enable comprehensive diagnosis, interpretation, and prediction of neurocognitive outcomes. Our evaluation of current large vision-language models (LVLMs) shows limited performance on this benchmark, highlighting both the challenges of the task and the importance of this benchmark for advancing medical AI. Furthermore, we propose a novel ``Clinical Graph of Thoughts\" model, which integrates domain-specific medical knowledge and clinical reasoning processes with the interpretive abilities of LVLMs. The model demonstrates promising results, achieving around 15\\% absolute gain on the most important neurocognitive outcome task, while the benchmark still reveals substantial opportunities for further research innovation. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "tqL8gJsuS5@OpenReview",
      "index": 178,
      "title": "Efficient Source-free Unlearning via Energy-Guided Data Synthesis and Discrimination-Aware Multitask Optimization",
      "authors": [
        "Xiuyuan Wang",
        "Chaochao Chen",
        "Weiming Liu",
        "Xinting Liao",
        "Fan Wang",
        "Xiaolin Zheng"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "unlearning",
        "dsda",
        "source",
        "data",
        "discrimination",
        "multitask",
        "synthesis",
        "aware",
        "free",
        "retain"
      ],
      "summary": "With growing privacy concerns and the enforcement of data protection regulations, machine unlearning has emerged as a promising approach for removing the influence of forget data while maintaining model performance on retain data. However, most existing unlearning methods require access to the original training data, which is often impractical due to privacy policies, storage constraints, and other limitations. This gives rise to the challenging task of source-free unlearning, where unlearning must be accomplished without accessing the original training data. Few existing source-free unlearning methods rely on knowledge distillation and model retraining, which impose substantial computational costs. In this work, we propose the Data Synthesis-based Discrimination-Aware (DSDA) unlearning framework, which enables efficient source-free unlearning in two stages: (1) Accelerated Energy-Guided Data Synthesis (AEGDS), which employs Langevin dynamics to model the training data distribution while integrating Runge–Kutta methods and momentum to enhance efficiency. (2) Discrimination-Aware Multitask Optimization (DAMO), which refines the feature distribution of retain data and mitigates the gradient conflicts among multiple unlearning objectives. Extensive experiments on three benchmark datasets demonstrate that DSDA outperforms existing unlearning methods, validating its effectiveness and efficiency in source-free unlearning.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=tqL8gJsuS5"
        ],
        "venue": [
          "/venue/tqL8gJsuS5@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=tqL8gJsuS5"
        ],
        "detail": [
          "https://openreview.net/forum?id=tqL8gJsuS5"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "Efficient Source-free Unlearning via Energy-Guided Data Synthesis and Discrimination-Aware Multitask Optimization [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : Xiuyuan Wang , Chaochao Chen , Weiming Liu , Xinting Liao , Fan Wang , Xiaolin Zheng With growing privacy concerns and the enforcement of data protection regulations, machine unlearning has emerged as a promising approach for removing the influence of forget data while maintaining model performance on retain data. However, most existing unlearning methods require access to the original training data, which is often impractical due to privacy policies, storage constraints, and other limitations. This gives rise to the challenging task of source-free unlearning, where unlearning must be accomplished without accessing the original training data. Few existing source-free unlearning methods rely on knowledge distillation and model retraining, which impose substantial computational costs. In this work, we propose the Data Synthesis-based Discrimination-Aware (DSDA) unlearning framework, which enables efficient source-free unlearning in two stages: (1) Accelerated Energy-Guided Data Synthesis (AEGDS), which employs Langevin dynamics to model the training data distribution while integrating Runge–Kutta methods and momentum to enhance efficiency. (2) Discrimination-Aware Multitask Optimization (DAMO), which refines the feature distribution of retain data and mitigates the gradient conflicts among multiple unlearning objectives. Extensive experiments on three benchmark datasets demonstrate that DSDA outperforms existing unlearning methods, validating its effectiveness and efficiency in source-free unlearning. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "u3n5wuRGTa@OpenReview",
      "index": 179,
      "title": "Discovering a Zero (Zero-Vector Class of Machine Learning)",
      "authors": [
        "Harikrishna Metta",
        "Venkatesh Babu Radhakrishnan"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "metta",
        "classes",
        "class",
        "learning",
        "vector",
        "zero",
        "application",
        "discovering",
        "machine",
        "corresponds"
      ],
      "summary": "In Machine learning, separating data into classes is a very fundamental problem. A mathematical framework around the classes is presented in this work to deepen the understanding of classes. The classes are defined as vectors in a Vector Space, where addition corresponds to the union of classes, and scalar multiplication resembles set complement of classes. The Zero-Vector in the vector space corresponds to a class referred to as the Metta-Class. This discovery enables numerous applications. One such application, termed 'clear learning' in this work, focuses on learning the true nature (manifold) of the data instead of merely learning a boundary sufficient for classification. Another application, called 'unary class learning', involves learning a single class in isolation rather than learning by comparing two or more classes. Additionally, 'set operations on classes' is another application highlighted in this work. Furthermore, Continual Learning of classes is facilitated by smaller networks. The Metta-Class enables neural networks to learn only the data manifold; therefore, it can also be used for generation of new data. Results for the key applications are shown using the MNIST dataset. To further strengthen the claims, some results are also produced using the CIFAR-10 and ImageNet-1k embeddings. The code supporting these applications is publicly available at: github.com/hm-4/Metta-Class.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=u3n5wuRGTa"
        ],
        "venue": [
          "/venue/u3n5wuRGTa@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=u3n5wuRGTa"
        ],
        "detail": [
          "https://openreview.net/forum?id=u3n5wuRGTa"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 4
      },
      "raw_excerpt": "Discovering a Zero (Zero-Vector Class of Machine Learning) [PDF 4 ] [Copy] [Kimi 4 ] [REL] Authors : Harikrishna Metta , Venkatesh Babu Radhakrishnan In Machine learning, separating data into classes is a very fundamental problem. A mathematical framework around the classes is presented in this work to deepen the understanding of classes. The classes are defined as vectors in a Vector Space, where addition corresponds to the union of classes, and scalar multiplication resembles set complement of classes. The Zero-Vector in the vector space corresponds to a class referred to as the Metta-Class. This discovery enables numerous applications. One such application, termed 'clear learning' in this work, focuses on learning the true nature (manifold) of the data instead of merely learning a boundary sufficient for classification. Another application, called 'unary class learning', involves learning a single class in isolation rather than learning by comparing two or more classes. Additionally, 'set operations on classes' is another application highlighted in this work. Furthermore, Continual Learning of classes is facilitated by smaller networks. The Metta-Class enables neural networks to learn only the data manifold; therefore, it can also be used for generation of new data. Results for the key applications are shown using the MNIST dataset. To further strengthen the claims, some results are also produced using the CIFAR-10 and ImageNet-1k embeddings. The code supporting these applications is publicly available at: github.com/hm-4/Metta-Class. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "u6xeKVHS6K@OpenReview",
      "index": 180,
      "title": "GMAIL: Generative Modality Alignment for generated Image Learning",
      "authors": [
        "Shentong Mo",
        "Sukmin Yun"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "generated",
        "images",
        "gmail",
        "modality",
        "generative",
        "image",
        "vision",
        "captioning",
        "alignment",
        "real"
      ],
      "summary": "Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can even cause mode collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined \\textit{GMAIL}, that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the pixel space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach. To be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image learning across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=u6xeKVHS6K"
        ],
        "venue": [
          "/venue/u6xeKVHS6K@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=u6xeKVHS6K"
        ],
        "detail": [
          "https://openreview.net/forum?id=u6xeKVHS6K"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 2
      },
      "raw_excerpt": "GMAIL: Generative Modality Alignment for generated Image Learning [PDF 1 ] [Copy] [Kimi 2 ] [REL] Authors : Shentong Mo , Sukmin Yun Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can even cause mode collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined \\textit{GMAIL}, that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the pixel space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach. To be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image learning across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "uqCfoVXb67@OpenReview",
      "index": 181,
      "title": "UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control",
      "authors": [
        "Kaizhen Zhu",
        "Mokai Pan",
        "Yuexin Ma",
        "Yanwei Fu",
        "Jingyi Yu",
        "Jingya Wang",
        "Ye Shi"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "unidb",
        "soc",
        "bridge",
        "diffusion",
        "terminal",
        "doob",
        "control",
        "restoration",
        "bridges",
        "framework"
      ],
      "summary": "Recent advances in diffusion bridge models leverage Doob’s h h -transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches frequently produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified framework for diffusion bridges based on Stochastic Optimal Control (SOC). UniDB formulates the problem through an SOC-based optimization and derives a closed-form solution for the optimal controller, thereby unifying and generalizing existing diffusion bridge models. We demonstrate that existing diffusion bridges employing Doob’s h h -transform constitute a special case of our framework, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. Notably, UniDB seamlessly integrates with existing diffusion bridge models, requiring only minimal code modifications. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework. Our code is available at https://github.com/UniDB-SOC/UniDB/.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=uqCfoVXb67"
        ],
        "venue": [
          "/venue/uqCfoVXb67@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=uqCfoVXb67"
        ],
        "detail": [
          "https://openreview.net/forum?id=uqCfoVXb67"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : Kaizhen Zhu , Mokai Pan , Yuexin Ma , Yanwei Fu , Jingyi Yu , Jingya Wang , Ye Shi Recent advances in diffusion bridge models leverage Doob’s h h -transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches frequently produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified framework for diffusion bridges based on Stochastic Optimal Control (SOC). UniDB formulates the problem through an SOC-based optimization and derives a closed-form solution for the optimal controller, thereby unifying and generalizing existing diffusion bridge models. We demonstrate that existing diffusion bridges employing Doob’s h h -transform constitute a special case of our framework, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. Notably, UniDB seamlessly integrates with existing diffusion bridge models, requiring only minimal code modifications. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework. Our code is available at https://github.com/UniDB-SOC/UniDB/. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "v4DWXM93VV@OpenReview",
      "index": 182,
      "title": "Convergence of Mean-Field Langevin Stochastic Descent-Ascent for Distributional Minimax Optimization",
      "authors": [
        "Zhangyi Liu",
        "Feng Liu",
        "Rui Gao",
        "Shuang Li"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "mfl",
        "distributional",
        "sda",
        "langevin",
        "minimax",
        "convergence",
        "descent",
        "ascent",
        "rate",
        "mean"
      ],
      "summary": "We study convergence properties of the discrete-time Mean-Field Langevin Stochastic Descent-Ascent (MFL-SDA) algorithm for solving distributional minimax optimization. These problems arise in various applications, such as zero-sum games, generative adversarial networks and distributionally robust learning. Despite the significance of MFL-SDA in these contexts, the discrete-time convergence rate remains underexplored.To address this gap, we establish a last-iterate convergence rate of O ( 1 ϵ log 1 ϵ ) O ( 1 ϵ log ⁡ 1 ϵ ) for MFL-SDA. This rate is nearly optimal when compared to the complexity lower bound of its Euclidean counterpart. This rate also matches the complexity of mean-field Langevin stochastic gradient descent for distributional minimization and the outer-loop iteration complexity of an existing double-loop algorithm for distributional minimax problems.By leveraging an elementary analysis framework that avoids PDE-based techniques, we overcome previous limitations and achieve a faster convergence rate.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=v4DWXM93VV"
        ],
        "venue": [
          "/venue/v4DWXM93VV@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=v4DWXM93VV"
        ],
        "detail": [
          "https://openreview.net/forum?id=v4DWXM93VV"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 2
      },
      "raw_excerpt": "Convergence of Mean-Field Langevin Stochastic Descent-Ascent for Distributional Minimax Optimization [PDF 2 ] [Copy] [Kimi 2 ] [REL] Authors : Zhangyi Liu , Feng Liu , Rui Gao , Shuang Li We study convergence properties of the discrete-time Mean-Field Langevin Stochastic Descent-Ascent (MFL-SDA) algorithm for solving distributional minimax optimization. These problems arise in various applications, such as zero-sum games, generative adversarial networks and distributionally robust learning. Despite the significance of MFL-SDA in these contexts, the discrete-time convergence rate remains underexplored.To address this gap, we establish a last-iterate convergence rate of O ( 1 ϵ log 1 ϵ ) O ( 1 ϵ log ⁡ 1 ϵ ) for MFL-SDA. This rate is nearly optimal when compared to the complexity lower bound of its Euclidean counterpart. This rate also matches the complexity of mean-field Langevin stochastic gradient descent for distributional minimization and the outer-loop iteration complexity of an existing double-loop algorithm for distributional minimax problems.By leveraging an elementary analysis framework that avoids PDE-based techniques, we overcome previous limitations and achieve a faster convergence rate. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "vOdz3zhSCj@OpenReview",
      "index": 183,
      "title": "Neural Encoding and Decoding at Scale",
      "authors": [
        "Yizi Zhang",
        "Yanchen Wang",
        "Mehdi Azabou",
        "Alexandre Andre",
        "Zixuan Wang",
        "Hanrui Lyu",
        "International Brain Laboratory",
        "Eva Dyer",
        "Department of Statistics Liam Paninski",
        "Cole Hurwitz"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "neds",
        "decoding",
        "neural",
        "activity",
        "encoding",
        "behavior",
        "brain",
        "scale",
        "animals",
        "animal"
      ],
      "summary": "Recent work has demonstrated that large-scale, multi-animal models are powerful tools for characterizing the relationship between neural activity and behavior. Current large-scale approaches, however, focus exclusively on either predicting neural activity from behavior (encoding) or predicting behavior from neural activity (decoding), limiting their ability to capture the bidirectional relationship between neural activity and behavior. To bridge this gap, we introduce a multimodal, multi-task model that enables simultaneous Neural Encoding and Decoding at Scale (NEDS). Central to our approach is a novel multi-task-masking strategy, which alternates between neural, behavioral, within-modality, and cross-modality masking. We pretrain our method on the International Brain Laboratory (IBL) repeated site dataset, which includes recordings from 83 animals performing the visual decision-making task. In comparison to other large-scale modeling approaches, we demonstrate that NEDS achieves state-of-the-art performance for both encoding and decoding when pretrained on multi-animal data and then fine-tuned on new animals. Surprisingly, NEDS's learned embeddings exhibit emergent properties: even without explicit training, they are highly predictive of the brain regions in each recording. Altogether, our approach is a step towards a foundation model of the brain that enables seamless translation between neural activity and behavior.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=vOdz3zhSCj"
        ],
        "venue": [
          "/venue/vOdz3zhSCj@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=vOdz3zhSCj"
        ],
        "detail": [
          "https://openreview.net/forum?id=vOdz3zhSCj"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 3
      },
      "raw_excerpt": "Neural Encoding and Decoding at Scale [PDF 3 ] [Copy] [Kimi 3 ] [REL] Authors : Yizi Zhang , Yanchen Wang , Mehdi Azabou , Alexandre Andre , Zixuan Wang , Hanrui Lyu , International Brain Laboratory , Eva Dyer , Department of Statistics Liam Paninski , Cole Hurwitz Recent work has demonstrated that large-scale, multi-animal models are powerful tools for characterizing the relationship between neural activity and behavior. Current large-scale approaches, however, focus exclusively on either predicting neural activity from behavior (encoding) or predicting behavior from neural activity (decoding), limiting their ability to capture the bidirectional relationship between neural activity and behavior. To bridge this gap, we introduce a multimodal, multi-task model that enables simultaneous Neural Encoding and Decoding at Scale (NEDS). Central to our approach is a novel multi-task-masking strategy, which alternates between neural, behavioral, within-modality, and cross-modality masking. We pretrain our method on the International Brain Laboratory (IBL) repeated site dataset, which includes recordings from 83 animals performing the visual decision-making task. In comparison to other large-scale modeling approaches, we demonstrate that NEDS achieves state-of-the-art performance for both encoding and decoding when pretrained on multi-animal data and then fine-tuned on new animals. Surprisingly, NEDS's learned embeddings exhibit emergent properties: even without explicit training, they are highly predictive of the brain regions in each recording. Altogether, our approach is a step towards a foundation model of the brain that enables seamless translation between neural activity and behavior. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "vhACnRfuYh@OpenReview",
      "index": 184,
      "title": "Latent Diffusion Planning for Imitation Learning",
      "authors": [
        "Amber Xie",
        "Oleh Rybkin",
        "Dorsa Sadigh",
        "Chelsea Finn"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "ldp",
        "imitation",
        "latent",
        "planning",
        "leverage",
        "diffusion",
        "demonstrations",
        "planner",
        "suboptimal",
        "action"
      ],
      "summary": "Recent progress in imitation learning has been enabled by policy architectures that scale to complex visuomotor tasks, multimodal distributions, and large datasets. However, these methods often rely on learning from large amount of expert demonstrations.To address these shortcomings, we propose Latent Diffusion Planning (LDP), a modular approach consisting of a planner which can leverage action-free demonstrations, and an inverse dynamics model which can leverage suboptimal data, that both operate over a learned latent space. First, we learn a compact latent space through a variational autoencoder, enabling effective forecasting of future states in image-based domains. Then, we train a planner and an inverse dynamics model with diffusion objectives. By separating planning from action prediction, LDP can benefit from the denser supervision signals of suboptimal and action-free data.On simulated visual robotic manipulation tasks, LDP outperforms state-of-the-art imitation learning approaches, as they cannot leverage such additional data.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=vhACnRfuYh"
        ],
        "venue": [
          "/venue/vhACnRfuYh@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=vhACnRfuYh"
        ],
        "detail": [
          "https://openreview.net/forum?id=vhACnRfuYh"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 3
      },
      "raw_excerpt": "Latent Diffusion Planning for Imitation Learning [PDF 5 ] [Copy] [Kimi 3 ] [REL] Authors : Amber Xie , Oleh Rybkin , Dorsa Sadigh , Chelsea Finn Recent progress in imitation learning has been enabled by policy architectures that scale to complex visuomotor tasks, multimodal distributions, and large datasets. However, these methods often rely on learning from large amount of expert demonstrations.To address these shortcomings, we propose Latent Diffusion Planning (LDP), a modular approach consisting of a planner which can leverage action-free demonstrations, and an inverse dynamics model which can leverage suboptimal data, that both operate over a learned latent space. First, we learn a compact latent space through a variational autoencoder, enabling effective forecasting of future states in image-based domains. Then, we train a planner and an inverse dynamics model with diffusion objectives. By separating planning from action prediction, LDP can benefit from the denser supervision signals of suboptimal and action-free data.On simulated visual robotic manipulation tasks, LDP outperforms state-of-the-art imitation learning approaches, as they cannot leverage such additional data. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "w0xYx9CJhY@OpenReview",
      "index": 185,
      "title": "Mitigating Object Hallucination in Large Vision-Language Models via Image-Grounded Guidance",
      "authors": [
        "Linxi Zhao",
        "Yihe Deng",
        "Weitong Zhang",
        "Quanquan Gu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "lvlms",
        "marine",
        "guidance",
        "grounded",
        "vision",
        "hallucination",
        "object",
        "hallucinations",
        "mitigating",
        "api"
      ],
      "summary": "The advancement of Large Vision-Language Models (LVLMs) has increasingly highlighted the critical issue of their tendency to hallucinate non-existing objects in the images. To address this issue, previous works focused on using specially curated datasets or powerful LLMs to rectify the outputs of LVLMs. However, these approaches require either costly training or fine-tuning, or API access to proprietary LLMs for post-generation correction. In response to these limitations, we propose Mitigating hallucinAtion via image-gRounded guIdaNcE (MARINE), a framework that is both training-free and API-free. MARINE effectively and efficiently reduces object hallucinations during inference by introducing image-grounded guidance to LVLMs. This is achieved by leveraging open-source vision models to extract object-level information, thereby enhancing the precision of LVLM-generated content. Our framework's flexibility further allows for the integration of multiple vision models, enabling more reliable and robust object-level guidance. Through comprehensive evaluations across 5 popular LVLMs with diverse evaluation metrics and benchmarks, we demonstrate the effectiveness of MARINE, which even outperforms existing fine-tuning-based methods. Remarkably, it reduces hallucinations consistently in GPT-4V-assisted evaluation while maintaining the detailedness of LVLMs' generations. We release our code at https://github.com/Linxi-ZHAO/MARINE.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=w0xYx9CJhY"
        ],
        "venue": [
          "/venue/w0xYx9CJhY@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=w0xYx9CJhY"
        ],
        "detail": [
          "https://openreview.net/forum?id=w0xYx9CJhY"
        ]
      },
      "scores": {
        "pdf": 8,
        "kimi": 5
      },
      "raw_excerpt": "Mitigating Object Hallucination in Large Vision-Language Models via Image-Grounded Guidance [PDF 8 ] [Copy] [Kimi 5 ] [REL] Authors : Linxi Zhao , Yihe Deng , Weitong Zhang , Quanquan Gu The advancement of Large Vision-Language Models (LVLMs) has increasingly highlighted the critical issue of their tendency to hallucinate non-existing objects in the images. To address this issue, previous works focused on using specially curated datasets or powerful LLMs to rectify the outputs of LVLMs. However, these approaches require either costly training or fine-tuning, or API access to proprietary LLMs for post-generation correction. In response to these limitations, we propose Mitigating hallucinAtion via image-gRounded guIdaNcE (MARINE), a framework that is both training-free and API-free. MARINE effectively and efficiently reduces object hallucinations during inference by introducing image-grounded guidance to LVLMs. This is achieved by leveraging open-source vision models to extract object-level information, thereby enhancing the precision of LVLM-generated content. Our framework's flexibility further allows for the integration of multiple vision models, enabling more reliable and robust object-level guidance. Through comprehensive evaluations across 5 popular LVLMs with diverse evaluation metrics and benchmarks, we demonstrate the effectiveness of MARINE, which even outperforms existing fine-tuning-based methods. Remarkably, it reduces hallucinations consistently in GPT-4V-assisted evaluation while maintaining the detailedness of LVLMs' generations. We release our code at https://github.com/Linxi-ZHAO/MARINE. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "wBJIO15pBV@OpenReview",
      "index": 186,
      "title": "Beyond the Permutation Symmetry of Transformers: The Role of Rotation for Model Fusion",
      "authors": [
        "Binchi Zhang",
        "Zaiyi Zheng",
        "Zhengzhang Chen",
        "Jundong Li"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "symmetry",
        "permutation",
        "transformers",
        "rotation",
        "fusion",
        "mlps",
        "parameter",
        "model",
        "permuting",
        "matrices"
      ],
      "summary": "Symmetry in the parameter space of deep neural networks (DNNs) has proven beneficial for various deep learning applications. A well-known example is the permutation symmetry in Multi-Layer Perceptrons (MLPs), where permuting the rows of weight matrices in one layer and applying the inverse permutation to adjacent layers yields a functionally equivalent model. While permutation symmetry fully characterizes the equivalence set for MLPs, its discrete nature limits its utility for transformers. In this paper, we introduce rotation symmetry, a novel form of parameter space symmetry for transformers that generalizes permutation symmetry by rotating parameter matrices in self-attention layers. Unlike permutation symmetry, rotation symmetry operates in a continuous domain, thereby significantly expanding the equivalence set for transformers. Based on this property, we propose a theoretically optimal parameter matching algorithm as a plug-and-play module to enhance model fusion. We evaluate our approach using pre-trained transformers across diverse natural language and vision tasks. Experimental results demonstrate that our rotation symmetry-based matching algorithm substantially improves model fusion, highlighting the potential of parameter space symmetry to facilitate model fusion. Our code is available on https://github.com/zhengzaiyi/RotationSymmetry",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=wBJIO15pBV"
        ],
        "venue": [
          "/venue/wBJIO15pBV@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=wBJIO15pBV"
        ],
        "detail": [
          "https://openreview.net/forum?id=wBJIO15pBV"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 1
      },
      "raw_excerpt": "Beyond the Permutation Symmetry of Transformers: The Role of Rotation for Model Fusion [PDF 4 ] [Copy] [Kimi 1 ] [REL] Authors : Binchi Zhang , Zaiyi Zheng , Zhengzhang Chen , Jundong Li Symmetry in the parameter space of deep neural networks (DNNs) has proven beneficial for various deep learning applications. A well-known example is the permutation symmetry in Multi-Layer Perceptrons (MLPs), where permuting the rows of weight matrices in one layer and applying the inverse permutation to adjacent layers yields a functionally equivalent model. While permutation symmetry fully characterizes the equivalence set for MLPs, its discrete nature limits its utility for transformers. In this paper, we introduce rotation symmetry, a novel form of parameter space symmetry for transformers that generalizes permutation symmetry by rotating parameter matrices in self-attention layers. Unlike permutation symmetry, rotation symmetry operates in a continuous domain, thereby significantly expanding the equivalence set for transformers. Based on this property, we propose a theoretically optimal parameter matching algorithm as a plug-and-play module to enhance model fusion. We evaluate our approach using pre-trained transformers across diverse natural language and vision tasks. Experimental results demonstrate that our rotation symmetry-based matching algorithm substantially improves model fusion, highlighting the potential of parameter space symmetry to facilitate model fusion. Our code is available on https://github.com/zhengzaiyi/RotationSymmetry Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "wXfuOj9C7L@OpenReview",
      "index": 187,
      "title": "Learning to (Learn at Test Time): RNNs with Expressive Hidden States",
      "authors": [
        "Yu Sun",
        "Xinhao Li",
        "Karan Dalal",
        "Jiarui Xu",
        "Arjun Vikram",
        "Genghan Zhang",
        "Yann Dubois",
        "Xinlei Chen",
        "Xiaolong Wang",
        "Sanmi Koyejo",
        "Tatsunori Hashimoto",
        "Carlos Guestrin"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "ttt",
        "hidden",
        "mlp",
        "expressive",
        "layers",
        "instantiations",
        "mamba",
        "context",
        "linear",
        "test"
      ],
      "summary": "Self-attention performs well in long context but has quadratic complexity. Existing RNN layers have linear complexity, but their performance in long context is limited by the expressive power of their hidden states. We present a practical framework for instantiating sequence modeling layers with linear complexity and expressive hidden states. The key idea is to make the hidden state a machine learning model itself, and the update rule a step of self-supervised learning. Since the hidden state is updated by training even on test sequences, our layers are called Test-Time Training (TTT) layers. We consider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a linear model and a two-layer MLP respectively. We evaluate our instantiations at the scale of 125M to 1.3B parameters, comparing with a strong Transformer and Mamba, a modern RNN. Similar to Transformer, TTT-Linear and TTT-MLP can keep reducing perplexity by conditioning on more tokens, while Mamba cannot after 16k context. TTT-MLP still faces challenges in memory I/O, but shows larger potential in long context, pointing to a promising direction for future research.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=wXfuOj9C7L"
        ],
        "venue": [
          "/venue/wXfuOj9C7L@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=wXfuOj9C7L"
        ],
        "detail": [
          "https://openreview.net/forum?id=wXfuOj9C7L"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 4
      },
      "raw_excerpt": "Learning to (Learn at Test Time): RNNs with Expressive Hidden States [PDF 3 ] [Copy] [Kimi 4 ] [REL] Authors : Yu Sun , Xinhao Li , Karan Dalal , Jiarui Xu , Arjun Vikram , Genghan Zhang , Yann Dubois , Xinlei Chen , Xiaolong Wang , Sanmi Koyejo , Tatsunori Hashimoto , Carlos Guestrin Self-attention performs well in long context but has quadratic complexity. Existing RNN layers have linear complexity, but their performance in long context is limited by the expressive power of their hidden states. We present a practical framework for instantiating sequence modeling layers with linear complexity and expressive hidden states. The key idea is to make the hidden state a machine learning model itself, and the update rule a step of self-supervised learning. Since the hidden state is updated by training even on test sequences, our layers are called Test-Time Training (TTT) layers. We consider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a linear model and a two-layer MLP respectively. We evaluate our instantiations at the scale of 125M to 1.3B parameters, comparing with a strong Transformer and Mamba, a modern RNN. Similar to Transformer, TTT-Linear and TTT-MLP can keep reducing perplexity by conditioning on more tokens, while Mamba cannot after 16k context. TTT-MLP still faces challenges in memory I/O, but shows larger potential in long context, pointing to a promising direction for future research. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "wbvshlfyB0@OpenReview",
      "index": 188,
      "title": "Nonparametric Teaching for Graph Property Learners",
      "authors": [
        "Chen Zhang",
        "Weixin Bu",
        "Zeyi Ren",
        "Zhengwu Liu",
        "Yik-Chung WU",
        "Ngai Wong"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "teaching",
        "graph",
        "nonparametric",
        "learners",
        "gcns",
        "grant",
        "property",
        "descent",
        "level",
        "reinterprets"
      ],
      "summary": "Inferring properties of graph-structured data, *e.g.*, the solubility of molecules, essentially involves learning the implicit mapping from graphs to their properties. This learning process is often costly for graph property learners like Graph Convolutional Networks (GCNs). To address this, we propose a paradigm called Graph Nonparametric Teaching (GraNT) that reinterprets the learning process through a novel nonparametric teaching perspective. Specifically, the latter offers a theoretical framework for teaching implicitly defined (*i.e.*, nonparametric) mappings via example selection. Such an implicit mapping is realized by a dense set of graph-property pairs, with the GraNT teacher selecting a subset of them to promote faster convergence in GCN training. By analytically examining the impact of graph structure on parameter-based gradient descent during training, and recasting the evolution of GCNs—shaped by parameter updates—through functional gradient descent in nonparametric teaching, we show *for the first time* that teaching graph property learners (*i.e.*, GCNs) is consistent with teaching structure-aware nonparametric learners. These new findings readily commit GraNT to enhancing learning efficiency of the graph property learner, showing significant reductions in training time for graph-level regression (-36.62\\%), graph-level classification (-38.19\\%), node-level regression (-30.97\\%) and node-level classification (-47.30\\%), all while maintaining its generalization performance.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=wbvshlfyB0"
        ],
        "venue": [
          "/venue/wbvshlfyB0@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=wbvshlfyB0"
        ],
        "detail": [
          "https://openreview.net/forum?id=wbvshlfyB0"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Nonparametric Teaching for Graph Property Learners [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Chen Zhang , Weixin Bu , Zeyi Ren , Zhengwu Liu , Yik-Chung WU , Ngai Wong Inferring properties of graph-structured data, *e.g.*, the solubility of molecules, essentially involves learning the implicit mapping from graphs to their properties. This learning process is often costly for graph property learners like Graph Convolutional Networks (GCNs). To address this, we propose a paradigm called Graph Nonparametric Teaching (GraNT) that reinterprets the learning process through a novel nonparametric teaching perspective. Specifically, the latter offers a theoretical framework for teaching implicitly defined (*i.e.*, nonparametric) mappings via example selection. Such an implicit mapping is realized by a dense set of graph-property pairs, with the GraNT teacher selecting a subset of them to promote faster convergence in GCN training. By analytically examining the impact of graph structure on parameter-based gradient descent during training, and recasting the evolution of GCNs—shaped by parameter updates—through functional gradient descent in nonparametric teaching, we show *for the first time* that teaching graph property learners (*i.e.*, GCNs) is consistent with teaching structure-aware nonparametric learners. These new findings readily commit GraNT to enhancing learning efficiency of the graph property learner, showing significant reductions in training time for graph-level regression (-36.62\\%), graph-level classification (-38.19\\%), node-level regression (-30.97\\%) and node-level classification (-47.30\\%), all while maintaining its generalization performance. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "wiQe95BPaB@OpenReview",
      "index": 189,
      "title": "FlashTP: Fused, Sparsity-Aware Tensor Product for Machine Learning Interatomic Potentials",
      "authors": [
        "Seung Lee",
        "Hojoon Kim",
        "Yutack Park",
        "Dawoon Jeong",
        "Seungwu Han",
        "Yeonhong Park",
        "Jae W. Lee"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "flashtp",
        "times",
        "mlips",
        "interatomic",
        "tensor",
        "product",
        "sevennet",
        "e3nn",
        "potentials",
        "snu"
      ],
      "summary": "Machine Learning Interatomic Potentials (MLIPs) enable efficient molecular dynamics (MD) simulations with high accuracy. While equivariant MLIPs achieve state-of-the-art accuracy, they face significant computational bottlenecks centered around their Tensor-Product layer, which account for up to 75\\% of training time and cause substantial memory overhead. We present FlashTP, a highly optimized tensor-product library that addresses these inefficiencies through kernel fusion, sparse computation, and path-aggregated execution. FlashTP achieves up to 41.6 × × and 60.8 × × kernel speedups over _e3nn_ and NVIDIA cuEquivariance, respectively. For SevenNet-l3i5, it delivers 4.2 × × and 3.5 × × speedup while reducing peak memory usage by 6.3 × × and 6.2 × × for inference and training, respectively. The code is available at https://github.com/SNU-ARC/flashTP.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=wiQe95BPaB"
        ],
        "venue": [
          "/venue/wiQe95BPaB@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=wiQe95BPaB"
        ],
        "detail": [
          "https://openreview.net/forum?id=wiQe95BPaB"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "FlashTP: Fused, Sparsity-Aware Tensor Product for Machine Learning Interatomic Potentials [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Seung Lee , Hojoon Kim , Yutack Park , Dawoon Jeong , Seungwu Han , Yeonhong Park , Jae W. Lee Machine Learning Interatomic Potentials (MLIPs) enable efficient molecular dynamics (MD) simulations with high accuracy. While equivariant MLIPs achieve state-of-the-art accuracy, they face significant computational bottlenecks centered around their Tensor-Product layer, which account for up to 75\\% of training time and cause substantial memory overhead. We present FlashTP, a highly optimized tensor-product library that addresses these inefficiencies through kernel fusion, sparse computation, and path-aggregated execution. FlashTP achieves up to 41.6 × × and 60.8 × × kernel speedups over _e3nn_ and NVIDIA cuEquivariance, respectively. For SevenNet-l3i5, it delivers 4.2 × × and 3.5 × × speedup while reducing peak memory usage by 6.3 × × and 6.2 × × for inference and training, respectively. The code is available at https://github.com/SNU-ARC/flashTP. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "xVBfdltHST@OpenReview",
      "index": 190,
      "title": "Relational Invariant Learning for Robust Solvation Free Energy Prediction",
      "authors": [
        "Yeyun Chen"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "solvation",
        "rilood",
        "relational",
        "invariant",
        "prediction",
        "ood",
        "free",
        "energy",
        "robust",
        "diverse"
      ],
      "summary": "Predicting the solvation free energy of molecules using graph neural networks holds significant potential for advancing drug discovery and the design of novel materials. While previous methods have demonstrated success on independent and identically distributed (IID) datasets, their performance in out-of-distribution (OOD) scenarios remains largely unexplored. We propose a novel Relational Invariant Learning framework (RILOOD) to enhance OOD generalization in solvation free energy prediction. RILOOD comprises three key components: (i) a mixup-based conditional modeling module that integrates diverse environments, (ii) a novel multi-granularity refinement strategy that extends beyond core substructures to enable context-aware representation learning for capturing multi-level interactions, and (iii) an invariant learning mechanism that identifies robust patterns generalizable to unseen environments. Extensive experiments demonstrate that RILOOD significantly outperforms state-of-the-art methods across various distribution shifts, highlighting its effectiveness in improving solvation free energy prediction under diverse conditions.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=xVBfdltHST"
        ],
        "venue": [
          "/venue/xVBfdltHST@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=xVBfdltHST"
        ],
        "detail": [
          "https://openreview.net/forum?id=xVBfdltHST"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 2
      },
      "raw_excerpt": "Relational Invariant Learning for Robust Solvation Free Energy Prediction [PDF 1 ] [Copy] [Kimi 2 ] [REL] Author : Yeyun Chen Predicting the solvation free energy of molecules using graph neural networks holds significant potential for advancing drug discovery and the design of novel materials. While previous methods have demonstrated success on independent and identically distributed (IID) datasets, their performance in out-of-distribution (OOD) scenarios remains largely unexplored. We propose a novel Relational Invariant Learning framework (RILOOD) to enhance OOD generalization in solvation free energy prediction. RILOOD comprises three key components: (i) a mixup-based conditional modeling module that integrates diverse environments, (ii) a novel multi-granularity refinement strategy that extends beyond core substructures to enable context-aware representation learning for capturing multi-level interactions, and (iii) an invariant learning mechanism that identifies robust patterns generalizable to unseen environments. Extensive experiments demonstrate that RILOOD significantly outperforms state-of-the-art methods across various distribution shifts, highlighting its effectiveness in improving solvation free energy prediction under diverse conditions. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "xtlixzbcfV@OpenReview",
      "index": 191,
      "title": "Novelty Detection in Reinforcement Learning with World Models",
      "authors": [
        "Geigh Zollicoffer",
        "Kenneth Eaton",
        "Jonathan Balloch",
        "Julia Kim",
        "Wei Zhou",
        "Robert Wright",
        "Mark Riedl"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "novelty",
        "world",
        "novelties",
        "detection",
        "agent",
        "sudden",
        "ofour",
        "reinforcement",
        "ina",
        "transitions"
      ],
      "summary": "Reinforcement learning (RL) using world models has found significant recent successes.However, when a sudden change to world mechanics or properties occurs then agent performance and reliability can dramatically decline.We refer to the sudden change in visual properties or state transitions as novelties.Implementing novelty detection within generated world model frameworks is a crucialtask for protecting the agent when deployed. In this paper, we propose straightforward bounding approaches to incorporate novelty detection into world model RL agents by utilizing the misalignment of the world model's hallucinated states and the true observed states as a novelty score. We provideeffective approaches to detecting novelties in a distribution of transitions learned by an agent ina world model. Finally, we show the advantage ofour work in a novel environment compared to traditional machine learning novelty detection methods as well as currently accepted RL-focused novelty detection algorithms.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=xtlixzbcfV"
        ],
        "venue": [
          "/venue/xtlixzbcfV@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=xtlixzbcfV"
        ],
        "detail": [
          "https://openreview.net/forum?id=xtlixzbcfV"
        ]
      },
      "scores": {
        "pdf": 7,
        "kimi": 4
      },
      "raw_excerpt": "Novelty Detection in Reinforcement Learning with World Models [PDF 7 ] [Copy] [Kimi 4 ] [REL] Authors : Geigh Zollicoffer , Kenneth Eaton , Jonathan Balloch , Julia Kim , Wei Zhou , Robert Wright , Mark Riedl Reinforcement learning (RL) using world models has found significant recent successes.However, when a sudden change to world mechanics or properties occurs then agent performance and reliability can dramatically decline.We refer to the sudden change in visual properties or state transitions as novelties.Implementing novelty detection within generated world model frameworks is a crucialtask for protecting the agent when deployed. In this paper, we propose straightforward bounding approaches to incorporate novelty detection into world model RL agents by utilizing the misalignment of the world model's hallucinated states and the true observed states as a novelty score. We provideeffective approaches to detecting novelties in a distribution of transitions learned by an agent ina world model. Finally, we show the advantage ofour work in a novel environment compared to traditional machine learning novelty detection methods as well as currently accepted RL-focused novelty detection algorithms. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "xvLVYrYQ8a@OpenReview",
      "index": 192,
      "title": "Covered Forest: Fine-grained generalization analysis of graph neural networks",
      "authors": [
        "Antonis Vasileiou",
        "Ben Finkelshtein",
        "Floris Geerts",
        "Ron Levie",
        "Christopher Morris"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "mpnns",
        "graph",
        "generalization",
        "abilities",
        "aggregation",
        "covered",
        "forest",
        "overlook",
        "loss",
        "grained"
      ],
      "summary": "The expressive power of message-passing graph neural networks (MPNNs) is reasonably well understood, primarily through combinatorial techniques from graph isomorphism testing. However, MPNNs' generalization abilities---making meaningful predictions beyond the training set---remain less explored. Current generalization analyses often overlook graph structure, limit the focus to specific aggregation functions, and assume the impractical, hard-to-optimize 0 0 - 1 1 loss function. Here, we extend recent advances in graph similarity theory to assess the influence of graph structure, aggregation, and loss functions on MPNNs' generalization abilities. Our empirical study supports our theoretical insights, improving our understanding of MPNNs' generalization properties.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=xvLVYrYQ8a"
        ],
        "venue": [
          "/venue/xvLVYrYQ8a@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=xvLVYrYQ8a"
        ],
        "detail": [
          "https://openreview.net/forum?id=xvLVYrYQ8a"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 1
      },
      "raw_excerpt": "Covered Forest: Fine-grained generalization analysis of graph neural networks [PDF 4 ] [Copy] [Kimi 1 ] [REL] Authors : Antonis Vasileiou , Ben Finkelshtein , Floris Geerts , Ron Levie , Christopher Morris The expressive power of message-passing graph neural networks (MPNNs) is reasonably well understood, primarily through combinatorial techniques from graph isomorphism testing. However, MPNNs' generalization abilities---making meaningful predictions beyond the training set---remain less explored. Current generalization analyses often overlook graph structure, limit the focus to specific aggregation functions, and assume the impractical, hard-to-optimize 0 0 - 1 1 loss function. Here, we extend recent advances in graph similarity theory to assess the influence of graph structure, aggregation, and loss functions on MPNNs' generalization abilities. Our empirical study supports our theoretical insights, improving our understanding of MPNNs' generalization properties. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "yXRixu0ONY@OpenReview",
      "index": 193,
      "title": "P(all-atom) Is Unlocking New Path For Protein Design",
      "authors": [
        "Wei Qu",
        "Jiawei Guan",
        "Rui Ma",
        "kezhai",
        "weikun wu",
        "haobo Wang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "protein",
        "pallatom",
        "atom",
        "textit",
        "generation",
        "unlocking",
        "coordinates",
        "tokenizes",
        "designability",
        "atom14"
      ],
      "summary": "We introduce Pallatom, an innovative protein generation model capable of producing protein structures with all-atom coordinates. Pallatom directly learns and models the joint distribution P ( structure , seq ) P ( structure , seq ) by focusing on P ( all-atom ) P ( all-atom ) , effectively addressing the interdependence between sequence and structure in protein generation. To achieve this, we propose a novel network architecture specifically designed for all-atom protein generation. Our model employs a dual-track framework that tokenizes proteins into token-level and atomic-level representations, integrating them through a multi-layer decoding process with \"traversing\" representations and recycling mechanism. We also introduce the atom14 atom14 representation method, which unifies the description of unknown side-chain coordinates, ensuring high fidelity between the generated all-atom conformation and its physical structure. Experimental results demonstrate that Pallatom excels in key metrics of protein design, including designability, diversity, and novelty, showing significant improvements across the board. Our model not only enhances the accuracy of protein generation but also exhibits excellent sampling efficiency, paving the way for future applications in larger and more complex systems.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=yXRixu0ONY"
        ],
        "venue": [
          "/venue/yXRixu0ONY@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=yXRixu0ONY"
        ],
        "detail": [
          "https://openreview.net/forum?id=yXRixu0ONY"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 2
      },
      "raw_excerpt": "P(all-atom) Is Unlocking New Path For Protein Design [PDF 5 ] [Copy] [Kimi 2 ] [REL] Authors : Wei Qu , Jiawei Guan , Rui Ma , kezhai , weikun wu , haobo Wang We introduce Pallatom, an innovative protein generation model capable of producing protein structures with all-atom coordinates. Pallatom directly learns and models the joint distribution P ( structure , seq ) P ( structure , seq ) by focusing on P ( all-atom ) P ( all-atom ) , effectively addressing the interdependence between sequence and structure in protein generation. To achieve this, we propose a novel network architecture specifically designed for all-atom protein generation. Our model employs a dual-track framework that tokenizes proteins into token-level and atomic-level representations, integrating them through a multi-layer decoding process with \"traversing\" representations and recycling mechanism. We also introduce the atom14 atom14 representation method, which unifies the description of unknown side-chain coordinates, ensuring high fidelity between the generated all-atom conformation and its physical structure. Experimental results demonstrate that Pallatom excels in key metrics of protein design, including designability, diversity, and novelty, showing significant improvements across the board. Our model not only enhances the accuracy of protein generation but also exhibits excellent sampling efficiency, paving the way for future applications in larger and more complex systems. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "zIGIvysR1H@OpenReview",
      "index": 194,
      "title": "Data-Juicer Sandbox: A Feedback-Driven Suite for Multimodal Data-Model Co-development",
      "authors": [
        "Daoyuan Chen",
        "Haibin Wang",
        "Yilun Huang",
        "Ce Ge",
        "Yaliang Li",
        "Bolin Ding",
        "Jingren Zhou"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "sandbox",
        "suite",
        "multimodal",
        "juicer",
        "data",
        "development",
        "vbench",
        "feedback",
        "models",
        "centric"
      ],
      "summary": "The emergence of multimodal large models has advanced artificial intelligence, introducing unprecedented levels of performance and functionality. However, optimizing these models remains challenging due to historically isolated paths of model-centric and data-centric developments, leading to suboptimal outcomes and inefficient resource utilization. In response, we present a new sandbox suite tailored for integrated data-model co-development. This sandbox provides a feedback-driven experimental platform, enabling cost-effective iteration and guided refinement of both data and models. Our proposed ``Probe-Analyze-Refine'' workflow, validated through practical use cases on multimodal tasks such as image-text pre-training with CLIP, image-to-text generation with LLaVA-like models, and text-to-video generation with DiT-based models, yields transferable and notable performance boosts, such as topping the VBench leaderboard. A comprehensive set of over 100 experiments demonstrated the suite's usability and extensibility, while also uncovering insights into the interplay between data quality, diversity, model behavior, and computational costs. All codes, datasets, and models are open-sourced to foster future research and applications that would otherwise be infeasible due to the lack of a dedicated co-development infrastructure.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=zIGIvysR1H"
        ],
        "venue": [
          "/venue/zIGIvysR1H@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=zIGIvysR1H"
        ],
        "detail": [
          "https://openreview.net/forum?id=zIGIvysR1H"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 2
      },
      "raw_excerpt": "Data-Juicer Sandbox: A Feedback-Driven Suite for Multimodal Data-Model Co-development [PDF 1 ] [Copy] [Kimi 2 ] [REL] Authors : Daoyuan Chen , Haibin Wang , Yilun Huang , Ce Ge , Yaliang Li , Bolin Ding , Jingren Zhou The emergence of multimodal large models has advanced artificial intelligence, introducing unprecedented levels of performance and functionality. However, optimizing these models remains challenging due to historically isolated paths of model-centric and data-centric developments, leading to suboptimal outcomes and inefficient resource utilization. In response, we present a new sandbox suite tailored for integrated data-model co-development. This sandbox provides a feedback-driven experimental platform, enabling cost-effective iteration and guided refinement of both data and models. Our proposed ``Probe-Analyze-Refine'' workflow, validated through practical use cases on multimodal tasks such as image-text pre-training with CLIP, image-to-text generation with LLaVA-like models, and text-to-video generation with DiT-based models, yields transferable and notable performance boosts, such as topping the VBench leaderboard. A comprehensive set of over 100 experiments demonstrated the suite's usability and extensibility, while also uncovering insights into the interplay between data quality, diversity, model behavior, and computational costs. All codes, datasets, and models are open-sourced to foster future research and applications that would otherwise be infeasible due to the lack of a dedicated co-development infrastructure. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "zL6ljQvPzZ@OpenReview",
      "index": 195,
      "title": "Lightweight Protocols for Distributed Private Quantile Estimation",
      "authors": [
        "Anders Aamand",
        "Fabrizio Boninsegna",
        "Abigail Gentle",
        "Jacob Imola",
        "Rasmus Pagh"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "varepsilon",
        "ldp",
        "quantile",
        "shuffle",
        "protocols",
        "adaptive",
        "private",
        "privacy",
        "frac",
        "users"
      ],
      "summary": "Distributed data analysis is a large and growing field driven by a massive proliferation of user devices, and by privacy concerns surrounding the centralised storage of data. We consider two \\emph{adaptive} algorithms for estimating one quantile (e.g.~the median) when each user holds a single data point lying in a domain [ B ] [ B ] that can be queried once through a private mechanism; one under local differential privacy (LDP) and another for shuffle differential privacy (shuffle-DP). In the adaptive setting we present an ε ε -LDP algorithm which can estimate any quantile within error α α only requiring O ( log B ε 2 α 2 ) O ( log ⁡ B ε 2 α 2 ) users, and an ( ε , δ ) ( ε , δ ) -shuffle DP algorithm requiring only O ˜ ( ( 1 ε 2 + 1 α 2 ) log B ) O ~ ( ( 1 ε 2 + 1 α 2 ) log ⁡ B ) users. Prior (nonadaptive) algorithms require more users by several logarithmic factors in B B . We further provide a matching lower bound for adaptive protocols, showing that our LDP algorithm is optimal in the low- ε ε regime. Additionally, we establish lower bounds against non-adaptive protocols which paired with our understanding of the adaptive case, proves a fundamental separation between these models.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=zL6ljQvPzZ"
        ],
        "venue": [
          "/venue/zL6ljQvPzZ@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=zL6ljQvPzZ"
        ],
        "detail": [
          "https://openreview.net/forum?id=zL6ljQvPzZ"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Lightweight Protocols for Distributed Private Quantile Estimation [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Anders Aamand , Fabrizio Boninsegna , Abigail Gentle , Jacob Imola , Rasmus Pagh Distributed data analysis is a large and growing field driven by a massive proliferation of user devices, and by privacy concerns surrounding the centralised storage of data. We consider two \\emph{adaptive} algorithms for estimating one quantile (e.g.~the median) when each user holds a single data point lying in a domain [ B ] [ B ] that can be queried once through a private mechanism; one under local differential privacy (LDP) and another for shuffle differential privacy (shuffle-DP). In the adaptive setting we present an ε ε -LDP algorithm which can estimate any quantile within error α α only requiring O ( log B ε 2 α 2 ) O ( log ⁡ B ε 2 α 2 ) users, and an ( ε , δ ) ( ε , δ ) -shuffle DP algorithm requiring only O ˜ ( ( 1 ε 2 + 1 α 2 ) log B ) O ~ ( ( 1 ε 2 + 1 α 2 ) log ⁡ B ) users. Prior (nonadaptive) algorithms require more users by several logarithmic factors in B B . We further provide a matching lower bound for adaptive protocols, showing that our LDP algorithm is optimal in the low- ε ε regime. Additionally, we establish lower bounds against non-adaptive protocols which paired with our understanding of the adaptive case, proves a fundamental separation between these models. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "zU4VCPHYRC@OpenReview",
      "index": 196,
      "title": "On the Tension between Byzantine Robustness and No-Attack Accuracy in Distributed Learning",
      "authors": [
        "Yi-Rui Yang",
        "Chang-Wei Shi",
        "Wu-Jun Li"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "byzantine",
        "workers",
        "aggregators",
        "brdl",
        "robust",
        "robustness",
        "tension",
        "accuracy",
        "attack",
        "faulty"
      ],
      "summary": "Byzantine-robust distributed learning (BRDL), which refers to distributed learning that can work with potential faulty or malicious workers (also known as Byzantine workers), has recently attracted much research attention. Robust aggregators are widely used in existing BRDL methods to obtain robustness against Byzantine workers. However, Byzantine workers do not always exist in applications. As far as we know, there is almost no existing work theoretically investigating the effect of using robust aggregators when there are no Byzantine workers. To bridge this knowledge gap, we theoretically analyze the aggregation error for robust aggregators when there are no Byzantine workers. Specifically, we show that the worst-case aggregation error without Byzantine workers increases with the increase of the number of Byzantine workers that a robust aggregator can tolerate. The theoretical result reveals the tension between Byzantine robustness and no-attack accuracy, which refers to accuracy without faulty workers and malicious workers in this paper. Furthermore, we provide lower bounds for the convergence rate of gradient descent with robust aggregators for non-convex objective functions and objective functions that satisfy the Polyak-Lojasiewicz (PL) condition, respectively. We also prove the tightness of the lower bounds. The lower bounds for convergence rate reveal similar tension between Byzantine robustness and no-attack accuracy. Empirical results further support our theoretical findings.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=zU4VCPHYRC"
        ],
        "venue": [
          "/venue/zU4VCPHYRC@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=zU4VCPHYRC"
        ],
        "detail": [
          "https://openreview.net/forum?id=zU4VCPHYRC"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "On the Tension between Byzantine Robustness and No-Attack Accuracy in Distributed Learning [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Yi-Rui Yang , Chang-Wei Shi , Wu-Jun Li Byzantine-robust distributed learning (BRDL), which refers to distributed learning that can work with potential faulty or malicious workers (also known as Byzantine workers), has recently attracted much research attention. Robust aggregators are widely used in existing BRDL methods to obtain robustness against Byzantine workers. However, Byzantine workers do not always exist in applications. As far as we know, there is almost no existing work theoretically investigating the effect of using robust aggregators when there are no Byzantine workers. To bridge this knowledge gap, we theoretically analyze the aggregation error for robust aggregators when there are no Byzantine workers. Specifically, we show that the worst-case aggregation error without Byzantine workers increases with the increase of the number of Byzantine workers that a robust aggregator can tolerate. The theoretical result reveals the tension between Byzantine robustness and no-attack accuracy, which refers to accuracy without faulty workers and malicious workers in this paper. Furthermore, we provide lower bounds for the convergence rate of gradient descent with robust aggregators for non-convex objective functions and objective functions that satisfy the Polyak-Lojasiewicz (PL) condition, respectively. We also prove the tightness of the lower bounds. The lower bounds for convergence rate reveal similar tension between Byzantine robustness and no-attack accuracy. Empirical results further support our theoretical findings. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "zdOGBRQEbz@OpenReview",
      "index": 197,
      "title": "From Mechanistic Interpretability to Mechanistic Biology: Training, Evaluating, and Interpreting Sparse Autoencoders on Protein Language Models",
      "authors": [
        "Etowah Adams",
        "Liam Bai",
        "Minji Lee",
        "Yiyang Yu",
        "Mohammed AlQuraishi"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "protein",
        "plms",
        "sae",
        "mechanistic",
        "features",
        "biology",
        "plm",
        "autoencoders",
        "thermostability",
        "sparse"
      ],
      "summary": "Protein language models (pLMs) are powerful predictors of protein structure and function, learning through unsupervised training on millions of protein sequences. pLMs are thought to capture common motifs in protein sequences, but the specifics of pLM features are not well understood. Identifying these features would not only shed light on how pLMs work, but potentially uncover novel protein biology––studying the model to study the biology. Motivated by this, we train sparse autoencoders (SAEs) on the residual stream of a pLM, ESM-2. By characterizing SAE features, we determine that pLMs use a combination of generic features and family-specific features to represent a protein. In addition, we demonstrate how known sequence determinants of properties such as thermostability and subcellular localization can be identified by linear probing of SAE features. For predictive features without known functional associations, we hypothesize their role in unknown mechanisms and provide visualization tools to aid their interpretation. Our study gives a better understanding of the limitations of pLMs, and demonstrates how SAE features can be used to help generate hypotheses for biological mechanisms. We release our code, model weights, and feature visualizer.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=zdOGBRQEbz"
        ],
        "venue": [
          "/venue/zdOGBRQEbz@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=zdOGBRQEbz"
        ],
        "detail": [
          "https://openreview.net/forum?id=zdOGBRQEbz"
        ]
      },
      "scores": {
        "pdf": 5,
        "kimi": 1
      },
      "raw_excerpt": "From Mechanistic Interpretability to Mechanistic Biology: Training, Evaluating, and Interpreting Sparse Autoencoders on Protein Language Models [PDF 5 ] [Copy] [Kimi 1 ] [REL] Authors : Etowah Adams , Liam Bai , Minji Lee , Yiyang Yu , Mohammed AlQuraishi Protein language models (pLMs) are powerful predictors of protein structure and function, learning through unsupervised training on millions of protein sequences. pLMs are thought to capture common motifs in protein sequences, but the specifics of pLM features are not well understood. Identifying these features would not only shed light on how pLMs work, but potentially uncover novel protein biology––studying the model to study the biology. Motivated by this, we train sparse autoencoders (SAEs) on the residual stream of a pLM, ESM-2. By characterizing SAE features, we determine that pLMs use a combination of generic features and family-specific features to represent a protein. In addition, we demonstrate how known sequence determinants of properties such as thermostability and subcellular localization can be identified by linear probing of SAE features. For predictive features without known functional associations, we hypothesize their role in unknown mechanisms and provide visualization tools to aid their interpretation. Our study gives a better understanding of the limitations of pLMs, and demonstrates how SAE features can be used to help generate hypotheses for biological mechanisms. We release our code, model weights, and feature visualizer. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "42Au7FoD8F@OpenReview",
      "index": 198,
      "title": "Position: Deep Learning is Not So Mysterious or Different",
      "authors": [
        "Andrew Wilson"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "mysterious",
        "generalization",
        "phenomena",
        "hypothesis",
        "overfitting",
        "deep",
        "position",
        "classes",
        "defying",
        "overparametrization"
      ],
      "summary": "Deep neural networks are often seen as different from other model classes by defying conventional notions of generalization. Popular examples of anomalous generalization behaviour include benign overfitting, double descent, and the success of overparametrization.This position paper argues that these phenomena are not distinct to neural networks, or particularly mysterious. Moreover, this generalization behaviour can be intuitively understood, and rigorously characterized, using long-standing generalization frameworks such as PAC-Bayes and countable hypothesis bounds. We present soft inductive biases as a key unifying principle in explaining these phenomena: rather than restricting the hypothesis space to avoid overfitting, embrace a flexible hypothesis space, with a soft preference for simpler solutions that are consistent with the data. This principle can be encoded in many model classes, and thus deep learning is not as mysterious or different from other model classes as it might seem. However, we also highlight how deep learning is relatively distinct in other ways, such as its ability for representation learning, phenomena such as mode connectivity, and its relative universality.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=42Au7FoD8F"
        ],
        "venue": [
          "/venue/42Au7FoD8F@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=42Au7FoD8F"
        ],
        "detail": [
          "https://openreview.net/forum?id=42Au7FoD8F"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "Position: Deep Learning is Not So Mysterious or Different [PDF 3 ] [Copy] [Kimi 1 ] [REL] Author : Andrew Wilson Deep neural networks are often seen as different from other model classes by defying conventional notions of generalization. Popular examples of anomalous generalization behaviour include benign overfitting, double descent, and the success of overparametrization.This position paper argues that these phenomena are not distinct to neural networks, or particularly mysterious. Moreover, this generalization behaviour can be intuitively understood, and rigorously characterized, using long-standing generalization frameworks such as PAC-Bayes and countable hypothesis bounds. We present soft inductive biases as a key unifying principle in explaining these phenomena: rather than restricting the hypothesis space to avoid overfitting, embrace a flexible hypothesis space, with a soft preference for simpler solutions that are consistent with the data. This principle can be encoded in many model classes, and thus deep learning is not as mysterious or different from other model classes as it might seem. However, we also highlight how deep learning is relatively distinct in other ways, such as its ability for representation learning, phenomena such as mode connectivity, and its relative universality. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "ACzL62Jp4E@OpenReview",
      "index": 199,
      "title": "Position: In-House Evaluation Is Not Enough. Towards Robust Third-Party Evaluation and Flaw Disclosure for General-Purpose AI",
      "authors": [
        "Shayne Longpre",
        "Kevin Klyman",
        "Ruth Elisabeth Appel",
        "Sayash Kapoor",
        "Rishi Bommasani",
        "Michelle Sahar",
        "Sean McGregor",
        "Avijit Ghosh",
        "Borhane Blili-Hamelin",
        "Nathan Butters",
        "Alondra Nelson",
        "Amit Elazari",
        "Andrew Sellars",
        "Casey Ellis",
        "Dane Sherrets",
        "Dawn Song",
        "Harley Geiger",
        "Ilona Cohen",
        "Lauren McIlvenny",
        "Madhulika Srikumar",
        "Mark Jaycox",
        "Markus Anderljung",
        "Nadine Johnson",
        "Nicholas Carlini",
        "Nicolas Miailhe",
        "Nik Marda",
        "Peter Henderson",
        "Rebecca Portnoff",
        "Rebecca Weiss",
        "Victoria Westerhoff",
        "Yacine Jernite",
        "Rumman Chowdhury",
        "Percy Liang",
        "Arvind Narayanan"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "gpai",
        "flaw",
        "flaws",
        "reporting",
        "disclosure",
        "systems",
        "evaluation",
        "security",
        "interventions",
        "providers"
      ],
      "summary": "The widespread deployment of general-purpose AI (GPAI) systems introduces significant new risks. Yet the infrastructure, practices, and norms for reporting flaws in GPAI systems remain seriously underdeveloped, lagging far behind more established fields like software security. Based on a collaboration between experts from the fields of software security, machine learning, law, social science, and policy, we identify key gaps in the evaluation and reporting of flaws in GPAI systems. We call for three interventions to advance system safety. First, we propose using standardized AI flaw reports and rules of engagement for researchers in order to ease the process of submitting, reproducing, and triaging flaws in GPAI systems. Second, we propose GPAI system providers adopt broadly-scoped flaw disclosure programs, borrowing from bug bounties, with legal safe harbors to protect researchers. Third, we advocate for the development of improved infrastructure to coordinate distribution of flaw reports across the many stakeholders who may be impacted. These interventions are increasingly urgent, as evidenced by the prevalence of jailbreaks and other flaws that can transfer across different providers' GPAI systems. By promoting robust reporting and coordination in the AI ecosystem, these proposals could significantly improve the safety, security, and accountability of GPAI systems.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=ACzL62Jp4E"
        ],
        "venue": [
          "/venue/ACzL62Jp4E@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=ACzL62Jp4E"
        ],
        "detail": [
          "https://openreview.net/forum?id=ACzL62Jp4E"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Position: In-House Evaluation Is Not Enough. Towards Robust Third-Party Evaluation and Flaw Disclosure for General-Purpose AI [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Shayne Longpre , Kevin Klyman , Ruth Elisabeth Appel , Sayash Kapoor , Rishi Bommasani , Michelle Sahar , Sean McGregor , Avijit Ghosh , Borhane Blili-Hamelin , Nathan Butters , Alondra Nelson , Amit Elazari , Andrew Sellars , Casey Ellis , Dane Sherrets , Dawn Song , Harley Geiger , Ilona Cohen , Lauren McIlvenny , Madhulika Srikumar , Mark Jaycox , Markus Anderljung , Nadine Johnson , Nicholas Carlini , Nicolas Miailhe , Nik Marda , Peter Henderson , Rebecca Portnoff , Rebecca Weiss , Victoria Westerhoff , Yacine Jernite , Rumman Chowdhury , Percy Liang , Arvind Narayanan The widespread deployment of general-purpose AI (GPAI) systems introduces significant new risks. Yet the infrastructure, practices, and norms for reporting flaws in GPAI systems remain seriously underdeveloped, lagging far behind more established fields like software security. Based on a collaboration between experts from the fields of software security, machine learning, law, social science, and policy, we identify key gaps in the evaluation and reporting of flaws in GPAI systems. We call for three interventions to advance system safety. First, we propose using standardized AI flaw reports and rules of engagement for researchers in order to ease the process of submitting, reproducing, and triaging flaws in GPAI systems. Second, we propose GPAI system providers adopt broadly-scoped flaw disclosure programs, borrowing from bug bounties, with legal safe harbors to protect researchers. Third, we advocate for the development of improved infrastructure to coordinate distribution of flaw reports across the many stakeholders who may be impacted. These interventions are increasingly urgent, as evidenced by the prevalence of jailbreaks and other flaws that can transfer across different providers' GPAI systems. By promoting robust reporting and coordination in the AI ecosystem, these proposals could significantly improve the safety, security, and accountability of GPAI systems. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "HuvAM5x2xG@OpenReview",
      "index": 200,
      "title": "Position: Formal Mathematical Reasoning—A New Frontier in AI",
      "authors": [
        "Kaiyu Yang",
        "Gabriel Poesia",
        "Jingxuan He",
        "Wenda Li",
        "Kristin Lauter",
        "Swarat Chaudhuri",
        "Dawn Song"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "formal",
        "reasoning",
        "ai4math",
        "mathematical",
        "position",
        "math",
        "intellectually",
        "frontier",
        "verification",
        "mirrored"
      ],
      "summary": "AI for Mathematics (AI4Math) is intellectually intriguing and is crucial for AI-driven system design and verification. Extensive efforts on AI4Math have mirrored techniques in NLP, in particular, training large language models on carefully curated math datasets in text form. As a complementary yet less explored avenue, formal mathematical reasoning is grounded in formal systems such as proof assistants, which can verify the correctness of reasoning and provide automatic feedback. This position paper advocates formal mathematical reasoning as an indispensable component in future AI for math, formal verification, and verifiable generation. We summarize existing progress, discuss open challenges, and envision critical milestones to measure future success.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=HuvAM5x2xG"
        ],
        "venue": [
          "/venue/HuvAM5x2xG@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=HuvAM5x2xG"
        ],
        "detail": [
          "https://openreview.net/forum?id=HuvAM5x2xG"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 3
      },
      "raw_excerpt": "Position: Formal Mathematical Reasoning—A New Frontier in AI [PDF 2 ] [Copy] [Kimi 3 ] [REL] Authors : Kaiyu Yang , Gabriel Poesia , Jingxuan He , Wenda Li , Kristin Lauter , Swarat Chaudhuri , Dawn Song AI for Mathematics (AI4Math) is intellectually intriguing and is crucial for AI-driven system design and verification. Extensive efforts on AI4Math have mirrored techniques in NLP, in particular, training large language models on carefully curated math datasets in text form. As a complementary yet less explored avenue, formal mathematical reasoning is grounded in formal systems such as proof assistants, which can verify the correctness of reasoning and provide automatic feedback. This position paper advocates formal mathematical reasoning as an indispensable component in future AI for math, formal verification, and verifiable generation. We summarize existing progress, discuss open challenges, and envision critical milestones to measure future success. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "QMgCDPWL9Y@OpenReview",
      "index": 201,
      "title": "Position: General Intelligence Requires Reward-based Pretraining",
      "authors": [
        "Seungwook Han",
        "Jyothish Pari",
        "Samuel Gershman",
        "Pulkit Agrawal"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "reasoning",
        "aui",
        "reason",
        "agi",
        "intelligence",
        "pretraining",
        "llms",
        "transferability",
        "pretaining",
        "algorithmic"
      ],
      "summary": "Large Language Models (LLMs) have demonstrated impressive real-world utility, exemplifying artificial useful intelligence (AUI). However, their ability to reason adaptively and robustly -- the hallmarks of artificial general intelligence (AGI) -- remains fragile. While LLMs seemingly succeed in commonsense reasoning, programming, and mathematics, they struggle to generalize algorithmic understanding across novel contexts. Our experiments with algorithmic tasks in esoteric programming languages reveal that LLM's reasoning overfits to the training data and is limited in its transferability. We hypothesize that the core issue underlying such limited transferability is the coupling of reasoning and knowledge in LLMs. To transition from AUI to AGI, we propose disentangling knowledge and reasoning through three key directions: (1) pretaining to reason using RL from scratch as an alternative to the widely used next-token prediction pretraining, (2) using a curriculum of synthetic tasks to ease the learning of a \\textit{reasoning prior} for RL that can then be transferred to natural language tasks, and (3) learning more generalizable reasoning functions using a small context window to reduce exploiting spurious correlations between tokens. Such a reasoning system coupled with a trained retrieval system and a large external memory bank as a knowledge store can overcome several limitations of existing architectures at learning to reason in novel scenarios.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=QMgCDPWL9Y"
        ],
        "venue": [
          "/venue/QMgCDPWL9Y@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=QMgCDPWL9Y"
        ],
        "detail": [
          "https://openreview.net/forum?id=QMgCDPWL9Y"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 2
      },
      "raw_excerpt": "Position: General Intelligence Requires Reward-based Pretraining [PDF 4 ] [Copy] [Kimi 2 ] [REL] Authors : Seungwook Han , Jyothish Pari , Samuel Gershman , Pulkit Agrawal Large Language Models (LLMs) have demonstrated impressive real-world utility, exemplifying artificial useful intelligence (AUI). However, their ability to reason adaptively and robustly -- the hallmarks of artificial general intelligence (AGI) -- remains fragile. While LLMs seemingly succeed in commonsense reasoning, programming, and mathematics, they struggle to generalize algorithmic understanding across novel contexts. Our experiments with algorithmic tasks in esoteric programming languages reveal that LLM's reasoning overfits to the training data and is limited in its transferability. We hypothesize that the core issue underlying such limited transferability is the coupling of reasoning and knowledge in LLMs. To transition from AUI to AGI, we propose disentangling knowledge and reasoning through three key directions: (1) pretaining to reason using RL from scratch as an alternative to the widely used next-token prediction pretraining, (2) using a curriculum of synthetic tasks to ease the learning of a \\textit{reasoning prior} for RL that can then be transferred to natural language tasks, and (3) learning more generalizable reasoning functions using a small context window to reduce exploiting spurious correlations between tokens. Such a reasoning system coupled with a trained retrieval system and a large external memory bank as a knowledge store can overcome several limitations of existing architectures at learning to reason in novel scenarios. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "YhZ2PY2nZa@OpenReview",
      "index": 202,
      "title": "Position: Don't Use the CLT in LLM Evals With Fewer Than a Few Hundred Datapoints",
      "authors": [
        "Sam Bowyer",
        "Laurence Aitchison",
        "Desi Ivanova"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "clt",
        "evals",
        "llm",
        "uncertainty",
        "bars",
        "datapoints",
        "position",
        "hundred",
        "evaluations",
        "rely"
      ],
      "summary": "Rigorous statistical evaluations of large language models (LLMs), including valid error bars and significance testing, are essential for meaningful and reliable performance assessment. Currently, when such statistical measures are reported, they typically rely on the Central Limit Theorem (CLT). In this position paper, we argue that while CLT-based methods for uncertainty quantification are appropriate when benchmarks consist of thousands of examples, they fail to provide adequate uncertainty estimates for LLM evaluations that rely on smaller, highly specialized benchmarks. In these small-data settings, we demonstrate that CLT-based methods perform very poorly, usually dramatically underestimating uncertainty (i.e. producing error bars that are too small). We give recommendations for alternative frequentist and Bayesian methods that are both easy to implement and more appropriate in these increasingly common scenarios.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=YhZ2PY2nZa"
        ],
        "venue": [
          "/venue/YhZ2PY2nZa@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=YhZ2PY2nZa"
        ],
        "detail": [
          "https://openreview.net/forum?id=YhZ2PY2nZa"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 2
      },
      "raw_excerpt": "Position: Don't Use the CLT in LLM Evals With Fewer Than a Few Hundred Datapoints [PDF 1 ] [Copy] [Kimi 2 ] [REL] Authors : Sam Bowyer , Laurence Aitchison , Desi Ivanova Rigorous statistical evaluations of large language models (LLMs), including valid error bars and significance testing, are essential for meaningful and reliable performance assessment. Currently, when such statistical measures are reported, they typically rely on the Central Limit Theorem (CLT). In this position paper, we argue that while CLT-based methods for uncertainty quantification are appropriate when benchmarks consist of thousands of examples, they fail to provide adequate uncertainty estimates for LLM evaluations that rely on smaller, highly specialized benchmarks. In these small-data settings, we demonstrate that CLT-based methods perform very poorly, usually dramatically underestimating uncertainty (i.e. producing error bars that are too small). We give recommendations for alternative frequentist and Bayesian methods that are both easy to implement and more appropriate in these increasingly common scenarios. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "asQJx56NqB@OpenReview",
      "index": 203,
      "title": "Position: We Can’t Understand AI Using our Existing Vocabulary",
      "authors": [
        "John Hewitt",
        "Robert Geirhos",
        "Been Kim"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "neologisms",
        "neologism",
        "concepts",
        "vocabulary",
        "machines",
        "understand",
        "human",
        "andnot",
        "position",
        "machine"
      ],
      "summary": "This position paper argues that, in order to understand AI, we cannot rely on our existing vocabulary of human words. Instead, we shouldstrive to develop neologisms: new words thatrepresent precise human concepts that we wantto teach machines, or machine concepts that weneed to learn. We start from the premise thathumans and machines have differing concepts.This means interpretability can be framed as acommunication problem: humans must be able toreference and control machine concepts, and communicate human concepts to machines. Creatinga shared human-machine language through developing neologisms, we believe, could solve thiscommunication problem. Successful neologismsachieve a useful amount of abstraction: not toodetailed, so they’re reusable in many contexts, andnot too high-level, so they convey precise information. As a proof of concept, we demonstrate howa “length neologism” enables controlling LLMresponse length, while a “diversity neologism” allows sampling more variable responses. Takentogether, we argue that we cannot understand AIusing our existing vocabulary, and expanding itthrough neologisms creates opportunities for bothcontrolling and understanding machines better.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=asQJx56NqB"
        ],
        "venue": [
          "/venue/asQJx56NqB@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=asQJx56NqB"
        ],
        "detail": [
          "https://openreview.net/forum?id=asQJx56NqB"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 3
      },
      "raw_excerpt": "Position: We Can’t Understand AI Using our Existing Vocabulary [PDF 3 ] [Copy] [Kimi 3 ] [REL] Authors : John Hewitt , Robert Geirhos , Been Kim This position paper argues that, in order to understand AI, we cannot rely on our existing vocabulary of human words. Instead, we shouldstrive to develop neologisms: new words thatrepresent precise human concepts that we wantto teach machines, or machine concepts that weneed to learn. We start from the premise thathumans and machines have differing concepts.This means interpretability can be framed as acommunication problem: humans must be able toreference and control machine concepts, and communicate human concepts to machines. Creatinga shared human-machine language through developing neologisms, we believe, could solve thiscommunication problem. Successful neologismsachieve a useful amount of abstraction: not toodetailed, so they’re reusable in many contexts, andnot too high-level, so they convey precise information. As a proof of concept, we demonstrate howa “length neologism” enables controlling LLMresponse length, while a “diversity neologism” allows sampling more variable responses. Takentogether, we argue that we cannot understand AIusing our existing vocabulary, and expanding itthrough neologisms creates opportunities for bothcontrolling and understanding machines better. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "eI8KegpPyX@OpenReview",
      "index": 204,
      "title": "Position: The Categorization of Race in ML is a Flawed Premise",
      "authors": [
        "Miriam Doh",
        "Benedikt Höltgen",
        "Piera Riccio",
        "Nuria Oliver"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "race",
        "racial",
        "flawed",
        "essentialist",
        "position",
        "categorization",
        "premise",
        "oversimplify",
        "critiques",
        "social"
      ],
      "summary": "This position paper critiques the reliance on rigid racial taxonomies in machine learning, exposing their U.S.-centric nature and lack of global applicability—particularly in Europe, where race categories are not commonly used. These classifications oversimplify racial identity, erasing the experiences of mixed-race individuals and reinforcing outdated essentialist views that contradict the social construction of race. We suggest research agendas in machine learning that move beyond categorical variables to better address discrimination and social inequality.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=eI8KegpPyX"
        ],
        "venue": [
          "/venue/eI8KegpPyX@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=eI8KegpPyX"
        ],
        "detail": [
          "https://openreview.net/forum?id=eI8KegpPyX"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Position: The Categorization of Race in ML is a Flawed Premise [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Miriam Doh , Benedikt Höltgen , Piera Riccio , Nuria Oliver This position paper critiques the reliance on rigid racial taxonomies in machine learning, exposing their U.S.-centric nature and lack of global applicability—particularly in Europe, where race categories are not commonly used. These classifications oversimplify racial identity, erasing the experiences of mixed-race individuals and reinforcing outdated essentialist views that contradict the social construction of race. We suggest research agendas in machine learning that move beyond categorical variables to better address discrimination and social inequality. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "eax2ixyeQL@OpenReview",
      "index": 205,
      "title": "Position: We Need An Algorithmic Understanding of Generative AI",
      "authors": [
        "Oliver Eberle",
        "Thomas McGee",
        "Hamza Giaffar",
        "Taylor Webb",
        "Ida Momennejad"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "algorithmic",
        "algorithms",
        "algeval",
        "llms",
        "understanding",
        "position",
        "actually",
        "solve",
        "emergent",
        "hypotheses"
      ],
      "summary": "What algorithms do LLMs actually learn and use to solve problems? Studies addressing this question are sparse, as research priorities are focused on improving performance through scale, leaving a theoretical and empirical gap in understanding emergent algorithms. This position paper proposes AlgEval: a framework for systematic research into the algorithms that LLMs learn and use. AlgEval aims to uncover algorithmic primitives, reflected in latent representations, attention, and inference-time compute, and their algorithmic composition to solve task-specific problems. We highlight potential methodological paths and a case study toward this goal, focusing on emergent search algorithms. Our case study illustrates both the formation of top-down hypotheses about candidate algorithms, and bottom-up tests of these hypotheses via circuit-level analysis of attention patterns and hidden states. The rigorous, systematic evaluation of how LLMs actually solve tasks provides an alternative to resource-intensive scaling, reorienting the field toward a principled understanding of underlying computations. Such algorithmic explanations offer a pathway to human-understandable interpretability, enabling comprehension of the model's internal reasoning performance measures. This can in turn lead to more sample-efficient methods for training and improving performance, as well as novel architectures for end-to-end and multi-agent systems.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=eax2ixyeQL"
        ],
        "venue": [
          "/venue/eax2ixyeQL@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=eax2ixyeQL"
        ],
        "detail": [
          "https://openreview.net/forum?id=eax2ixyeQL"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 2
      },
      "raw_excerpt": "Position: We Need An Algorithmic Understanding of Generative AI [PDF 1 ] [Copy] [Kimi 2 ] [REL] Authors : Oliver Eberle , Thomas McGee , Hamza Giaffar , Taylor Webb , Ida Momennejad What algorithms do LLMs actually learn and use to solve problems? Studies addressing this question are sparse, as research priorities are focused on improving performance through scale, leaving a theoretical and empirical gap in understanding emergent algorithms. This position paper proposes AlgEval: a framework for systematic research into the algorithms that LLMs learn and use. AlgEval aims to uncover algorithmic primitives, reflected in latent representations, attention, and inference-time compute, and their algorithmic composition to solve task-specific problems. We highlight potential methodological paths and a case study toward this goal, focusing on emergent search algorithms. Our case study illustrates both the formation of top-down hypotheses about candidate algorithms, and bottom-up tests of these hypotheses via circuit-level analysis of attention patterns and hidden states. The rigorous, systematic evaluation of how LLMs actually solve tasks provides an alternative to resource-intensive scaling, reorienting the field toward a principled understanding of underlying computations. Such algorithmic explanations offer a pathway to human-understandable interpretability, enabling comprehension of the model's internal reasoning performance measures. This can in turn lead to more sample-efficient methods for training and improving performance, as well as novel architectures for end-to-end and multi-agent systems. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "gwhPvu97Gm@OpenReview",
      "index": 206,
      "title": "Position: Human Baselines in Model Evaluations Need Rigor and Transparency (With Recommendations & Reporting Checklist)",
      "authors": [
        "Kevin Wei",
        "Patricia Paskov",
        "Sunishchal Dev",
        "Michael Byun",
        "Anka Reuel",
        "Xavier Roberts-Gaal",
        "Rachel Calcott",
        "Evie Coxon",
        "Chinmay Deshpande"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "checklist",
        "baselines",
        "human",
        "reporting",
        "recommendations",
        "baselining",
        "evaluations",
        "kevinlwei",
        "rigorous",
        "policymakers"
      ],
      "summary": "**In this position paper, we argue that human baselines in foundation model evaluations must be more rigorous and more transparent to enable meaningful comparisons of human vs. AI performance, and we provide recommendations and a reporting checklist towards this end.** Human performance baselines are vital for the machine learning community, downstream users, and policymakers to interpret AI evaluations. Models are often claimed to achieve \"super-human\" performance, but existing baselining methods are neither sufficiently rigorous nor sufficiently well-documented to robustly measure and assess performance differences. Based on a meta-review of the measurement theory and AI evaluation literatures, we derive a framework with recommendations for designing, executing, and reporting human baselines. We synthesize our recommendations into a checklist that we use to systematically review 115 human baselines (studies) in foundation model evaluations and thus identify shortcomings in existing baselining methods; our checklist can also assist researchers in conducting human baselines and reporting results. We hope our work can advance more rigorous AI evaluation practices that can better serve both the research community and policymakers. Data is available at: [https://github.com/kevinlwei/human-baselines](https://github.com/kevinlwei/human-baselines).",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=gwhPvu97Gm"
        ],
        "venue": [
          "/venue/gwhPvu97Gm@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=gwhPvu97Gm"
        ],
        "detail": [
          "https://openreview.net/forum?id=gwhPvu97Gm"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Position: Human Baselines in Model Evaluations Need Rigor and Transparency (With Recommendations & Reporting Checklist) [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Kevin Wei , Patricia Paskov , Sunishchal Dev , Michael Byun , Anka Reuel , Xavier Roberts-Gaal , Rachel Calcott , Evie Coxon , Chinmay Deshpande **In this position paper, we argue that human baselines in foundation model evaluations must be more rigorous and more transparent to enable meaningful comparisons of human vs. AI performance, and we provide recommendations and a reporting checklist towards this end.** Human performance baselines are vital for the machine learning community, downstream users, and policymakers to interpret AI evaluations. Models are often claimed to achieve \"super-human\" performance, but existing baselining methods are neither sufficiently rigorous nor sufficiently well-documented to robustly measure and assess performance differences. Based on a meta-review of the measurement theory and AI evaluation literatures, we derive a framework with recommendations for designing, executing, and reporting human baselines. We synthesize our recommendations into a checklist that we use to systematically review 115 human baselines (studies) in foundation model evaluations and thus identify shortcomings in existing baselining methods; our checklist can also assist researchers in conducting human baselines and reporting results. We hope our work can advance more rigorous AI evaluation practices that can better serve both the research community and policymakers. Data is available at: [https://github.com/kevinlwei/human-baselines](https://github.com/kevinlwei/human-baselines). Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "mzc1KPkIMJ@OpenReview",
      "index": 207,
      "title": "Position: Algebra Unveils Deep Learning - An Invitation to Neuroalgebraic Geometry",
      "authors": [
        "Giovanni Luca Marchetti",
        "Vahid Shahverdi",
        "Stefano Mereta",
        "Matthew Trager",
        "Kathlén Kohn"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "neuroalgebraic",
        "algebraic",
        "geometry",
        "invitation",
        "position",
        "unveils",
        "varieties",
        "learning",
        "algebro",
        "spaces"
      ],
      "summary": "In this position paper, we promote the study of function spaces parameterized by machine learning models through the lens of algebraic geometry. To this end, we focus on algebraic models, such as neural networks with polynomial activations, whose associated function spaces are semi-algebraic varieties. We outline a dictionary between algebro-geometric invariants of these varieties, such as dimension, degree, and singularities, and fundamental aspects of machine learning, such as sample complexity, expressivity, training dynamics, and implicit bias. Along the way, we review the literature and discuss ideas beyond the algebraic domain. This work lays the foundations of a research direction bridging algebraic geometry and deep learning, that we refer to as neuroalgebraic geometry.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=mzc1KPkIMJ"
        ],
        "venue": [
          "/venue/mzc1KPkIMJ@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=mzc1KPkIMJ"
        ],
        "detail": [
          "https://openreview.net/forum?id=mzc1KPkIMJ"
        ]
      },
      "scores": {
        "pdf": null,
        "kimi": null
      },
      "raw_excerpt": "Position: Algebra Unveils Deep Learning - An Invitation to Neuroalgebraic Geometry [PDF ] [Copy] [Kimi ] [REL] Authors : Giovanni Luca Marchetti , Vahid Shahverdi , Stefano Mereta , Matthew Trager , Kathlén Kohn In this position paper, we promote the study of function spaces parameterized by machine learning models through the lens of algebraic geometry. To this end, we focus on algebraic models, such as neural networks with polynomial activations, whose associated function spaces are semi-algebraic varieties. We outline a dictionary between algebro-geometric invariants of these varieties, such as dimension, degree, and singularities, and fundamental aspects of machine learning, such as sample complexity, expressivity, training dynamics, and implicit bias. Along the way, we review the literature and discuss ideas beyond the algebraic domain. This work lays the foundations of a research direction bridging algebraic geometry and deep learning, that we refer to as neuroalgebraic geometry. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "tctWi7I5wd@OpenReview",
      "index": 208,
      "title": "Position: Rethinking LLM Bias Probing Using Lessons from the Social Sciences",
      "authors": [
        "Kirsten Morehouse",
        "Siddharth Swaroop",
        "Weiwei Pan"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "bias",
        "llm",
        "probes",
        "social",
        "sciences",
        "probing",
        "lessons",
        "conflicting",
        "rethinking",
        "appropriate"
      ],
      "summary": "The proliferation of LLM bias probes introduces three challenges: we lack (1) principled criteria for selecting appropriate probes, (2) a system for reconciling conflicting results across probes, and (3) formal frameworks for reasoning about when and why experimental findings will generalize to real user behavior. In response, we propose a systematic approach to LLM social bias probing, drawing on insights from the social sciences. Central to this approach is EcoLevels—a novel framework that helps (a) identify appropriate bias probes (b) reconcile conflicting results, and (c) generate predictions about bias generalization. We ground our framework in the social sciences, as many LLM probes are adapted from human studies, and these fields have faced similar challenges when studying bias in humans. Finally, we outline five lessons that demonstrate how LLM bias probing can (and should) benefit from decades of social science research",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=tctWi7I5wd"
        ],
        "venue": [
          "/venue/tctWi7I5wd@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=tctWi7I5wd"
        ],
        "detail": [
          "https://openreview.net/forum?id=tctWi7I5wd"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Position: Rethinking LLM Bias Probing Using Lessons from the Social Sciences [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Kirsten Morehouse , Siddharth Swaroop , Weiwei Pan The proliferation of LLM bias probes introduces three challenges: we lack (1) principled criteria for selecting appropriate probes, (2) a system for reconciling conflicting results across probes, and (3) formal frameworks for reasoning about when and why experimental findings will generalize to real user behavior. In response, we propose a systematic approach to LLM social bias probing, drawing on insights from the social sciences. Central to this approach is EcoLevels—a novel framework that helps (a) identify appropriate bias probes (b) reconcile conflicting results, and (c) generate predictions about bias generalization. We ground our framework in the social sciences, as many LLM probes are adapted from human studies, and these fields have faced similar challenges when studying bias in humans. Finally, we outline five lessons that demonstrate how LLM bias probing can (and should) benefit from decades of social science research Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "hfLqdquVt3@OpenReview",
      "index": 209,
      "title": "Do Multiple Instance Learning Models Transfer?",
      "authors": [
        "Daniel Shao",
        "Richard Chen",
        "Andrew Song",
        "Joel Runevic",
        "Ming Y. Lu",
        "Tong Ding",
        "Faisal Mahmood"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "mil",
        "pretraining",
        "transfer",
        "pretrained",
        "cancer",
        "pathology",
        "pan",
        "tissue",
        "models",
        "instance"
      ],
      "summary": "Multiple Instance Learning (MIL) is a cornerstone approach in computational pathology for distilling embeddings from gigapixel tissue images into patient-level representations to predict clinical outcomes. However, MIL is frequently challenged by the constraints of working with small, weakly-supervised clinical datasets. Unlike fields such as natural language processing and computer vision, which effectively use transfer learning to improve model quality in data-scarce environments, the transferability of MIL models remains largely unexplored. We conduct the first comprehensive investigation into transfer learning capabilities of pretrained MIL models, evaluating 11 MIL models across 19 pretraining tasks spanning tissue subtyping, cancer grading, and molecular subtype prediction. We observe a substantial performance boost with finetuning pretrained models over training from randomly initialized weights, even with domain differences between pretraining and target tasks. Pretraining on pan-cancer datasets enables consistent generalization across organs and task types compared to single-disease pretraining. Remarkably, this pan-cancer pretraining leads to better transfer than that of a state-of-the-art slide-level foundation model, while using only 6.5\\% of the training data. These findings indicate that MIL architectures exhibit robust adaptability, offering insights into the benefits of leveraging pretrained models to enhance performance in computational pathology.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=hfLqdquVt3"
        ],
        "venue": [
          "/venue/hfLqdquVt3@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=hfLqdquVt3"
        ],
        "detail": [
          "https://openreview.net/forum?id=hfLqdquVt3"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": null
      },
      "raw_excerpt": "Do Multiple Instance Learning Models Transfer? [PDF 1 ] [Copy] [Kimi ] [REL] Authors : Daniel Shao , Richard Chen , Andrew Song , Joel Runevic , Ming Y. Lu , Tong Ding , Faisal Mahmood Multiple Instance Learning (MIL) is a cornerstone approach in computational pathology for distilling embeddings from gigapixel tissue images into patient-level representations to predict clinical outcomes. However, MIL is frequently challenged by the constraints of working with small, weakly-supervised clinical datasets. Unlike fields such as natural language processing and computer vision, which effectively use transfer learning to improve model quality in data-scarce environments, the transferability of MIL models remains largely unexplored. We conduct the first comprehensive investigation into transfer learning capabilities of pretrained MIL models, evaluating 11 MIL models across 19 pretraining tasks spanning tissue subtyping, cancer grading, and molecular subtype prediction. We observe a substantial performance boost with finetuning pretrained models over training from randomly initialized weights, even with domain differences between pretraining and target tasks. Pretraining on pan-cancer datasets enables consistent generalization across organs and task types compared to single-disease pretraining. Remarkably, this pan-cancer pretraining leads to better transfer than that of a state-of-the-art slide-level foundation model, while using only 6.5\\% of the training data. These findings indicate that MIL architectures exhibit robust adaptability, offering insights into the benefits of leveraging pretrained models to enhance performance in computational pathology. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "92oBV5HAGl@OpenReview",
      "index": 210,
      "title": "Mechanistic Unlearning: Robust Knowledge Unlearning and Editing via Mechanistic Localization",
      "authors": [
        "Phillip Guo",
        "Aaquib Syed",
        "Abhay Sheshadri",
        "Aidan Ewart",
        "Gintare Karolina Dziugaite"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "unlearning",
        "mechanistic",
        "editing",
        "edits",
        "knowledge",
        "components",
        "robust",
        "edit",
        "counterfact",
        "relearn"
      ],
      "summary": "Methods for knowledge editing and unlearning in large language models seek to edit or remove undesirable knowledge or capabilities without compromising general language modeling performance. This work investigates how mechanistic interpretability---which, in part, aims to identify model components (circuits) associated to specific interpretable mechanisms that make up a model capability---can improve the precision and effectiveness of editing and unlearning. We find a stark difference in unlearning and edit robustness when training components localized by different methods. We highlight an important distinction between methods that localize components based primarily on preserving outputs, and those finding high level mechanisms with predictable intermediate states. In particular, localizing edits/unlearning to components associated with the *lookup-table mechanism* for factual recall 1) leads to more robust edits/unlearning across different input/output formats, and 2) resists attempts to relearn the unwanted information, while also reducing unintended side effects compared to baselines, on both a sports facts dataset and the CounterFact dataset across multiple models.We also find that certain localized edits disrupt the latent knowledge in the model more than any other baselines, making unlearning more robust to various attacks.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=92oBV5HAGl"
        ],
        "venue": [
          "/venue/92oBV5HAGl@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=92oBV5HAGl"
        ],
        "detail": [
          "https://openreview.net/forum?id=92oBV5HAGl"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Mechanistic Unlearning: Robust Knowledge Unlearning and Editing via Mechanistic Localization [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Phillip Guo , Aaquib Syed , Abhay Sheshadri , Aidan Ewart , Gintare Karolina Dziugaite Methods for knowledge editing and unlearning in large language models seek to edit or remove undesirable knowledge or capabilities without compromising general language modeling performance. This work investigates how mechanistic interpretability---which, in part, aims to identify model components (circuits) associated to specific interpretable mechanisms that make up a model capability---can improve the precision and effectiveness of editing and unlearning. We find a stark difference in unlearning and edit robustness when training components localized by different methods. We highlight an important distinction between methods that localize components based primarily on preserving outputs, and those finding high level mechanisms with predictable intermediate states. In particular, localizing edits/unlearning to components associated with the *lookup-table mechanism* for factual recall 1) leads to more robust edits/unlearning across different input/output formats, and 2) resists attempts to relearn the unwanted information, while also reducing unintended side effects compared to baselines, on both a sports facts dataset and the CounterFact dataset across multiple models.We also find that certain localized edits disrupt the latent knowledge in the model more than any other baselines, making unlearning more robust to various attacks. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "XrCbBdycDc@OpenReview",
      "index": 211,
      "title": "Monte Carlo Tree Diffusion for System 2 Planning",
      "authors": [
        "Jaesik Yoon",
        "Hyeonseo Cho",
        "Doojin Baek",
        "Yoshua Bengio",
        "Sungjin Ahn"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "diffusion",
        "mctd",
        "mcts",
        "tree",
        "monte",
        "carlo",
        "reconceptualizes",
        "planning",
        "denoised",
        "search"
      ],
      "summary": "Diffusion models have recently emerged as a powerful tool for planning. However, unlike Monte Carlo Tree Search (MCTS)—whose performance naturally improves with inference-time computation scaling—standard diffusion‐based planners offer only limited avenues for the scalability. In this paper, we introduce Monte Carlo Tree Diffusion (MCTD), a novel framework that integrates the generative strength of diffusion models with the adaptive search capabilities of MCTS. Our method reconceptualizes denoising as a tree‐structured process, allowing partially denoised plans to be iteratively evaluated, pruned, and refined. By selectively expanding promising trajectories while retaining the flexibility to revisit and improve suboptimal branches, MCTD achieves the benefits of MCTS such as controlling exploration-exploitation trade-offs within the diffusion framework. Empirical results on challenging long‐horizon tasks show that MCTD outperforms diffusion baselines, yielding higher‐quality solutions as inference-time computation increases.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=XrCbBdycDc"
        ],
        "venue": [
          "/venue/XrCbBdycDc@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=XrCbBdycDc"
        ],
        "detail": [
          "https://openreview.net/forum?id=XrCbBdycDc"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 1
      },
      "raw_excerpt": "Monte Carlo Tree Diffusion for System 2 Planning [PDF 3 ] [Copy] [Kimi 1 ] [REL] Authors : Jaesik Yoon , Hyeonseo Cho , Doojin Baek , Yoshua Bengio , Sungjin Ahn Diffusion models have recently emerged as a powerful tool for planning. However, unlike Monte Carlo Tree Search (MCTS)—whose performance naturally improves with inference-time computation scaling—standard diffusion‐based planners offer only limited avenues for the scalability. In this paper, we introduce Monte Carlo Tree Diffusion (MCTD), a novel framework that integrates the generative strength of diffusion models with the adaptive search capabilities of MCTS. Our method reconceptualizes denoising as a tree‐structured process, allowing partially denoised plans to be iteratively evaluated, pruned, and refined. By selectively expanding promising trajectories while retaining the flexibility to revisit and improve suboptimal branches, MCTD achieves the benefits of MCTS such as controlling exploration-exploitation trade-offs within the diffusion framework. Empirical results on challenging long‐horizon tasks show that MCTD outperforms diffusion baselines, yielding higher‐quality solutions as inference-time computation increases. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "qLfo1sef50@OpenReview",
      "index": 212,
      "title": "Policy-labeled Preference Learning: Is Preference Enough for RLHF?",
      "authors": [
        "Taehyun Cho",
        "Seokhun Ju",
        "Seungyub Han",
        "Dohyeong Kim",
        "Kyungjae Lee",
        "Jungwoo Lee"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "rlhf",
        "preference",
        "ppl",
        "policy",
        "human",
        "learning",
        "labeled",
        "reward",
        "preferences",
        "regret"
      ],
      "summary": "To design reward that align with human goals, Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent technique for learning reward functions from human preferences and optimizing models using reinforcement learning algorithms. However, existing RLHF methods often misinterpret trajectories as being generated by an optimal policy, causing inaccurate likelihood estimation and suboptimal learning. To address this, we propose Policy-labeled Preference Learning (PPL) within the Direct Preference Optimization (DPO) framework, which resolves these likelihood mismatch problems by modeling human preferences with regret, reflecting the efficiency of executed policies. Additionally, we introduce a contrastive KL regularization term derived from regret-based principles to enhance sequential contrastive learning. Experiments in high-dimensional continuous control environments demonstrate PPL's significant improvements in offline RLHF performance and its effectiveness in online settings.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=qLfo1sef50"
        ],
        "venue": [
          "/venue/qLfo1sef50@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=qLfo1sef50"
        ],
        "detail": [
          "https://openreview.net/forum?id=qLfo1sef50"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 4
      },
      "raw_excerpt": "Policy-labeled Preference Learning: Is Preference Enough for RLHF? [PDF 3 ] [Copy] [Kimi 4 ] [REL] Authors : Taehyun Cho , Seokhun Ju , Seungyub Han , Dohyeong Kim , Kyungjae Lee , Jungwoo Lee To design reward that align with human goals, Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent technique for learning reward functions from human preferences and optimizing models using reinforcement learning algorithms. However, existing RLHF methods often misinterpret trajectories as being generated by an optimal policy, causing inaccurate likelihood estimation and suboptimal learning. To address this, we propose Policy-labeled Preference Learning (PPL) within the Direct Preference Optimization (DPO) framework, which resolves these likelihood mismatch problems by modeling human preferences with regret, reflecting the efficiency of executed policies. Additionally, we introduce a contrastive KL regularization term derived from regret-based principles to enhance sequential contrastive learning. Experiments in high-dimensional continuous control environments demonstrate PPL's significant improvements in offline RLHF performance and its effectiveness in online settings. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "IfWKVF6LfY@OpenReview",
      "index": 213,
      "title": "DPO Meets PPO: Reinforced Token Optimization for RLHF",
      "authors": [
        "Han Zhong",
        "Zikang Shan",
        "Guhao Feng",
        "Wei Xiong",
        "Xinle Cheng",
        "Li Zhao",
        "Di He",
        "Jiang Bian",
        "Liwei Wang"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "rto",
        "ppo",
        "token",
        "texttt",
        "dpo",
        "rlhf",
        "optimization",
        "reinforced",
        "wise",
        "zkshan2002"
      ],
      "summary": "In the classical Reinforcement Learning from Human Feedback (RLHF) framework, Proximal Policy Optimization (PPO) is employed to learn from sparse, sentence-level rewards---a challenging scenario in traditional deep reinforcement learning. Despite the great successes of PPO in the alignment of state-of-the-art closed-source large language models (LLMs), its open-source implementation is still largely sub-optimal, as widely reported by numerous research studies. To address these issues, we introduce a framework that models RLHF problems as a Markov decision process (MDP), enabling the capture of fine-grained token-wise information. Furthermore, we provide theoretical insights that demonstrate the superiority of our MDP framework over the previous sentence-level bandit formulation. Under this framework, we introduce an algorithm, dubbed as Reinforced Token Optimization (\\texttt{RTO}), which learns the token-wise reward function from preference data and performs policy optimization based on this learned token-wise reward signal. Theoretically, \\texttt{RTO} is proven to have the capability of finding the near-optimal policy sample-efficiently. For its practical implementation, \\texttt{RTO} innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO, originally derived from sparse sentence rewards, surprisingly provides us with a token-wise characterization of response quality, which is seamlessly incorporated into our subsequent PPO training stage. We conduct extensive experiments to evaluate \\texttt{RTO} against PPO and other direct preference learning algorithms. The results highlight the effectiveness of RTO, with the algorithm outperforming PPO by 7.5 points on the AlpacaEval 2 benchmark and by 4.1 points on Arena-Hard. Our code and models are available at \\href{https://github.com/zkshan2002/RTO}{https://github.com/zkshan2002/RTO}.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=IfWKVF6LfY"
        ],
        "venue": [
          "/venue/IfWKVF6LfY@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=IfWKVF6LfY"
        ],
        "detail": [
          "https://openreview.net/forum?id=IfWKVF6LfY"
        ]
      },
      "scores": {
        "pdf": 8,
        "kimi": 5
      },
      "raw_excerpt": "DPO Meets PPO: Reinforced Token Optimization for RLHF [PDF 8 ] [Copy] [Kimi 5 ] [REL] Authors : Han Zhong , Zikang Shan , Guhao Feng , Wei Xiong , Xinle Cheng , Li Zhao , Di He , Jiang Bian , Liwei Wang In the classical Reinforcement Learning from Human Feedback (RLHF) framework, Proximal Policy Optimization (PPO) is employed to learn from sparse, sentence-level rewards---a challenging scenario in traditional deep reinforcement learning. Despite the great successes of PPO in the alignment of state-of-the-art closed-source large language models (LLMs), its open-source implementation is still largely sub-optimal, as widely reported by numerous research studies. To address these issues, we introduce a framework that models RLHF problems as a Markov decision process (MDP), enabling the capture of fine-grained token-wise information. Furthermore, we provide theoretical insights that demonstrate the superiority of our MDP framework over the previous sentence-level bandit formulation. Under this framework, we introduce an algorithm, dubbed as Reinforced Token Optimization (\\texttt{RTO}), which learns the token-wise reward function from preference data and performs policy optimization based on this learned token-wise reward signal. Theoretically, \\texttt{RTO} is proven to have the capability of finding the near-optimal policy sample-efficiently. For its practical implementation, \\texttt{RTO} innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO, originally derived from sparse sentence rewards, surprisingly provides us with a token-wise characterization of response quality, which is seamlessly incorporated into our subsequent PPO training stage. We conduct extensive experiments to evaluate \\texttt{RTO} against PPO and other direct preference learning algorithms. The results highlight the effectiveness of RTO, with the algorithm outperforming PPO by 7.5 points on the AlpacaEval 2 benchmark and by 4.1 points on Arena-Hard. Our code and models are available at \\href{https://github.com/zkshan2002/RTO}{https://github.com/zkshan2002/RTO}. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "4HQaMUYWAT@OpenReview",
      "index": 214,
      "title": "An Analysis for Reasoning Bias of Language Models with Small Initialization",
      "authors": [
        "Junjie Yao",
        "zhongwang zhang",
        "Zhi-Qin John Xu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "initialization",
        "reasoning",
        "tasks",
        "language",
        "bias",
        "training",
        "llms",
        "models",
        "revolutionized",
        "scales"
      ],
      "summary": "Transformer-based Large Language Models (LLMs) have revolutionized Natural Language Processing by demonstrating exceptional performance across diverse tasks. This study investigates the impact of the parameter initialization scale on the training behavior and task preferences of LLMs. We discover that smaller initialization scales encourage models to favor reasoning tasks, whereas larger initialization scales lead to a preference for memorization tasks. We validate this reasoning bias via real datasets and meticulously designed anchor functions. Further analysis of initial training dynamics suggests that specific model components, particularly the embedding space and self-attention mechanisms, play pivotal roles in shaping these learning biases. We provide a theoretical framework from the perspective of model training dynamics to explain these phenomena. Additionally, experiments on real-world language tasks corroborate our theoretical insights. This work enhances our understanding of how initialization strategies influence LLM performance on reasoning tasks and offers valuable guidelines for training models.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=4HQaMUYWAT"
        ],
        "venue": [
          "/venue/4HQaMUYWAT@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=4HQaMUYWAT"
        ],
        "detail": [
          "https://openreview.net/forum?id=4HQaMUYWAT"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 1
      },
      "raw_excerpt": "An Analysis for Reasoning Bias of Language Models with Small Initialization [PDF 2 ] [Copy] [Kimi 1 ] [REL] Authors : Junjie Yao , zhongwang zhang , Zhi-Qin John Xu Transformer-based Large Language Models (LLMs) have revolutionized Natural Language Processing by demonstrating exceptional performance across diverse tasks. This study investigates the impact of the parameter initialization scale on the training behavior and task preferences of LLMs. We discover that smaller initialization scales encourage models to favor reasoning tasks, whereas larger initialization scales lead to a preference for memorization tasks. We validate this reasoning bias via real datasets and meticulously designed anchor functions. Further analysis of initial training dynamics suggests that specific model components, particularly the embedding space and self-attention mechanisms, play pivotal roles in shaping these learning biases. We provide a theoretical framework from the perspective of model training dynamics to explain these phenomena. Additionally, experiments on real-world language tasks corroborate our theoretical insights. This work enhances our understanding of how initialization strategies influence LLM performance on reasoning tasks and offers valuable guidelines for training models. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "5QAKPBVdFH@OpenReview",
      "index": 215,
      "title": "Hide & Seek: Transformer Symmetries Obscure Sharpness & Riemannian Geometry Finds It",
      "authors": [
        "Marvin F, da Silva",
        "Felix Dangel",
        "Sageev Oore"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "sharpness",
        "symmetries",
        "transformers",
        "riemannian",
        "transformer",
        "hide",
        "obscure",
        "generalization",
        "correlation",
        "quotient"
      ],
      "summary": "The concept of sharpness has been successfully applied to traditional architectures like MLPs and CNNs to predict their generalization. For transformers, however, recent work reported weak correlation between flatness and generalization. We argue that existing sharpness measures fail for transformers, because they have much richer symmetries in their attention mechanism that induce directions in parameter space along which the network or its loss remain identical. We posit that sharpness must account fully for these symmetries, and thus we redefine it on a quotient manifold that results from quotienting out the transformer symmetries, thereby removing their ambiguities. Leveraging tools from Riemannian geometry, we propose a fully general notion of sharpness, in terms of a geodesic ball on the symmetry-corrected quotient manifold. In practice, we need to resort to approximating the geodesics. Doing so up to first order yields existing adaptive sharpness measures, and we demonstrate that including higher-order terms is crucial to recover correlation with generalization. We present results on diagonal networks with synthetic data, and show that our geodesic sharpness reveals strong correlation for real-world transformers on both text and image classification tasks.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=5QAKPBVdFH"
        ],
        "venue": [
          "/venue/5QAKPBVdFH@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=5QAKPBVdFH"
        ],
        "detail": [
          "https://openreview.net/forum?id=5QAKPBVdFH"
        ]
      },
      "scores": {
        "pdf": null,
        "kimi": 2
      },
      "raw_excerpt": "Hide & Seek: Transformer Symmetries Obscure Sharpness & Riemannian Geometry Finds It [PDF ] [Copy] [Kimi 2 ] [REL] Authors : Marvin F, da Silva , Felix Dangel , Sageev Oore The concept of sharpness has been successfully applied to traditional architectures like MLPs and CNNs to predict their generalization. For transformers, however, recent work reported weak correlation between flatness and generalization. We argue that existing sharpness measures fail for transformers, because they have much richer symmetries in their attention mechanism that induce directions in parameter space along which the network or its loss remain identical. We posit that sharpness must account fully for these symmetries, and thus we redefine it on a quotient manifold that results from quotienting out the transformer symmetries, thereby removing their ambiguities. Leveraging tools from Riemannian geometry, we propose a fully general notion of sharpness, in terms of a geodesic ball on the symmetry-corrected quotient manifold. In practice, we need to resort to approximating the geodesics. Doing so up to first order yields existing adaptive sharpness measures, and we demonstrate that including higher-order terms is crucial to recover correlation with generalization. We present results on diagonal networks with synthetic data, and show that our geodesic sharpness reveals strong correlation for real-world transformers on both text and image classification tasks. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "GbJqQsIwJu@OpenReview",
      "index": 216,
      "title": "Learning Parametric Distributions from Samples and Preferences",
      "authors": [
        "Marc Jourdan",
        "Gizem Yüce",
        "Nicolas Flammarion"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "preferences",
        "distributions",
        "samples",
        "parametric",
        "preference",
        "estimators",
        "underscored",
        "feedback",
        "unknown",
        "deterministic"
      ],
      "summary": "Recent advances in language modeling have underscored the role of preference feedback in enhancing model performance. This paper investigates the conditions under which preference feedback improves parameter estimation in classes of continuous parametric distributions. In our framework, the learner observes pairs of samples from an unknown distribution along with their relative preferences depending on the same unknown parameter. We show that preferences-based M-estimators achieve a better asymptotic variance than sample-only M-estimators, further improved by deterministic preferences. Leveraging the hard constraints revealed by deterministic preferences, we propose an estimator achieving an estimation error scaling of O ( 1 / n ) O ( 1 / n ) ---a significant improvement over the Θ ( 1 / n − − √ ) Θ ( 1 / n ) rate attainable with samples alone. Next, we establish a lower bound that matches this accelerated rate; up to problem-dependent constants. While the assumptions underpinning our analysis are restrictive, they are satisfied by notable cases such as Gaussian or Laplace distributions for preferences based on the log-probability reward.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=GbJqQsIwJu"
        ],
        "venue": [
          "/venue/GbJqQsIwJu@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=GbJqQsIwJu"
        ],
        "detail": [
          "https://openreview.net/forum?id=GbJqQsIwJu"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Learning Parametric Distributions from Samples and Preferences [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Marc Jourdan , Gizem Yüce , Nicolas Flammarion Recent advances in language modeling have underscored the role of preference feedback in enhancing model performance. This paper investigates the conditions under which preference feedback improves parameter estimation in classes of continuous parametric distributions. In our framework, the learner observes pairs of samples from an unknown distribution along with their relative preferences depending on the same unknown parameter. We show that preferences-based M-estimators achieve a better asymptotic variance than sample-only M-estimators, further improved by deterministic preferences. Leveraging the hard constraints revealed by deterministic preferences, we propose an estimator achieving an estimation error scaling of O ( 1 / n ) O ( 1 / n ) ---a significant improvement over the Θ ( 1 / n − − √ ) Θ ( 1 / n ) rate attainable with samples alone. Next, we establish a lower bound that matches this accelerated rate; up to problem-dependent constants. While the assumptions underpinning our analysis are restrictive, they are satisfied by notable cases such as Gaussian or Laplace distributions for preferences based on the log-probability reward. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Hrp6jRIKdX@OpenReview",
      "index": 217,
      "title": "Towards a Mechanistic Explanation of Diffusion Model Generalization",
      "authors": [
        "Matthew Niedoba",
        "Berend Zwartsenberg",
        "Kevin Murphy",
        "Frank Wood"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "denoisers",
        "diffusion",
        "network",
        "mechanistic",
        "denoising",
        "generalization",
        "behaviour",
        "comparing",
        "operations",
        "training"
      ],
      "summary": "We propose a simple, training-free mechanism which explains the generalization behaviour of diffusion models. By comparing pre-trained diffusion models to their theoretically optimal empirical counterparts, we identify a shared local inductive bias across a variety of network architectures. From this observation, we hypothesize that network denoisers generalize through localized denoising operations, as these operations approximate the training objective well over much of the training distribution. To validate our hypothesis, we introduce novel denoising algorithms which aggregate local empirical denoisers to replicate network behaviour. Comparing these algorithms to network denoisers across forward and reverse diffusion processes, our approach exhibits consistent visual similarity to neural network outputs, with lower mean squared error than previously proposed methods.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Hrp6jRIKdX"
        ],
        "venue": [
          "/venue/Hrp6jRIKdX@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Hrp6jRIKdX"
        ],
        "detail": [
          "https://openreview.net/forum?id=Hrp6jRIKdX"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "Towards a Mechanistic Explanation of Diffusion Model Generalization [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Matthew Niedoba , Berend Zwartsenberg , Kevin Murphy , Frank Wood We propose a simple, training-free mechanism which explains the generalization behaviour of diffusion models. By comparing pre-trained diffusion models to their theoretically optimal empirical counterparts, we identify a shared local inductive bias across a variety of network architectures. From this observation, we hypothesize that network denoisers generalize through localized denoising operations, as these operations approximate the training objective well over much of the training distribution. To validate our hypothesis, we introduce novel denoising algorithms which aggregate local empirical denoisers to replicate network behaviour. Comparing these algorithms to network denoisers across forward and reverse diffusion processes, our approach exhibits consistent visual similarity to neural network outputs, with lower mean squared error than previously proposed methods. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Ukjl86EsIk@OpenReview",
      "index": 218,
      "title": "Decision Theoretic Foundations for Conformal Prediction: Optimal Uncertainty Quantification for Risk-Averse Agents",
      "authors": [
        "Shayan Kiyani",
        "George Pappas",
        "Aaron Roth",
        "Hamed Hassani"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "averse",
        "decision",
        "risk",
        "makers",
        "prediction",
        "rac",
        "uncertainty",
        "optimal",
        "sets",
        "quantification"
      ],
      "summary": "A fundamental question in data-driven decision making is how to quantify the uncertainty of predictions to inform risk-sensitive downstream actions, as often required in domains such as medicine. We develop a decision-theoretic foundation linking prediction sets to risk-averse decision-making, addressing three questions: (1) What is the correct notion of uncertainty quantification for risk-averse decision makers? We prove that prediction sets are optimal for decision makers who wish to optimize their value at risk. (2) What is the optimal policy that a risk averse decision maker should use to map prediction sets to actions? We show that a simple max-min decision policy is optimal for risk-averse decision makers. Finally, (3) How can we derive prediction sets that are optimal for such decision makers? We provide an exact characterization in the population regime and a distribution free finite-sample construction. These insights leads to *Risk-Averse Calibration (RAC)*, a principled algorithm that is both *practical*—exploiting black-box predictions to enhance downstream utility—and *safe*—adhering to user-defined risk thresholds. We experimentally demonstrate RAC's advantages in medical diagnosis and recommendation systems, showing that it substantially improves the trade-off between safety and utility, delivering higher utility than existing methods while avoiding critical errors.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Ukjl86EsIk"
        ],
        "venue": [
          "/venue/Ukjl86EsIk@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Ukjl86EsIk"
        ],
        "detail": [
          "https://openreview.net/forum?id=Ukjl86EsIk"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 3
      },
      "raw_excerpt": "Decision Theoretic Foundations for Conformal Prediction: Optimal Uncertainty Quantification for Risk-Averse Agents [PDF 1 ] [Copy] [Kimi 3 ] [REL] Authors : Shayan Kiyani , George Pappas , Aaron Roth , Hamed Hassani A fundamental question in data-driven decision making is how to quantify the uncertainty of predictions to inform risk-sensitive downstream actions, as often required in domains such as medicine. We develop a decision-theoretic foundation linking prediction sets to risk-averse decision-making, addressing three questions: (1) What is the correct notion of uncertainty quantification for risk-averse decision makers? We prove that prediction sets are optimal for decision makers who wish to optimize their value at risk. (2) What is the optimal policy that a risk averse decision maker should use to map prediction sets to actions? We show that a simple max-min decision policy is optimal for risk-averse decision makers. Finally, (3) How can we derive prediction sets that are optimal for such decision makers? We provide an exact characterization in the population regime and a distribution free finite-sample construction. These insights leads to *Risk-Averse Calibration (RAC)*, a principled algorithm that is both *practical*—exploiting black-box predictions to enhance downstream utility—and *safe*—adhering to user-defined risk thresholds. We experimentally demonstrate RAC's advantages in medical diagnosis and recommendation systems, showing that it substantially improves the trade-off between safety and utility, delivering higher utility than existing methods while avoiding critical errors. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "Z1qZoHa6ql@OpenReview",
      "index": 219,
      "title": "Counterfactual Graphical Models: Constraints and Inference",
      "authors": [
        "Juan Correa",
        "Elias Bareinboim"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "counterfactual",
        "constraints",
        "graphical",
        "causal",
        "calculus",
        "independences",
        "ctf",
        "inference",
        "quantities",
        "diagram"
      ],
      "summary": "Graphical models have been widely used as parsimonious encoders of constraints of the underlying probability models. When organized in a structured way, these models can facilitate the derivation of non-trivial constraints, the inference of quantities of interest, and the optimization of their estimands. In particular, causal diagrams allow for the efficient representation of structural constraints of the underlying causal system. In this paper, we introduce an efficient graphical construction called Ancestral Multi-world Networks that is sound and complete for reading counterfactual independences from a causal diagram using d-separation. Moreover, we introduce the counterfactual (ctf-) calculus, which can be used to transform counterfactual quantities using three rules licensed by the constraints encoded in the diagram. This result generalizes Pearl’s celebrated do-calculus from interventional to counterfactual reasoning.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=Z1qZoHa6ql"
        ],
        "venue": [
          "/venue/Z1qZoHa6ql@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=Z1qZoHa6ql"
        ],
        "detail": [
          "https://openreview.net/forum?id=Z1qZoHa6ql"
        ]
      },
      "scores": {
        "pdf": 3,
        "kimi": 2
      },
      "raw_excerpt": "Counterfactual Graphical Models: Constraints and Inference [PDF 3 ] [Copy] [Kimi 2 ] [REL] Authors : Juan Correa , Elias Bareinboim Graphical models have been widely used as parsimonious encoders of constraints of the underlying probability models. When organized in a structured way, these models can facilitate the derivation of non-trivial constraints, the inference of quantities of interest, and the optimization of their estimands. In particular, causal diagrams allow for the efficient representation of structural constraints of the underlying causal system. In this paper, we introduce an efficient graphical construction called Ancestral Multi-world Networks that is sound and complete for reading counterfactual independences from a causal diagram using d-separation. Moreover, we introduce the counterfactual (ctf-) calculus, which can be used to transform counterfactual quantities using three rules licensed by the constraints encoded in the diagram. This result generalizes Pearl’s celebrated do-calculus from interventional to counterfactual reasoning. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "c16m2kUTLZ@OpenReview",
      "index": 220,
      "title": "No Soundness in the Real World: On the Challenges of the Verification of Deployed Neural Networks",
      "authors": [
        "Attila Szász",
        "Balázs Bánhelyi",
        "Mark Jelasity"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "soundness",
        "verifiers",
        "floating",
        "verification",
        "deployed",
        "bounding",
        "deployment",
        "networks",
        "goal",
        "precision"
      ],
      "summary": "The ultimate goal of verification is to guarantee the safety of deployed neural networks. Here, we claim that all the state-of-the-art verifiers we are aware of fail to reach this goal. Our key insight is that theoretical soundness (bounding the full-precision output while computing with floating point) does not imply practical soundness (bounding the floating point output in a potentially stochastic environment). We prove this observation for the approaches that are currently used to achieve provable theoretical soundness, such as interval analysis and its variants. We also argue that achieving practical soundness is significantly harder computationally. We support our claims empirically as well by evaluating several well-known verification methods. To mislead the verifiers, we create adversarial networks that detect and exploit features of the deployment environment, such as the order and precision of floating point operations. We demonstrate that all the tested verifiers are vulnerable to our new deployment-specific attacks, which proves that they are not practically sound.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=c16m2kUTLZ"
        ],
        "venue": [
          "/venue/c16m2kUTLZ@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=c16m2kUTLZ"
        ],
        "detail": [
          "https://openreview.net/forum?id=c16m2kUTLZ"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "No Soundness in the Real World: On the Challenges of the Verification of Deployed Neural Networks [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Attila Szász , Balázs Bánhelyi , Mark Jelasity The ultimate goal of verification is to guarantee the safety of deployed neural networks. Here, we claim that all the state-of-the-art verifiers we are aware of fail to reach this goal. Our key insight is that theoretical soundness (bounding the full-precision output while computing with floating point) does not imply practical soundness (bounding the floating point output in a potentially stochastic environment). We prove this observation for the approaches that are currently used to achieve provable theoretical soundness, such as interval analysis and its variants. We also argue that achieving practical soundness is significantly harder computationally. We support our claims empirically as well by evaluating several well-known verification methods. To mislead the verifiers, we create adversarial networks that detect and exploit features of the deployment environment, such as the order and precision of floating point operations. We demonstrate that all the tested verifiers are vulnerable to our new deployment-specific attacks, which proves that they are not practically sound. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "d60cmFf89H@OpenReview",
      "index": 221,
      "title": "TabFlex: Scaling Tabular Learning to Millions with Linear Attention",
      "authors": [
        "Yuchen Zeng",
        "Tuan Dinh",
        "Wonjun Kang",
        "Andreas Mueller"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "tabflex",
        "tabpfn",
        "tabular",
        "datasets",
        "attention",
        "millions",
        "speedup",
        "scaling",
        "diverse",
        "poker"
      ],
      "summary": "Leveraging the in-context learning (ICL) capability of Large Language Models (LLMs) for tabular classification has gained significant attention for its training-free adaptability across diverse datasets. Recent advancements, like TabPFN, excel in small-scale tabular datasets but struggle to scale for large and complex datasets. Our work enhances the efficiency and scalability of TabPFN for larger datasets by incorporating linear attention mechanisms as a scalable alternative to complexity-quadratic self-attention. Our model, TabFlex, efficiently handles tabular datasets with thousands of features and hundreds of classes, scaling seamlessly to millions of samples. For instance, TabFlex processes the poker-hand dataset with over a million samples in just 5 seconds. Our extensive evaluations demonstrate that TabFlex can achieve over a 2× speedup compared to TabPFN and a 1.5× speedup over XGBoost, outperforming 25 tested baselines in terms of efficiency across a diverse range of datasets. Furthermore, TabFlex remains highly effective on large-scale datasets, delivering strong performance with significantly reduced computational costs, especially when combined with data-efficient techniques such as dimensionality reduction and data sampling.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=d60cmFf89H"
        ],
        "venue": [
          "/venue/d60cmFf89H@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=d60cmFf89H"
        ],
        "detail": [
          "https://openreview.net/forum?id=d60cmFf89H"
        ]
      },
      "scores": {
        "pdf": 1,
        "kimi": 1
      },
      "raw_excerpt": "TabFlex: Scaling Tabular Learning to Millions with Linear Attention [PDF 1 ] [Copy] [Kimi 1 ] [REL] Authors : Yuchen Zeng , Tuan Dinh , Wonjun Kang , Andreas Mueller Leveraging the in-context learning (ICL) capability of Large Language Models (LLMs) for tabular classification has gained significant attention for its training-free adaptability across diverse datasets. Recent advancements, like TabPFN, excel in small-scale tabular datasets but struggle to scale for large and complex datasets. Our work enhances the efficiency and scalability of TabPFN for larger datasets by incorporating linear attention mechanisms as a scalable alternative to complexity-quadratic self-attention. Our model, TabFlex, efficiently handles tabular datasets with thousands of features and hundreds of classes, scaling seamlessly to millions of samples. For instance, TabFlex processes the poker-hand dataset with over a million samples in just 5 seconds. Our extensive evaluations demonstrate that TabFlex can achieve over a 2× speedup compared to TabPFN and a 1.5× speedup over XGBoost, outperforming 25 tested baselines in terms of efficiency across a diverse range of datasets. Furthermore, TabFlex remains highly effective on large-scale datasets, delivering strong performance with significantly reduced computational costs, especially when combined with data-efficient techniques such as dimensionality reduction and data sampling. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "hYHczNrKoX@OpenReview",
      "index": 222,
      "title": "On the Benefits of Active Data Collection in Operator Learning",
      "authors": [
        "Unique Subedi",
        "Ambuj Tewari"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "collection",
        "covariance",
        "active",
        "operator",
        "decay",
        "strategies",
        "data",
        "kernels",
        "convergence",
        "rate"
      ],
      "summary": "We study active data collection strategies for operator learning when the target operator is linear and the input functions are drawn from a mean-zero stochastic process with continuous covariance kernels. With an active data collection strategy, we establish an error convergence rate in terms of the decay rate of the eigenvalues of the covariance kernel. We can achieve arbitrarily fast error convergence rates with sufficiently rapid eigenvalue decay of the covariance kernels. This contrasts with thepassive (i.i.d.) data collection strategies, where the convergence rate is never faster than linear decay ( ∼ n − 1 ∼ n − 1 ). In fact, for our setting, we show a \\emph{non-vanishing} lower bound for any passive data collection strategy, regardless of the eigenvalues decay rate of the covariance kernel. Overall, our results show the benefit of active data collection strategies in operator learning over their passive counterparts.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=hYHczNrKoX"
        ],
        "venue": [
          "/venue/hYHczNrKoX@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=hYHczNrKoX"
        ],
        "detail": [
          "https://openreview.net/forum?id=hYHczNrKoX"
        ]
      },
      "scores": {
        "pdf": null,
        "kimi": 1
      },
      "raw_excerpt": "On the Benefits of Active Data Collection in Operator Learning [PDF ] [Copy] [Kimi 1 ] [REL] Authors : Unique Subedi , Ambuj Tewari We study active data collection strategies for operator learning when the target operator is linear and the input functions are drawn from a mean-zero stochastic process with continuous covariance kernels. With an active data collection strategy, we establish an error convergence rate in terms of the decay rate of the eigenvalues of the covariance kernel. We can achieve arbitrarily fast error convergence rates with sufficiently rapid eigenvalue decay of the covariance kernels. This contrasts with thepassive (i.i.d.) data collection strategies, where the convergence rate is never faster than linear decay ( ∼ n − 1 ∼ n − 1 ). In fact, for our setting, we show a \\emph{non-vanishing} lower bound for any passive data collection strategy, regardless of the eigenvalues decay rate of the covariance kernel. Overall, our results show the benefit of active data collection strategies in operator learning over their passive counterparts. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "mQeZEsdODh@OpenReview",
      "index": 223,
      "title": "Continual Reinforcement Learning by Planning with Online World Models",
      "authors": [
        "Zichen Liu",
        "Guoji Fu",
        "Chao Du",
        "Wee Sun Lee",
        "Min Lin"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "online",
        "continual",
        "crl",
        "world",
        "forgetting",
        "planning",
        "solve",
        "tasks",
        "agent",
        "reinforcement"
      ],
      "summary": "Continual reinforcement learning (CRL) refers to a naturalistic setting where an agent needs to endlessly evolve, by trial and error, to solve multiple tasks that are presented sequentially. One of the largest obstacles to CRL is that the agent may forget how to solve previous tasks when learning a new task, known as catastrophic forgetting. In this paper, we propose to address this challenge by planning with online world models. Specifically, we learn a Follow-The-Leader shallow model online to capture the world dynamics, in which we plan using model predictive control to solve a set of tasks specified by any reward functions. The online world model is immune to forgetting by construction with a proven regret bound of O ( K 2 D log ( T ) − − − − − − − − − − √ ) O ( K 2 D log ⁡ ( T ) ) under mild assumptions. The planner searches actions solely based on the latest online model, thus forming a FTL Online Agent (OA) that updates incrementally. To assess OA, we further design Continual Bench, a dedicated environment for CRL, and compare with several strong baselines under the same model-planning algorithmic framework. The empirical results show that OA learns continuously to solve new tasks while not forgetting old skills, outperforming agents built on deep world models with various continual learning techniques.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=mQeZEsdODh"
        ],
        "venue": [
          "/venue/mQeZEsdODh@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=mQeZEsdODh"
        ],
        "detail": [
          "https://openreview.net/forum?id=mQeZEsdODh"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 3
      },
      "raw_excerpt": "Continual Reinforcement Learning by Planning with Online World Models [PDF 4 ] [Copy] [Kimi 3 ] [REL] Authors : Zichen Liu , Guoji Fu , Chao Du , Wee Sun Lee , Min Lin Continual reinforcement learning (CRL) refers to a naturalistic setting where an agent needs to endlessly evolve, by trial and error, to solve multiple tasks that are presented sequentially. One of the largest obstacles to CRL is that the agent may forget how to solve previous tasks when learning a new task, known as catastrophic forgetting. In this paper, we propose to address this challenge by planning with online world models. Specifically, we learn a Follow-The-Leader shallow model online to capture the world dynamics, in which we plan using model predictive control to solve a set of tasks specified by any reward functions. The online world model is immune to forgetting by construction with a proven regret bound of O ( K 2 D log ( T ) − − − − − − − − − − √ ) O ( K 2 D log ⁡ ( T ) ) under mild assumptions. The planner searches actions solely based on the latest online model, thus forming a FTL Online Agent (OA) that updates incrementally. To assess OA, we further design Continual Bench, a dedicated environment for CRL, and compare with several strong baselines under the same model-planning algorithmic framework. The empirical results show that OA learns continuously to solve new tasks while not forgetting old skills, outperforming agents built on deep world models with various continual learning techniques. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "n1cqQK4hhC@OpenReview",
      "index": 224,
      "title": "STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization",
      "authors": [
        "Hao Li",
        "Qi Lv",
        "Rui Shao",
        "Xiang Deng",
        "Yinchuan Li",
        "Jianye Hao",
        "Liqiang Nie"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "skill",
        "abstractions",
        "rotation",
        "codebook",
        "otation",
        "star",
        "skills",
        "libero",
        "augmented",
        "quantization"
      ],
      "summary": "Transforming complex actions into discrete skill abstractions has demonstrated strong potential for robotic manipulation.Existing approaches mainly leverage latent variable models, e.g., VQ-VAE, to learn skill abstractions through learned vectors (codebooks), while they suffer from codebook collapse and modeling the causal relationship between learned skills. To address these limitations, we present **S**kill **T**raining with **A**ugmented **R**otation (**STAR**), a framework that advances both skill learning and composition to complete complex behaviors. Specifically, to prevent codebook collapse, we devise rotation-augmented residual skill quantization (RaRSQ).It encodes relative angles between encoder outputs into the gradient flow by rotation-based gradient mechanism. Points within the same skill code are forced to be either pushed apart or pulled closer together depending on gradient directions.Further, to capture the casual relationship between skills, we present causal skill transformer (CST) which explicitly models dependencies between skill representations through an autoregressive mechanism for coherent action generation.Extensive experiments demonstrate the superiority of STAR on both LIBERO benchmark and realworld tasks, with around 12% improvement over the baselines.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=n1cqQK4hhC"
        ],
        "venue": [
          "/venue/n1cqQK4hhC@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=n1cqQK4hhC"
        ],
        "detail": [
          "https://openreview.net/forum?id=n1cqQK4hhC"
        ]
      },
      "scores": {
        "pdf": 2,
        "kimi": 5
      },
      "raw_excerpt": "STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization [PDF 2 ] [Copy] [Kimi 5 ] [REL] Authors : Hao Li , Qi Lv , Rui Shao , Xiang Deng , Yinchuan Li , Jianye Hao , Liqiang Nie Transforming complex actions into discrete skill abstractions has demonstrated strong potential for robotic manipulation.Existing approaches mainly leverage latent variable models, e.g., VQ-VAE, to learn skill abstractions through learned vectors (codebooks), while they suffer from codebook collapse and modeling the causal relationship between learned skills. To address these limitations, we present **S**kill **T**raining with **A**ugmented **R**otation (**STAR**), a framework that advances both skill learning and composition to complete complex behaviors. Specifically, to prevent codebook collapse, we devise rotation-augmented residual skill quantization (RaRSQ).It encodes relative angles between encoder outputs into the gradient flow by rotation-based gradient mechanism. Points within the same skill code are forced to be either pushed apart or pulled closer together depending on gradient directions.Further, to capture the casual relationship between skills, we present causal skill transformer (CST) which explicitly models dependencies between skill representations through an autoregressive mechanism for coherent action generation.Extensive experiments demonstrate the superiority of STAR on both LIBERO benchmark and realworld tasks, with around 12% improvement over the baselines. Subject : ICML.2025 - Spotlight"
    },
    {
      "paper_id": "vES22INUKm@OpenReview",
      "index": 225,
      "title": "An Error Analysis of Flow Matching for Deep Generative Modeling",
      "authors": [
        "Zhengyu Zhou",
        "Weiwei Liu"
      ],
      "subjects": [
        "ICML.2025 - Spotlight"
      ],
      "keywords": [
        "cnfs",
        "matching",
        "generative",
        "target",
        "analysis",
        "error",
        "flow",
        "modeling",
        "end",
        "deep"
      ],
      "summary": "Continuous Normalizing Flows (CNFs) have proven to be a highly efficient technique for generative modeling of complex data since the introduction of Flow Matching (FM). The core of FM is to learn the constructed velocity fields of CNFs through deep least squares regression. Despite its empirical effectiveness, theoretical investigations of FM remain limited. In this paper, we present the first end-to-end error analysis of CNFs built upon FM. Our analysis shows that for general target distributions with bounded support, the generated distribution of FM is guaranteed to converge to the target distribution in the sense of the Wasserstein-2 distance. Furthermore, the convergence rate is significantly improved under an additional mild Lipschitz condition of the target score function.",
      "session": null,
      "time": null,
      "links": {
        "link": [
          "https://openreview.net/forum?id=vES22INUKm"
        ],
        "venue": [
          "/venue/vES22INUKm@OpenReview",
          "/venue/ICML.2025?group=Spotlight"
        ],
        "pdf": [
          "https://openreview.net/pdf?id=vES22INUKm"
        ],
        "detail": [
          "https://openreview.net/forum?id=vES22INUKm"
        ]
      },
      "scores": {
        "pdf": 4,
        "kimi": 4
      },
      "raw_excerpt": "An Error Analysis of Flow Matching for Deep Generative Modeling [PDF 4 ] [Copy] [Kimi 4 ] [REL] Authors : Zhengyu Zhou , Weiwei Liu Continuous Normalizing Flows (CNFs) have proven to be a highly efficient technique for generative modeling of complex data since the introduction of Flow Matching (FM). The core of FM is to learn the constructed velocity fields of CNFs through deep least squares regression. Despite its empirical effectiveness, theoretical investigations of FM remain limited. In this paper, we present the first end-to-end error analysis of CNFs built upon FM. Our analysis shows that for general target distributions with bounded support, the generated distribution of FM is guaranteed to converge to the target distribution in the sense of the Wasserstein-2 distance. Furthermore, the convergence rate is significantly improved under an additional mild Lipschitz condition of the target score function. Subject : ICML.2025 - Spotlight"
    }
  ]
}